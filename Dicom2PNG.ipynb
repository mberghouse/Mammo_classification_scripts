{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-11T16:13:10.158774Z",
     "iopub.status.busy": "2022-12-11T16:13:10.158394Z",
     "iopub.status.idle": "2022-12-11T16:13:10.183465Z",
     "shell.execute_reply": "2022-12-11T16:13:10.182345Z",
     "shell.execute_reply.started": "2022-12-11T16:13:10.158740Z"
    },
    "id": "meYctK2rOW-M",
    "outputId": "d7b00dc0-e7bf-4525-8b33-2346c2f5ea1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbadhan/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules have been imported\n",
      "dim =  (300, 300) batch size =  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 10:48:32.952726: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import os\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.utils import *\n",
    "# import pydot\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "#import json\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from glob import glob\n",
    "from skimage.io import *\n",
    "%config Completer.use_jedi = False\n",
    "import time\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import lightgbm as lgb\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"All modules have been imported\")\n",
    "#dim=(320,160)\n",
    "batch_size=24\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 # VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19 # VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 # ResNet50\n",
    "from tensorflow.keras.applications.xception import Xception # Xception\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet # MobileNet\n",
    "from tensorflow.keras.applications.nasnet import NASNetMobile # NASNetMobile\n",
    "from tensorflow.keras.applications.densenet import DenseNet169 # DenseNet169\n",
    "from tensorflow.keras.applications.densenet import DenseNet121 # DenseNet121\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 # MobileNetV2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 # InceptionV3\n",
    "\n",
    "scale_percent = 100 # percent of original size\n",
    "width = int(np.round(300 * scale_percent / 100))\n",
    "height = int(np.round(300 * scale_percent / 100))\n",
    "dim = (width, height)\n",
    "\n",
    "print ('dim = ', dim, 'batch size = ',batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this to convert Dicom to PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PNG = True\n",
    "# !pip install dicom\n",
    "import pydicom as dicom\n",
    "# Specify the .dcm folder path\n",
    "folder_path = \"F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM/\"\n",
    "# Specify the output jpg/png folder path\n",
    "jpg_folder_path = \"F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/\"\n",
    "folders=os.listdir(folder_path)\n",
    "count=1\n",
    "for i in folders:\n",
    "    if 'LICENSE' in i:\n",
    "        continue\n",
    "    else:\n",
    "        folder1=os.listdir(os.path.join(folder_path, i))\n",
    "        folder2 = os.listdir(os.path.join(folder_path, i,folder1[0]))\n",
    "        if \"cropped images\" in folder2[0]:\n",
    "            images_path=os.listdir(os.path.join(folder_path, i,folder1[0],folder2[0]))\n",
    "            #print (images_path)\n",
    "            try:\n",
    "                os.makedirs(os.path.join(jpg_folder_path,i,folder1[0],folder2[0]))\n",
    "            except:\n",
    "                print ('some minor error')\n",
    "            for image in images_path:\n",
    "                ds = dicom.dcmread(os.path.join(folder_path, i,folder1[0],folder2[0],image))\n",
    "                pixel_array_numpy = ds.pixel_array\n",
    "                if PNG == False:\n",
    "                    image = image.replace('.dcm', '.jpg')\n",
    "                else:\n",
    "                    image = image.replace('.dcm', '.png')\n",
    "\n",
    "                cv2.imwrite(os.path.join(jpg_folder_path,i,folder1[0],folder2[0], image), pixel_array_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-1.dcm']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
