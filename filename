 1/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('C:/Users/marcb/Downloads/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]
    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename'})
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    for i in range(len(df)):
        df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
#df_list
df_mass_test=df_list[0]
df_mass_train=df_list[1]
# df_calc_test=df_list[0]
# df_calc_train=df_list[1]

filenames=[]
labels=[]
for i in range(len(df_mass_train)):
    filenames.append(df_mass_train.filename.iloc[i])
    labels.append(df_mass_train['class'].iloc[i])

filenames_test=[]
labels_test=[]
for i in range(len(df_mass_test)):
    filenames_test.append(df_mass_test.filename.iloc[i])
    labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
 1/2: !pip install torch
 1/3:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('C:/Users/marcb/Downloads/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]
    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename'})
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    for i in range(len(df)):
        df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
#df_list
df_mass_test=df_list[0]
df_mass_train=df_list[1]
# df_calc_test=df_list[0]
# df_calc_train=df_list[1]

filenames=[]
labels=[]
for i in range(len(df_mass_train)):
    filenames.append(df_mass_train.filename.iloc[i])
    labels.append(df_mass_train['class'].iloc[i])

filenames_test=[]
labels_test=[]
for i in range(len(df_mass_test)):
    filenames_test.append(df_mass_test.filename.iloc[i])
    labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
 1/4: !pip install torchvision
 1/5:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('C:/Users/marcb/Downloads/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]
    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename'})
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    for i in range(len(df)):
        df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
#df_list
df_mass_test=df_list[0]
df_mass_train=df_list[1]
# df_calc_test=df_list[0]
# df_calc_train=df_list[1]

filenames=[]
labels=[]
for i in range(len(df_mass_train)):
    filenames.append(df_mass_train.filename.iloc[i])
    labels.append(df_mass_train['class'].iloc[i])

filenames_test=[]
labels_test=[]
for i in range(len(df_mass_test)):
    filenames_test.append(df_mass_test.filename.iloc[i])
    labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
 1/6: !pip install opencv-python
 1/7:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('C:/Users/marcb/Downloads/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]
    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename'})
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    for i in range(len(df)):
        df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
#df_list
df_mass_test=df_list[0]
df_mass_train=df_list[1]
# df_calc_test=df_list[0]
# df_calc_train=df_list[1]

filenames=[]
labels=[]
for i in range(len(df_mass_train)):
    filenames.append(df_mass_train.filename.iloc[i])
    labels.append(df_mass_train['class'].iloc[i])

filenames_test=[]
labels_test=[]
for i in range(len(df_mass_test)):
    filenames_test.append(df_mass_test.filename.iloc[i])
    labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
 1/8: !pip install torchmetrics
 1/9:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os
pip install opencv-python

import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('C:/Users/marcb/Downloads/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]
    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename'})
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    for i in range(len(df)):
        df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
#df_list
df_mass_test=df_list[0]
df_mass_train=df_list[1]
# df_calc_test=df_list[0]
# df_calc_train=df_list[1]

filenames=[]
labels=[]
for i in range(len(df_mass_train)):
    filenames.append(df_mass_train.filename.iloc[i])
    labels.append(df_mass_train['class'].iloc[i])

filenames_test=[]
labels_test=[]
for i in range(len(df_mass_test)):
    filenames_test.append(df_mass_test.filename.iloc[i])
    labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
1/10:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os
#pip install opencv-python

import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('C:/Users/marcb/Downloads/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]
    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename'})
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    for i in range(len(df)):
        df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
#df_list
df_mass_test=df_list[0]
df_mass_train=df_list[1]
# df_calc_test=df_list[0]
# df_calc_train=df_list[1]

filenames=[]
labels=[]
for i in range(len(df_mass_train)):
    filenames.append(df_mass_train.filename.iloc[i])
    labels.append(df_mass_train['class'].iloc[i])

filenames_test=[]
labels_test=[]
for i in range(len(df_mass_test)):
    filenames_test.append(df_mass_test.filename.iloc[i])
    labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
1/11:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os
#pip install opencv-python

import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]
    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename'})
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    for i in range(len(df)):
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
#df_list
df_mass_test=df_list[0]
df_mass_train=df_list[1]
# df_calc_test=df_list[0]
# df_calc_train=df_list[1]

filenames=[]
labels=[]
for i in range(len(df_mass_train)):
    filenames.append(df_mass_train.filename.iloc[i])
    labels.append(df_mass_train['class'].iloc[i])

filenames_test=[]
labels_test=[]
for i in range(len(df_mass_test)):
    filenames_test.append(df_mass_test.filename.iloc[i])
    labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
1/12: df
1/13:

import torchvision

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
    #transforms.RandomAdjustSharpness(.3, p=0.5),
    transforms.ColorJitter(brightness=.2,contrast=.2),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(4),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 3)),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(), # return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(), # return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
        #image = image.repeat(3, 1, 1)
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
1/14:
dataset = CBISDataset(labels,filenames,transform=augmentator)

val_pct = 0.2
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test,filenames_test, transform=small_aug)
test_size =  len(val_dataset)
train_size = len(train_dataset)
1/15: # test_dataloader = DataLoader(test_dataset, batch_size=1)
1/16:
# print (val_size, len(labels_test_calc),train_size, len(labels_calc))
# for i in range(len(labels_test_calc)):
#     if labels_test_calc[i] == 1:
#         print (filenames_test_calc[i])
1/17:
batch_size = 14
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=14)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=0,drop_last=True )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=0,drop_last=True )


for X, y in val_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
1/18:
plt.figure(figsize=(4,4),dpi=200)
plt.imshow(X[0,:,:,:].permute(1, 2, 0)[:,:,0])
X.dtype
# torch.min(X[0,0,:,:])
#torch.max(X[0])
1/19:
rows = 4
cols = 5
plt.subplots(rows, cols, figsize = (20, 20))

batch_imgs, batch_labels = next(iter(train_dataloader))
i = 0
for img in batch_imgs:
    
    if i >= rows*cols:
        break
    plt.subplot(rows, cols, i + 1)
    plt.title("Cancer" if batch_labels[i] == 1 else "No cancer")
    plt.imshow(img.permute(1, 2, 0)[:,:,0], cmap='jet')

    i += 1

labels_count = np.zeros(2)
for l in batch_labels:
    labels_count[l] += 1 
    
print(f'There are {labels_count[0]} negative and {labels_count[1]} positive samples in this batch.')
1/20:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
1/21:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                # statistics
                # n_samples += labels.size(0)
                running_loss += loss.item()
                # n_correct += (preds == labels).sum().item()
                #print(f'Current loss is {loss.item()}')
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                #scheduler.step()
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
            if phase == 'val' and epoch_auc > best_f1:
                best_f1 = epoch_auc
                best_model_wts = model.state_dict()
                checkpoint['threshold'] = threshold
                torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in string
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
        if epoch == 0:
            val_f1_best=val_f1
        else:
            if val_f1 > val_f1_best:
                val_f1_best=val_f1
                stop_count = 0
            else:
                stop_count = stop_count + 1
        
        if stop_count == 200:
            break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
    #model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics,best_model_wts
1/22:
def test_model(model,criterion,dataloader):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
        # cant be formated in string
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')

    time_elapsed = time.time() - since
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
1/23:
# #scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=6e-7, max_lr=6e-6,step_size_up = 100, cycle_momentum =False)
# # earlystoper = EarlyStopper(patience = 50)
# #optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)
# #optimizer = torch.optim.Adam(model.parameters(), lr=4e-5)

# model, train_metrics, val_metrics = train_model(model, criterion, optimizer, scheduler, num_epochs=60)
1/24:
# PATH='C:/Users/marcb/Desktop/pytorch_models/SEresnet50_90epoch_calc_baseline_47th_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/SEresnet50_90epoch_calc_baseline_47th_model'
# torch.save(model, PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/SEresnet50_90epoch_calc_baseline_47th_train_data'
# torch.save(train_metrics,PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/SEresnet50_90epoch_calc_baseline_47th_eval_data'

# torch.save(val_metrics,PATH)
1/25:
from functools import partial
from typing import Any, Callable, List, Optional, Type, Union

import torch
import torch.nn as nn
from torch import Tensor

from torchvision.transforms._presets import ImageClassification
from torchvision.utils import _log_api_usage_once
from torchvision.models._api import register_model, Weights, WeightsEnum
from torchvision.models._meta import _IMAGENET_CATEGORIES
from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface

class SElayer(nn.Module):
    def __init__(self, inplanes, reduction=16):
        super(SElayer,self).__init__()
        self.globalAvgpool = nn.AdaptiveAvgPool2d(1)#Squeeze操作
        self.fc1 = nn.Conv2d(inplanes, inplanes // reduction, kernel_size=1, stride=1)
        self.fc2 = nn.Conv2d(inplanes // reduction, inplanes, kernel_size=1, stride=1)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()
    def forward(self,x):
        begin_input = x
        x = self.globalAvgpool(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        
        return x * begin_input
1/26:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
#         self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
#         out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(
            nn.Linear(2048  , 256),
            nn.Dropout(.5),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
1/27:
# model=my_resnet50()
# model
1/28:
# import torch
# import torch.nn as nn
# import math
# import torch.utils.model_zoo as model_zoo


# __all__ = ['ResNet', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam',
#            'resnet152_cbam']


# model_urls = {
#     'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
#     'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
#     'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
#     'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
#     'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
# }


# def conv3x3(in_planes, out_planes, stride=1):
#     "3x3 convolution with padding"
#     return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
#                      padding=1, bias=False)

# class ChannelAttention(nn.Module):
#     def __init__(self, in_planes, ratio=16):
#         super(ChannelAttention, self).__init__()
#         self.avg_pool = nn.AdaptiveAvgPool2d(1)
#         self.max_pool = nn.AdaptiveMaxPool2d(1)
           
#         self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
#                                nn.ReLU(),
#                                nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = self.fc(self.avg_pool(x))
#         max_out = self.fc(self.max_pool(x))
#         out = avg_out + max_out
#         return self.sigmoid(out)

# class SpatialAttention(nn.Module):
#     def __init__(self, kernel_size=7):
#         super(SpatialAttention, self).__init__()

#         self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = torch.mean(x, dim=1, keepdim=True)
#         max_out, _ = torch.max(x, dim=1, keepdim=True)
#         x = torch.cat([avg_out, max_out], dim=1)
#         x = self.conv1(x)
#         return self.sigmoid(x)

# class BasicBlock(nn.Module):
#     expansion = 1

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(BasicBlock, self).__init__()
#         self.conv1 = conv3x3(inplanes, planes, stride)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.relu = nn.ReLU(inplace=True)
#         self.conv2 = conv3x3(planes, planes)
#         self.bn2 = nn.BatchNorm2d(planes)

#         self.ca = ChannelAttention(planes)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class Bottleneck(nn.Module):
#     expansion = 4

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(Bottleneck, self).__init__()
#         self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
#                                padding=1, bias=False)
#         self.bn2 = nn.BatchNorm2d(planes)
#         self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)
#         self.bn3 = nn.BatchNorm2d(planes * 4)
#         self.relu = nn.ReLU(inplace=True)

#         self.ca = ChannelAttention(planes * 4)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)
#         out = self.relu(out)

#         out = self.conv3(out)
#         out = self.bn3(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class ResNet(nn.Module):

#     def __init__(self, block, layers, num_classes=1000):
#         self.inplanes = 64
#         super(ResNet, self).__init__()
#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
#                                bias=False)
#         self.bn1 = nn.BatchNorm2d(64)
#         self.relu = nn.ReLU(inplace=True)
#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
#         self.layer1 = self._make_layer(block, 64, layers[0])
#         self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
#         self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
#         self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
#         self.fc = nn.Linear(512 * block.expansion, num_classes)

#         for m in self.modules():
#             if isinstance(m, nn.Conv2d):
#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
#                 m.weight.data.normal_(0, math.sqrt(2. / n))
#             elif isinstance(m, nn.BatchNorm2d):
#                 m.weight.data.fill_(1)
#                 m.bias.data.zero_()

#     def _make_layer(self, block, planes, blocks, stride=1):
#         downsample = None
#         if stride != 1 or self.inplanes != planes * block.expansion:
#             downsample = nn.Sequential(
#                 nn.Conv2d(self.inplanes, planes * block.expansion,
#                           kernel_size=1, stride=stride, bias=False),
#                 nn.BatchNorm2d(planes * block.expansion),
#             )

#         layers = []
#         layers.append(block(self.inplanes, planes, stride, downsample))
#         self.inplanes = planes * block.expansion
#         for i in range(1, blocks):
#             layers.append(block(self.inplanes, planes))

#         return nn.Sequential(*layers)

#     def forward(self, x):
#         x = self.conv1(x)
#         x = self.bn1(x)
#         x = self.relu(x)
#         x = self.maxpool(x)

#         x = self.layer1(x)
#         x = self.layer2(x)
#         x = self.layer3(x)
#         x = self.layer4(x)

#         x = self.avgpool(x)
#         x = x.view(x.size(0), -1)
#         x = self.fc(x)
#         x = self.classifier_layer(x)

#         return torch.sigmoid(x)


# def resnet18_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-18 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet34_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-34 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet34'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet50_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-50 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet50'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet101_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-101 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet101'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet152_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-152 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet152'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model
1/29:
# model=resnet50_cbam()
# model.eval()
1/30:
# lin = model.classifier
# new_lin = nn.Sequential(
#     lin
#     nn.Linear(1000, 1),
#     nn.ReLU(),
    
# )
# new_lin
1/31:
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True
    
#from torchvision.models import efficientnet_v2_s  
# model = CNN()
model=my_resnet50(weights="IMAGENET1K_V2")

# import timm
# model = timm.create_model('ecaresnet50d', pretrained=True)
# model.reset_classifier(0)
# #
# #model=my_resnext50_32x4d(weights="IMAGENET1K_V2")
# # model = efficientnet_v2_s(weights='DEFAULT')

# model = nn.Sequential(
#     model,
#     nn.Linear(2048 ,256),
#     nn.Dropout(.5),
#     nn.BatchNorm1d(256),
#     nn.ReLU(),
#     nn.Linear(256,1),
#     nn.Sigmoid()
# )

model.to(device)

# defining the optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)
#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=1e-6, max_lr=4e-6,step_size_up = 20, cycle_momentum =False)
#epochs=420
#scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=8e-5, total_steps=(len(train_dataset)//batch_size)*(epochs+1),pct_start=.3)

scheduler = StepLR(optimizer, step_size=5000000, gamma=0.9)
# scheduler1 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,12,20,30], gamma=0.4)
# scheduler2 = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, 2)
# scheduler3 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60,80,85,90,95], gamma=0.3)
# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2, scheduler3], milestones=[45,50])
#scheduler=None

# defining the loss function
# Binary cross entropy is chosen because it is the classification problem
# the weight should be smaller if class count is higher
neg=0
pos=0
# for label in labels:
#     if label==1:
#         pos=pos+1
#     else:
#         neg=neg+1
w_pos = 2
w_neg = 1
print(f"Class weight for negative class: {w_neg}, and for positive {w_pos}")
#criterion = BCELoss_class_weighted(weights = [w_neg, w_pos])
criterion = nn.BCELoss()
# define early stopping
# earlystoper = EarlyStopper(patience = 30)

checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

dataloaders = {'train' : train_dataloader, 'val' : val_dataloader}
dataset_sizes = {'train': train_size, 'val' : val_size}
1/32:

#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)

model, train_metrics, val_metrics,best_weights = train_model(model, criterion, optimizer, scheduler, num_epochs=100)
 2/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('C:/Users/marcb/Downloads/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
 2/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
 2/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
 2/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(12),
#     transforms.RandomAffine(degrees=(0,30),translate=(0.0, 0.05),  shear=(.5,.5)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
 2/5:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
 2/6:
# print (val_size, len(labels_test_calc),train_size, len(labels_calc))
# for i in range(len(labels_test_calc)):
#     if labels_test_calc[i] == 1:
#         print (filenames_test_calc[i])
 2/7:
batch_size = 10
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=0 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=0)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
 2/8: fname
 2/9:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
2/10:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
2/11:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(12),
#     transforms.RandomAffine(degrees=(0,30),translate=(0.0, 0.05),  shear=(.5,.5)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
2/12:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
2/13:
# print (val_size, len(labels_test_calc),train_size, len(labels_calc))
# for i in range(len(labels_test_calc)):
#     if labels_test_calc[i] == 1:
#         print (filenames_test_calc[i])
2/14:
batch_size = 10
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=0 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=0)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
2/15:
rows = 6
cols = 5
plt.subplots(rows, cols, figsize = (30, 30),dpi=100)

batch_imgs, batch_labels = next(iter(train_dataloader))
i = 0
for img in batch_imgs:
    
    if i >= rows*cols:
        break
    plt.subplot(rows, cols, i + 1)
    #plt.figure(figsize=(6,6),dpi=300)
    plt.title("Cancer" if batch_labels[i] == 1 else "No cancer")
    
    plt.imshow(img.permute(1, 2, 0)[:,:,0])

    i += 1

labels_count = np.zeros(2)
for l in batch_labels:
    labels_count[l] += 1 
    
    
print(f'There are {labels_count[0]} negative and {labels_count[1]} positive samples in this batch.')
2/16:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(6),
#     transforms.RandomAffine(degrees=(0,30),translate=(0.0, 0.05),  shear=(.5,.5)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
2/17:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
2/18:
batch_size = 10
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=0 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=0)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
2/19:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="Mass_CBAMresnet50_900x1500_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "CBAMresnet50",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
2/20: !pip install wandb
2/21:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="Mass_CBAMresnet50_900x1500_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "CBAMresnet50",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
2/22:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="Mass_CBAMresnet50_900x1500_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "CBAMresnet50",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
 3/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="Mass_CBAMresnet50_900x1500_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "CBAMresnet50",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
 3/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
 3/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
 3/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(6),
#     transforms.RandomAffine(degrees=(0,30),translate=(0.0, 0.05),  shear=(.5,.5)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
 3/5:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
 3/6:
batch_size = 10
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=0 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=0)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
 3/7:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
 3/8:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
#                 wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
#                          , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
#                 wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
#                          , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
 3/9:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
3/10:
from functools import partial
from typing import Any, Callable, List, Optional, Type, Union

import torch
import torch.nn as nn
from torch import Tensor

from torchvision.transforms._presets import ImageClassification
from torchvision.utils import _log_api_usage_once
from torchvision.models._api import register_model, Weights, WeightsEnum
from torchvision.models._meta import _IMAGENET_CATEGORIES
from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface

class SElayer(nn.Module):
    def __init__(self, inplanes, reduction=16):
        super(SElayer,self).__init__()
        self.globalAvgpool = nn.AdaptiveAvgPool2d(1)#Squeeze操作
        self.fc1 = nn.Conv2d(inplanes, inplanes // reduction, kernel_size=1, stride=1)
        self.fc2 = nn.Conv2d(inplanes // reduction, inplanes, kernel_size=1, stride=1)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()
    def forward(self,x):
        begin_input = x
        x = self.globalAvgpool(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        
        return x * begin_input
3/11:
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
           
        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                               nn.ReLU(),
                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)
3/12:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

            nn.Dropout(.3, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
3/13:
# model=my_resnet50()
# model
3/14:
# import torch
# import torch.nn as nn
# import math
# import torch.utils.model_zoo as model_zoo


# __all__ = ['ResNet', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam',
#            'resnet152_cbam']


# model_urls = {
#     'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
#     'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
#     'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
#     'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
#     'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
# }


# def conv3x3(in_planes, out_planes, stride=1):
#     "3x3 convolution with padding"
#     return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
#                      padding=1, bias=False)

# class ChannelAttention(nn.Module):
#     def __init__(self, in_planes, ratio=16):
#         super(ChannelAttention, self).__init__()
#         self.avg_pool = nn.AdaptiveAvgPool2d(1)
#         self.max_pool = nn.AdaptiveMaxPool2d(1)
           
#         self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
#                                nn.ReLU(),
#                                nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = self.fc(self.avg_pool(x))
#         max_out = self.fc(self.max_pool(x))
#         out = avg_out + max_out
#         return self.sigmoid(out)

# class SpatialAttention(nn.Module):
#     def __init__(self, kernel_size=7):
#         super(SpatialAttention, self).__init__()

#         self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = torch.mean(x, dim=1, keepdim=True)
#         max_out, _ = torch.max(x, dim=1, keepdim=True)
#         x = torch.cat([avg_out, max_out], dim=1)
#         x = self.conv1(x)
#         return self.sigmoid(x)

# class BasicBlock(nn.Module):
#     expansion = 1

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(BasicBlock, self).__init__()
#         self.conv1 = conv3x3(inplanes, planes, stride)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.relu = nn.ReLU(inplace=True)
#         self.conv2 = conv3x3(planes, planes)
#         self.bn2 = nn.BatchNorm2d(planes)

#         self.ca = ChannelAttention(planes)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class Bottleneck(nn.Module):
#     expansion = 4

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(Bottleneck, self).__init__()
#         self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
#                                padding=1, bias=False)
#         self.bn2 = nn.BatchNorm2d(planes)
#         self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)
#         self.bn3 = nn.BatchNorm2d(planes * 4)
#         self.relu = nn.ReLU(inplace=True)

#         self.ca = ChannelAttention(planes * 4)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)
#         out = self.relu(out)

#         out = self.conv3(out)
#         out = self.bn3(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class ResNet(nn.Module):

#     def __init__(self, block, layers, num_classes=1000):
#         self.inplanes = 64
#         super(ResNet, self).__init__()
#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
#                                bias=False)
#         self.bn1 = nn.BatchNorm2d(64)
#         self.relu = nn.ReLU(inplace=True)
#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
#         self.layer1 = self._make_layer(block, 64, layers[0])
#         self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
#         self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
#         self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
#         self.fc = nn.Linear(512 * block.expansion, num_classes)

#         for m in self.modules():
#             if isinstance(m, nn.Conv2d):
#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
#                 m.weight.data.normal_(0, math.sqrt(2. / n))
#             elif isinstance(m, nn.BatchNorm2d):
#                 m.weight.data.fill_(1)
#                 m.bias.data.zero_()

#     def _make_layer(self, block, planes, blocks, stride=1):
#         downsample = None
#         if stride != 1 or self.inplanes != planes * block.expansion:
#             downsample = nn.Sequential(
#                 nn.Conv2d(self.inplanes, planes * block.expansion,
#                           kernel_size=1, stride=stride, bias=False),
#                 nn.BatchNorm2d(planes * block.expansion),
#             )

#         layers = []
#         layers.append(block(self.inplanes, planes, stride, downsample))
#         self.inplanes = planes * block.expansion
#         for i in range(1, blocks):
#             layers.append(block(self.inplanes, planes))

#         return nn.Sequential(*layers)

#     def forward(self, x):
#         x = self.conv1(x)
#         x = self.bn1(x)
#         x = self.relu(x)
#         x = self.maxpool(x)

#         x = self.layer1(x)
#         x = self.layer2(x)
#         x = self.layer3(x)
#         x = self.layer4(x)

#         x = self.avgpool(x)
#         x = x.view(x.size(0), -1)
#         x = self.fc(x)
#         x = self.classifier_layer(x)

#         return torch.sigmoid(x)


# def resnet18_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-18 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet34_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-34 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet34'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet50_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-50 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet50'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet101_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-101 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet101'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet152_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-152 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet152'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model
3/15:

model=my_resnet50(weights="IMAGENET1K_V2")
3/16:

for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
    
# for name, param in model.named_parameters():
#     if 'classifier' not in name:
#         param.requires_grad = False
#     print(name, param.requires_grad)
3/17:
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True
    
#     import timm
# model = timm.create_model('ecaresnet50d', pretrained=True)
# model.reset_classifier(0)
# # #
# # #model=my_resnext50_32x4d(weights="IMAGENET1K_V2")
# # # model = efficientnet_v2_s(weights='DEFAULT')

# model = nn.Sequential(
#     model,
#     nn.Linear(2048 ,256),
#     nn.Dropout(.3),
# #     nn.BatchNorm1d(256),
#     nn.ReLU(),
#     nn.Linear(256,1),
#     nn.Sigmoid()
# )
# for name, param in model.named_parameters():
#     if (('layer' in name)|('conv' in name))&('se' not in name):
#         param.requires_grad = False
    #print(name, param.requires_grad)
    
# #from torchvision.models import efficientnet_v2_s  
# # model = CNN()
# model=my_resnet50(weights="IMAGENET1K_V2")



model.to(device)

# defining the optimizer
# For Calc Patches
# optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 850, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image masses
# optimizer = torch.optim.NAdam(model.parameters(), lr=8-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1150, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image calfications
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 15*(len(train_dataloader//batch_size), T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=1e-6, max_lr=4e-6,step_size_up = 20, cycle_momentum =False)
# epochs=90
# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr= 4e-5, total_steps=(len(train_dataset)//batch_size)*(epochs+1),pct_start=.3)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)
# scheduler2 = StepLR(optimizer, step_size=1200, gamma=0.15)
# scheduler3 = StepLR(optimizer, step_size=1100, gamma=0.15)
# scheduler4 = StepLR(optimizer, step_size=1200, gamma=0.15)

# # # scheduler2 = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, 2)
# # scheduler4 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,12,20,30], gamma=0.4)
# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2,scheduler3,scheduler4]
#                                                   , milestones=[60,120,180])
#scheduler=None

neg=0
pos=0
# for label in labels:
#     if label==1:
#         pos=pos+1
#     else:
#         neg=neg+1
w_pos = 2
w_neg = 1
print(f"Class weight for negative class: {w_neg}, and for positive {w_pos}")
#criterion = BCELoss_class_weighted(weights = [w_neg, w_pos])
criterion = nn.BCELoss()
# define early stopping
# earlystoper = EarlyStopper(patience = 30)

checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}
test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
print (dataset_sizes)
3/18:
# # optimizer.param_groups[0]['lr']=1e-5
#optimizer = torch.optim.NAdam(model.parameters(), lr=2e-5, weight_decay=.04)

#scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=120)
 4/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
 4/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
 4/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(6),
#     transforms.RandomAffine(degrees=(0,30),translate=(0.0, 0.05),  shear=(.5,.5)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
 4/4:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
 4/5:
batch_size = 6
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=0 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=0)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
 4/6:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="Mass_CBAMresnet50_900x1500_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "CBAMresnet50",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
 4/7:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
 4/8:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
#                 wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
#                          , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
#                 wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
#                          , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
 4/9:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
4/10:
from functools import partial
from typing import Any, Callable, List, Optional, Type, Union

import torch
import torch.nn as nn
from torch import Tensor

from torchvision.transforms._presets import ImageClassification
from torchvision.utils import _log_api_usage_once
from torchvision.models._api import register_model, Weights, WeightsEnum
from torchvision.models._meta import _IMAGENET_CATEGORIES
from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface

class SElayer(nn.Module):
    def __init__(self, inplanes, reduction=16):
        super(SElayer,self).__init__()
        self.globalAvgpool = nn.AdaptiveAvgPool2d(1)#Squeeze操作
        self.fc1 = nn.Conv2d(inplanes, inplanes // reduction, kernel_size=1, stride=1)
        self.fc2 = nn.Conv2d(inplanes // reduction, inplanes, kernel_size=1, stride=1)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()
    def forward(self,x):
        begin_input = x
        x = self.globalAvgpool(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        
        return x * begin_input
4/11:
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
           
        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                               nn.ReLU(),
                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)
4/12:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

            nn.Dropout(.3, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
4/13:

model=my_resnet50(weights="IMAGENET1K_V2")
4/14:

for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
    
# for name, param in model.named_parameters():
#     if 'classifier' not in name:
#         param.requires_grad = False
#     print(name, param.requires_grad)
4/15:
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True
    
#     import timm
# model = timm.create_model('ecaresnet50d', pretrained=True)
# model.reset_classifier(0)
# # #
# # #model=my_resnext50_32x4d(weights="IMAGENET1K_V2")
# # # model = efficientnet_v2_s(weights='DEFAULT')

# model = nn.Sequential(
#     model,
#     nn.Linear(2048 ,256),
#     nn.Dropout(.3),
# #     nn.BatchNorm1d(256),
#     nn.ReLU(),
#     nn.Linear(256,1),
#     nn.Sigmoid()
# )
# for name, param in model.named_parameters():
#     if (('layer' in name)|('conv' in name))&('se' not in name):
#         param.requires_grad = False
    #print(name, param.requires_grad)
    
# #from torchvision.models import efficientnet_v2_s  
# # model = CNN()
# model=my_resnet50(weights="IMAGENET1K_V2")



model.to(device)

# defining the optimizer
# For Calc Patches
# optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 850, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image masses
# optimizer = torch.optim.NAdam(model.parameters(), lr=8-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1150, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image calfications
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 15*(len(train_dataloader//batch_size), T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=1e-6, max_lr=4e-6,step_size_up = 20, cycle_momentum =False)
# epochs=90
# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr= 4e-5, total_steps=(len(train_dataset)//batch_size)*(epochs+1),pct_start=.3)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)
# scheduler2 = StepLR(optimizer, step_size=1200, gamma=0.15)
# scheduler3 = StepLR(optimizer, step_size=1100, gamma=0.15)
# scheduler4 = StepLR(optimizer, step_size=1200, gamma=0.15)

# # # scheduler2 = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, 2)
# # scheduler4 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,12,20,30], gamma=0.4)
# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2,scheduler3,scheduler4]
#                                                   , milestones=[60,120,180])
#scheduler=None

neg=0
pos=0
# for label in labels:
#     if label==1:
#         pos=pos+1
#     else:
#         neg=neg+1
w_pos = 2
w_neg = 1
print(f"Class weight for negative class: {w_neg}, and for positive {w_pos}")
#criterion = BCELoss_class_weighted(weights = [w_neg, w_pos])
criterion = nn.BCELoss()
# define early stopping
# earlystoper = EarlyStopper(patience = 30)

checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}
test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
print (dataset_sizes)
4/16:
# # optimizer.param_groups[0]['lr']=1e-5
#optimizer = torch.optim.NAdam(model.parameters(), lr=2e-5, weight_decay=.04)

#scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=120)
4/17:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                           , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                           , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
4/18:
# # optimizer.param_groups[0]['lr']=1e-5
#optimizer = torch.optim.NAdam(model.parameters(), lr=2e-5, weight_decay=.04)

#scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=200)
4/19:
for name, param in model.named_parameters():
    param.requires_grad = True
    
optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.02) 

scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 800, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
scheduler1 = StepLR(optimizer, step_size=1600, gamma=0.1)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=25)
4/20:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .3)
wandb.finish()
 6/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
 6/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
 6/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.RandomAffine(degrees=(0,30),translate=(0.0, 0.05),  shear=(.5,.5)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
 6/4:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
 6/5:
batch_size = 8
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=8)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=8 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=8)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
 6/6:
rows = 6
cols = 5
plt.subplots(rows, cols, figsize = (30, 30),dpi=100)

batch_imgs, batch_labels = next(iter(train_dataloader))
i = 0
for img in batch_imgs:
    
    if i >= rows*cols:
        break
    plt.subplot(rows, cols, i + 1)
    #plt.figure(figsize=(6,6),dpi=300)
    plt.title("Cancer" if batch_labels[i] == 1 else "No cancer")
    
    plt.imshow(img.permute(1, 2, 0)[:,:,0])

    i += 1

labels_count = np.zeros(2)
for l in batch_labels:
    labels_count[l] += 1 
    
    
print(f'There are {labels_count[0]} negative and {labels_count[1]} positive samples in this batch.')
 6/7:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="Mass_CBAMresnet50_900x1500_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "CBAMresnet50",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
 6/8:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
 6/9:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                           , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                           , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
6/10:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
6/11:
from functools import partial
from typing import Any, Callable, List, Optional, Type, Union

import torch
import torch.nn as nn
from torch import Tensor

from torchvision.transforms._presets import ImageClassification
from torchvision.utils import _log_api_usage_once
from torchvision.models._api import register_model, Weights, WeightsEnum
from torchvision.models._meta import _IMAGENET_CATEGORIES
from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface

class SElayer(nn.Module):
    def __init__(self, inplanes, reduction=16):
        super(SElayer,self).__init__()
        self.globalAvgpool = nn.AdaptiveAvgPool2d(1)#Squeeze操作
        self.fc1 = nn.Conv2d(inplanes, inplanes // reduction, kernel_size=1, stride=1)
        self.fc2 = nn.Conv2d(inplanes // reduction, inplanes, kernel_size=1, stride=1)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()
    def forward(self,x):
        begin_input = x
        x = self.globalAvgpool(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        
        return x * begin_input
6/12:
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
           
        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                               nn.ReLU(),
                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)
6/13:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

#             nn.Dropout(.3, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
6/14:
# model=my_resnet50()
# model
6/15:
# import torch
# import torch.nn as nn
# import math
# import torch.utils.model_zoo as model_zoo


# __all__ = ['ResNet', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam',
#            'resnet152_cbam']


# model_urls = {
#     'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
#     'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
#     'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
#     'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
#     'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
# }


# def conv3x3(in_planes, out_planes, stride=1):
#     "3x3 convolution with padding"
#     return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
#                      padding=1, bias=False)

# class ChannelAttention(nn.Module):
#     def __init__(self, in_planes, ratio=16):
#         super(ChannelAttention, self).__init__()
#         self.avg_pool = nn.AdaptiveAvgPool2d(1)
#         self.max_pool = nn.AdaptiveMaxPool2d(1)
           
#         self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
#                                nn.ReLU(),
#                                nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = self.fc(self.avg_pool(x))
#         max_out = self.fc(self.max_pool(x))
#         out = avg_out + max_out
#         return self.sigmoid(out)

# class SpatialAttention(nn.Module):
#     def __init__(self, kernel_size=7):
#         super(SpatialAttention, self).__init__()

#         self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = torch.mean(x, dim=1, keepdim=True)
#         max_out, _ = torch.max(x, dim=1, keepdim=True)
#         x = torch.cat([avg_out, max_out], dim=1)
#         x = self.conv1(x)
#         return self.sigmoid(x)

# class BasicBlock(nn.Module):
#     expansion = 1

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(BasicBlock, self).__init__()
#         self.conv1 = conv3x3(inplanes, planes, stride)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.relu = nn.ReLU(inplace=True)
#         self.conv2 = conv3x3(planes, planes)
#         self.bn2 = nn.BatchNorm2d(planes)

#         self.ca = ChannelAttention(planes)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class Bottleneck(nn.Module):
#     expansion = 4

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(Bottleneck, self).__init__()
#         self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
#                                padding=1, bias=False)
#         self.bn2 = nn.BatchNorm2d(planes)
#         self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)
#         self.bn3 = nn.BatchNorm2d(planes * 4)
#         self.relu = nn.ReLU(inplace=True)

#         self.ca = ChannelAttention(planes * 4)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)
#         out = self.relu(out)

#         out = self.conv3(out)
#         out = self.bn3(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class ResNet(nn.Module):

#     def __init__(self, block, layers, num_classes=1000):
#         self.inplanes = 64
#         super(ResNet, self).__init__()
#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
#                                bias=False)
#         self.bn1 = nn.BatchNorm2d(64)
#         self.relu = nn.ReLU(inplace=True)
#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
#         self.layer1 = self._make_layer(block, 64, layers[0])
#         self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
#         self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
#         self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
#         self.fc = nn.Linear(512 * block.expansion, num_classes)

#         for m in self.modules():
#             if isinstance(m, nn.Conv2d):
#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
#                 m.weight.data.normal_(0, math.sqrt(2. / n))
#             elif isinstance(m, nn.BatchNorm2d):
#                 m.weight.data.fill_(1)
#                 m.bias.data.zero_()

#     def _make_layer(self, block, planes, blocks, stride=1):
#         downsample = None
#         if stride != 1 or self.inplanes != planes * block.expansion:
#             downsample = nn.Sequential(
#                 nn.Conv2d(self.inplanes, planes * block.expansion,
#                           kernel_size=1, stride=stride, bias=False),
#                 nn.BatchNorm2d(planes * block.expansion),
#             )

#         layers = []
#         layers.append(block(self.inplanes, planes, stride, downsample))
#         self.inplanes = planes * block.expansion
#         for i in range(1, blocks):
#             layers.append(block(self.inplanes, planes))

#         return nn.Sequential(*layers)

#     def forward(self, x):
#         x = self.conv1(x)
#         x = self.bn1(x)
#         x = self.relu(x)
#         x = self.maxpool(x)

#         x = self.layer1(x)
#         x = self.layer2(x)
#         x = self.layer3(x)
#         x = self.layer4(x)

#         x = self.avgpool(x)
#         x = x.view(x.size(0), -1)
#         x = self.fc(x)
#         x = self.classifier_layer(x)

#         return torch.sigmoid(x)


# def resnet18_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-18 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet34_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-34 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet34'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet50_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-50 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet50'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet101_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-101 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet101'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet152_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-152 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet152'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model
6/16:

model=my_resnet50(weights="IMAGENET1K_V2")
6/17:

for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
    
# for name, param in model.named_parameters():
#     if 'classifier' not in name:
#         param.requires_grad = False
#     print(name, param.requires_grad)
6/18:
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True
    
#     import timm
# model = timm.create_model('ecaresnet50d', pretrained=True)
# model.reset_classifier(0)
# # #
# # #model=my_resnext50_32x4d(weights="IMAGENET1K_V2")
# # # model = efficientnet_v2_s(weights='DEFAULT')

# model = nn.Sequential(
#     model,
#     nn.Linear(2048 ,256),
#     nn.Dropout(.3),
# #     nn.BatchNorm1d(256),
#     nn.ReLU(),
#     nn.Linear(256,1),
#     nn.Sigmoid()
# )
# for name, param in model.named_parameters():
#     if (('layer' in name)|('conv' in name))&('se' not in name):
#         param.requires_grad = False
    #print(name, param.requires_grad)
    
# #from torchvision.models import efficientnet_v2_s  
# # model = CNN()
# model=my_resnet50(weights="IMAGENET1K_V2")



model.to(device)

# defining the optimizer
# For Calc Patches
# optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 850, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image masses
# optimizer = torch.optim.NAdam(model.parameters(), lr=8-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1150, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image calfications
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 15*(len(train_dataloader//batch_size), T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=1e-6, max_lr=4e-6,step_size_up = 20, cycle_momentum =False)
# epochs=90
# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr= 4e-5, total_steps=(len(train_dataset)//batch_size)*(epochs+1),pct_start=.3)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)
# scheduler2 = StepLR(optimizer, step_size=1200, gamma=0.15)
# scheduler3 = StepLR(optimizer, step_size=1100, gamma=0.15)
# scheduler4 = StepLR(optimizer, step_size=1200, gamma=0.15)

# # # scheduler2 = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, 2)
# # scheduler4 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,12,20,30], gamma=0.4)
# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2,scheduler3,scheduler4]
#                                                   , milestones=[60,120,180])
#scheduler=None

neg=0
pos=0
# for label in labels:
#     if label==1:
#         pos=pos+1
#     else:
#         neg=neg+1
w_pos = 2
w_neg = 1
print(f"Class weight for negative class: {w_neg}, and for positive {w_pos}")
#criterion = BCELoss_class_weighted(weights = [w_neg, w_pos])
criterion = nn.BCELoss()
# define early stopping
# earlystoper = EarlyStopper(patience = 30)

checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}
test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
print (dataset_sizes)
6/19:
# # optimizer.param_groups[0]['lr']=1e-5
#optimizer = torch.optim.NAdam(model.parameters(), lr=2e-5, weight_decay=.04)

#scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=200)
6/20:
batch_size = 7
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=7)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=7 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=7)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
6/21:
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True
    
#     import timm
# model = timm.create_model('ecaresnet50d', pretrained=True)
# model.reset_classifier(0)
# # #
# # #model=my_resnext50_32x4d(weights="IMAGENET1K_V2")
# # # model = efficientnet_v2_s(weights='DEFAULT')

# model = nn.Sequential(
#     model,
#     nn.Linear(2048 ,256),
#     nn.Dropout(.3),
# #     nn.BatchNorm1d(256),
#     nn.ReLU(),
#     nn.Linear(256,1),
#     nn.Sigmoid()
# )
# for name, param in model.named_parameters():
#     if (('layer' in name)|('conv' in name))&('se' not in name):
#         param.requires_grad = False
    #print(name, param.requires_grad)
    
# #from torchvision.models import efficientnet_v2_s  
# # model = CNN()
# model=my_resnet50(weights="IMAGENET1K_V2")



model.to(device)

# defining the optimizer
# For Calc Patches
# optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 850, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image masses
# optimizer = torch.optim.NAdam(model.parameters(), lr=8-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1150, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image calfications
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 15*(len(train_dataloader//batch_size), T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=1e-6, max_lr=4e-6,step_size_up = 20, cycle_momentum =False)
# epochs=90
# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr= 4e-5, total_steps=(len(train_dataset)//batch_size)*(epochs+1),pct_start=.3)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)
# scheduler2 = StepLR(optimizer, step_size=1200, gamma=0.15)
# scheduler3 = StepLR(optimizer, step_size=1100, gamma=0.15)
# scheduler4 = StepLR(optimizer, step_size=1200, gamma=0.15)

# # # scheduler2 = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, 2)
# # scheduler4 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,12,20,30], gamma=0.4)
# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2,scheduler3,scheduler4]
#                                                   , milestones=[60,120,180])
#scheduler=None

neg=0
pos=0
# for label in labels:
#     if label==1:
#         pos=pos+1
#     else:
#         neg=neg+1
w_pos = 2
w_neg = 1
print(f"Class weight for negative class: {w_neg}, and for positive {w_pos}")
#criterion = BCELoss_class_weighted(weights = [w_neg, w_pos])
criterion = nn.BCELoss()
# define early stopping
# earlystoper = EarlyStopper(patience = 30)

checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}
test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
print (dataset_sizes)
6/22:
# # optimizer.param_groups[0]['lr']=1e-5
#optimizer = torch.optim.NAdam(model.parameters(), lr=2e-5, weight_decay=.04)

#scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=200)
 7/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
 7/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
 7/3: len(filenames_calc)
 7/4:
# count=0
# for i in filenames_calc:
#     if i == np.nan:
#         filenames_calc.pop(count)
#         labels_calc.pop(count)
#     count=count+1

# count=0
# for i in filenames_test_calc:
#     if i == np.nan:
#         filenames_test_calc.pop(count)
#         labels_test_calc.pop(count)
#     count=count+1
 7/5:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.RandomAffine(degrees=(0,30),translate=(0.0, 0.05),  shear=(.5,.5)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
 7/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
 7/7:
# print (val_size, len(labels_test_calc),train_size, len(labels_calc))
# for i in range(len(labels_test_calc)):
#     if labels_test_calc[i] == 1:
#         print (filenames_test_calc[i])
 7/8:
batch_size = 7
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=7)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=7 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=7)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
 7/9:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="Mass_CBAMresnet50_900x1500_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "CBAMresnet50",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
7/10:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
7/11:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                           , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                           , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
7/12:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
7/13:
from functools import partial
from typing import Any, Callable, List, Optional, Type, Union

import torch
import torch.nn as nn
from torch import Tensor

from torchvision.transforms._presets import ImageClassification
from torchvision.utils import _log_api_usage_once
from torchvision.models._api import register_model, Weights, WeightsEnum
from torchvision.models._meta import _IMAGENET_CATEGORIES
from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface

class SElayer(nn.Module):
    def __init__(self, inplanes, reduction=16):
        super(SElayer,self).__init__()
        self.globalAvgpool = nn.AdaptiveAvgPool2d(1)#Squeeze操作
        self.fc1 = nn.Conv2d(inplanes, inplanes // reduction, kernel_size=1, stride=1)
        self.fc2 = nn.Conv2d(inplanes // reduction, inplanes, kernel_size=1, stride=1)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()
    def forward(self,x):
        begin_input = x
        x = self.globalAvgpool(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        
        return x * begin_input
7/14:
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
           
        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                               nn.ReLU(),
                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)
7/15:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

#             nn.Dropout(.3, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
7/16:
# model=my_resnet50()
# model
7/17:
# import torch
# import torch.nn as nn
# import math
# import torch.utils.model_zoo as model_zoo


# __all__ = ['ResNet', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam',
#            'resnet152_cbam']


# model_urls = {
#     'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
#     'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
#     'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
#     'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
#     'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
# }


# def conv3x3(in_planes, out_planes, stride=1):
#     "3x3 convolution with padding"
#     return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
#                      padding=1, bias=False)

# class ChannelAttention(nn.Module):
#     def __init__(self, in_planes, ratio=16):
#         super(ChannelAttention, self).__init__()
#         self.avg_pool = nn.AdaptiveAvgPool2d(1)
#         self.max_pool = nn.AdaptiveMaxPool2d(1)
           
#         self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
#                                nn.ReLU(),
#                                nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = self.fc(self.avg_pool(x))
#         max_out = self.fc(self.max_pool(x))
#         out = avg_out + max_out
#         return self.sigmoid(out)

# class SpatialAttention(nn.Module):
#     def __init__(self, kernel_size=7):
#         super(SpatialAttention, self).__init__()

#         self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = torch.mean(x, dim=1, keepdim=True)
#         max_out, _ = torch.max(x, dim=1, keepdim=True)
#         x = torch.cat([avg_out, max_out], dim=1)
#         x = self.conv1(x)
#         return self.sigmoid(x)

# class BasicBlock(nn.Module):
#     expansion = 1

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(BasicBlock, self).__init__()
#         self.conv1 = conv3x3(inplanes, planes, stride)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.relu = nn.ReLU(inplace=True)
#         self.conv2 = conv3x3(planes, planes)
#         self.bn2 = nn.BatchNorm2d(planes)

#         self.ca = ChannelAttention(planes)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class Bottleneck(nn.Module):
#     expansion = 4

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(Bottleneck, self).__init__()
#         self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
#                                padding=1, bias=False)
#         self.bn2 = nn.BatchNorm2d(planes)
#         self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)
#         self.bn3 = nn.BatchNorm2d(planes * 4)
#         self.relu = nn.ReLU(inplace=True)

#         self.ca = ChannelAttention(planes * 4)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)
#         out = self.relu(out)

#         out = self.conv3(out)
#         out = self.bn3(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class ResNet(nn.Module):

#     def __init__(self, block, layers, num_classes=1000):
#         self.inplanes = 64
#         super(ResNet, self).__init__()
#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
#                                bias=False)
#         self.bn1 = nn.BatchNorm2d(64)
#         self.relu = nn.ReLU(inplace=True)
#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
#         self.layer1 = self._make_layer(block, 64, layers[0])
#         self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
#         self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
#         self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
#         self.fc = nn.Linear(512 * block.expansion, num_classes)

#         for m in self.modules():
#             if isinstance(m, nn.Conv2d):
#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
#                 m.weight.data.normal_(0, math.sqrt(2. / n))
#             elif isinstance(m, nn.BatchNorm2d):
#                 m.weight.data.fill_(1)
#                 m.bias.data.zero_()

#     def _make_layer(self, block, planes, blocks, stride=1):
#         downsample = None
#         if stride != 1 or self.inplanes != planes * block.expansion:
#             downsample = nn.Sequential(
#                 nn.Conv2d(self.inplanes, planes * block.expansion,
#                           kernel_size=1, stride=stride, bias=False),
#                 nn.BatchNorm2d(planes * block.expansion),
#             )

#         layers = []
#         layers.append(block(self.inplanes, planes, stride, downsample))
#         self.inplanes = planes * block.expansion
#         for i in range(1, blocks):
#             layers.append(block(self.inplanes, planes))

#         return nn.Sequential(*layers)

#     def forward(self, x):
#         x = self.conv1(x)
#         x = self.bn1(x)
#         x = self.relu(x)
#         x = self.maxpool(x)

#         x = self.layer1(x)
#         x = self.layer2(x)
#         x = self.layer3(x)
#         x = self.layer4(x)

#         x = self.avgpool(x)
#         x = x.view(x.size(0), -1)
#         x = self.fc(x)
#         x = self.classifier_layer(x)

#         return torch.sigmoid(x)


# def resnet18_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-18 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet34_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-34 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet34'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet50_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-50 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet50'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet101_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-101 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet101'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet152_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-152 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet152'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model
7/18:

model=my_resnet50(weights="IMAGENET1K_V2")
7/19:

for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
    
# for name, param in model.named_parameters():
#     if 'classifier' not in name:
#         param.requires_grad = False
#     print(name, param.requires_grad)
7/20: model
7/21:
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True
    
#     import timm
# model = timm.create_model('ecaresnet50d', pretrained=True)
# model.reset_classifier(0)
# # #
# # #model=my_resnext50_32x4d(weights="IMAGENET1K_V2")
# # # model = efficientnet_v2_s(weights='DEFAULT')

# model = nn.Sequential(
#     model,
#     nn.Linear(2048 ,256),
#     nn.Dropout(.3),
# #     nn.BatchNorm1d(256),
#     nn.ReLU(),
#     nn.Linear(256,1),
#     nn.Sigmoid()
# )
# for name, param in model.named_parameters():
#     if (('layer' in name)|('conv' in name))&('se' not in name):
#         param.requires_grad = False
    #print(name, param.requires_grad)
    
# #from torchvision.models import efficientnet_v2_s  
# # model = CNN()
# model=my_resnet50(weights="IMAGENET1K_V2")



model.to(device)

# defining the optimizer
# For Calc Patches
# optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 850, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image masses
# optimizer = torch.optim.NAdam(model.parameters(), lr=8-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1150, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image calfications
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 15*(len(train_dataloader//batch_size), T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=1e-6, max_lr=4e-6,step_size_up = 20, cycle_momentum =False)
# epochs=90
# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr= 4e-5, total_steps=(len(train_dataset)//batch_size)*(epochs+1),pct_start=.3)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)
# scheduler2 = StepLR(optimizer, step_size=1200, gamma=0.15)
# scheduler3 = StepLR(optimizer, step_size=1100, gamma=0.15)
# scheduler4 = StepLR(optimizer, step_size=1200, gamma=0.15)

# # # scheduler2 = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, 2)
# # scheduler4 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,12,20,30], gamma=0.4)
# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2,scheduler3,scheduler4]
#                                                   , milestones=[60,120,180])
#scheduler=None

neg=0
pos=0
# for label in labels:
#     if label==1:
#         pos=pos+1
#     else:
#         neg=neg+1
w_pos = 2
w_neg = 1
print(f"Class weight for negative class: {w_neg}, and for positive {w_pos}")
#criterion = BCELoss_class_weighted(weights = [w_neg, w_pos])
criterion = nn.BCELoss()
# define early stopping
# earlystoper = EarlyStopper(patience = 30)

checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}
test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
print (dataset_sizes)
7/22:
# # optimizer.param_groups[0]['lr']=1e-5
#optimizer = torch.optim.NAdam(model.parameters(), lr=2e-5, weight_decay=.04)

#scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=200)
 8/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
 8/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
 8/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.RandomAffine(degrees=(0,30),translate=(0.0, 0.05),  shear=(.5,.5)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
 8/4:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
 8/5:
batch_size = 6
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=6)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=6 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=6)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
 8/6:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="Mass_CBAMresnet50_900x1500_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "CBAMresnet50",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
 8/7:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
 8/8:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                           , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                           , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
 8/9:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
8/10:
from functools import partial
from typing import Any, Callable, List, Optional, Type, Union

import torch
import torch.nn as nn
from torch import Tensor

from torchvision.transforms._presets import ImageClassification
from torchvision.utils import _log_api_usage_once
from torchvision.models._api import register_model, Weights, WeightsEnum
from torchvision.models._meta import _IMAGENET_CATEGORIES
from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface

class SElayer(nn.Module):
    def __init__(self, inplanes, reduction=16):
        super(SElayer,self).__init__()
        self.globalAvgpool = nn.AdaptiveAvgPool2d(1)#Squeeze操作
        self.fc1 = nn.Conv2d(inplanes, inplanes // reduction, kernel_size=1, stride=1)
        self.fc2 = nn.Conv2d(inplanes // reduction, inplanes, kernel_size=1, stride=1)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()
    def forward(self,x):
        begin_input = x
        x = self.globalAvgpool(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        
        return x * begin_input
8/11:
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
           
        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                               nn.ReLU(),
                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)
8/12:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

#             nn.Dropout(.3, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
8/13:
# model=my_resnet50()
# model
8/14:
# import torch
# import torch.nn as nn
# import math
# import torch.utils.model_zoo as model_zoo


# __all__ = ['ResNet', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam',
#            'resnet152_cbam']


# model_urls = {
#     'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
#     'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
#     'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
#     'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
#     'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
# }


# def conv3x3(in_planes, out_planes, stride=1):
#     "3x3 convolution with padding"
#     return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
#                      padding=1, bias=False)

# class ChannelAttention(nn.Module):
#     def __init__(self, in_planes, ratio=16):
#         super(ChannelAttention, self).__init__()
#         self.avg_pool = nn.AdaptiveAvgPool2d(1)
#         self.max_pool = nn.AdaptiveMaxPool2d(1)
           
#         self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
#                                nn.ReLU(),
#                                nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = self.fc(self.avg_pool(x))
#         max_out = self.fc(self.max_pool(x))
#         out = avg_out + max_out
#         return self.sigmoid(out)

# class SpatialAttention(nn.Module):
#     def __init__(self, kernel_size=7):
#         super(SpatialAttention, self).__init__()

#         self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = torch.mean(x, dim=1, keepdim=True)
#         max_out, _ = torch.max(x, dim=1, keepdim=True)
#         x = torch.cat([avg_out, max_out], dim=1)
#         x = self.conv1(x)
#         return self.sigmoid(x)

# class BasicBlock(nn.Module):
#     expansion = 1

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(BasicBlock, self).__init__()
#         self.conv1 = conv3x3(inplanes, planes, stride)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.relu = nn.ReLU(inplace=True)
#         self.conv2 = conv3x3(planes, planes)
#         self.bn2 = nn.BatchNorm2d(planes)

#         self.ca = ChannelAttention(planes)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class Bottleneck(nn.Module):
#     expansion = 4

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(Bottleneck, self).__init__()
#         self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
#                                padding=1, bias=False)
#         self.bn2 = nn.BatchNorm2d(planes)
#         self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)
#         self.bn3 = nn.BatchNorm2d(planes * 4)
#         self.relu = nn.ReLU(inplace=True)

#         self.ca = ChannelAttention(planes * 4)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)
#         out = self.relu(out)

#         out = self.conv3(out)
#         out = self.bn3(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class ResNet(nn.Module):

#     def __init__(self, block, layers, num_classes=1000):
#         self.inplanes = 64
#         super(ResNet, self).__init__()
#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
#                                bias=False)
#         self.bn1 = nn.BatchNorm2d(64)
#         self.relu = nn.ReLU(inplace=True)
#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
#         self.layer1 = self._make_layer(block, 64, layers[0])
#         self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
#         self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
#         self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
#         self.fc = nn.Linear(512 * block.expansion, num_classes)

#         for m in self.modules():
#             if isinstance(m, nn.Conv2d):
#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
#                 m.weight.data.normal_(0, math.sqrt(2. / n))
#             elif isinstance(m, nn.BatchNorm2d):
#                 m.weight.data.fill_(1)
#                 m.bias.data.zero_()

#     def _make_layer(self, block, planes, blocks, stride=1):
#         downsample = None
#         if stride != 1 or self.inplanes != planes * block.expansion:
#             downsample = nn.Sequential(
#                 nn.Conv2d(self.inplanes, planes * block.expansion,
#                           kernel_size=1, stride=stride, bias=False),
#                 nn.BatchNorm2d(planes * block.expansion),
#             )

#         layers = []
#         layers.append(block(self.inplanes, planes, stride, downsample))
#         self.inplanes = planes * block.expansion
#         for i in range(1, blocks):
#             layers.append(block(self.inplanes, planes))

#         return nn.Sequential(*layers)

#     def forward(self, x):
#         x = self.conv1(x)
#         x = self.bn1(x)
#         x = self.relu(x)
#         x = self.maxpool(x)

#         x = self.layer1(x)
#         x = self.layer2(x)
#         x = self.layer3(x)
#         x = self.layer4(x)

#         x = self.avgpool(x)
#         x = x.view(x.size(0), -1)
#         x = self.fc(x)
#         x = self.classifier_layer(x)

#         return torch.sigmoid(x)


# def resnet18_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-18 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet34_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-34 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet34'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet50_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-50 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet50'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet101_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-101 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet101'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet152_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-152 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet152'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model
8/15:

model=my_resnet50(weights="IMAGENET1K_V2")
8/16:

for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
    
# for name, param in model.named_parameters():
#     if 'classifier' not in name:
#         param.requires_grad = False
#     print(name, param.requires_grad)
8/17: model
8/18:
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True
    
#     import timm
# model = timm.create_model('ecaresnet50d', pretrained=True)
# model.reset_classifier(0)
# # #
# # #model=my_resnext50_32x4d(weights="IMAGENET1K_V2")
# # # model = efficientnet_v2_s(weights='DEFAULT')

# model = nn.Sequential(
#     model,
#     nn.Linear(2048 ,256),
#     nn.Dropout(.3),
# #     nn.BatchNorm1d(256),
#     nn.ReLU(),
#     nn.Linear(256,1),
#     nn.Sigmoid()
# )
# for name, param in model.named_parameters():
#     if (('layer' in name)|('conv' in name))&('se' not in name):
#         param.requires_grad = False
    #print(name, param.requires_grad)
    
# #from torchvision.models import efficientnet_v2_s  
# # model = CNN()
# model=my_resnet50(weights="IMAGENET1K_V2")



model.to(device)

# defining the optimizer
# For Calc Patches
# optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 850, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image masses
# optimizer = torch.optim.NAdam(model.parameters(), lr=8-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1150, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image calfications
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 15*(len(train_dataloader//batch_size), T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=1e-6, max_lr=4e-6,step_size_up = 20, cycle_momentum =False)
# epochs=90
# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr= 4e-5, total_steps=(len(train_dataset)//batch_size)*(epochs+1),pct_start=.3)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)
# scheduler2 = StepLR(optimizer, step_size=1200, gamma=0.15)
# scheduler3 = StepLR(optimizer, step_size=1100, gamma=0.15)
# scheduler4 = StepLR(optimizer, step_size=1200, gamma=0.15)

# # # scheduler2 = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, 2)
# # scheduler4 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,12,20,30], gamma=0.4)
# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2,scheduler3,scheduler4]
#                                                   , milestones=[60,120,180])
#scheduler=None

neg=0
pos=0
# for label in labels:
#     if label==1:
#         pos=pos+1
#     else:
#         neg=neg+1
w_pos = 2
w_neg = 1
print(f"Class weight for negative class: {w_neg}, and for positive {w_pos}")
#criterion = BCELoss_class_weighted(weights = [w_neg, w_pos])
criterion = nn.BCELoss()
# define early stopping
# earlystoper = EarlyStopper(patience = 30)

checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}
test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
print (dataset_sizes)
8/19:
# # optimizer.param_groups[0]['lr']=1e-5
#optimizer = torch.optim.NAdam(model.parameters(), lr=2e-5, weight_decay=.04)

#scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=200)
 9/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
 9/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
 9/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.RandomAffine(degrees=(0,30),translate=(0.0, 0.05),  shear=(.5,.5)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
 9/4:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
 9/5:
# print (val_size, len(labels_test_calc),train_size, len(labels_calc))
# for i in range(len(labels_test_calc)):
#     if labels_test_calc[i] == 1:
#         print (filenames_test_calc[i])
 9/6:
batch_size = 6
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=6)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=6 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=6)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
 9/7:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="Mass_CBAMresnet50_900x1500_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "CBAMresnet50",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
 9/8:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
 9/9:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                           , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                           , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
9/10:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
9/11:
from functools import partial
from typing import Any, Callable, List, Optional, Type, Union

import torch
import torch.nn as nn
from torch import Tensor

from torchvision.transforms._presets import ImageClassification
from torchvision.utils import _log_api_usage_once
from torchvision.models._api import register_model, Weights, WeightsEnum
from torchvision.models._meta import _IMAGENET_CATEGORIES
from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface

class SElayer(nn.Module):
    def __init__(self, inplanes, reduction=16):
        super(SElayer,self).__init__()
        self.globalAvgpool = nn.AdaptiveAvgPool2d(1)#Squeeze操作
        self.fc1 = nn.Conv2d(inplanes, inplanes // reduction, kernel_size=1, stride=1)
        self.fc2 = nn.Conv2d(inplanes // reduction, inplanes, kernel_size=1, stride=1)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()
    def forward(self,x):
        begin_input = x
        x = self.globalAvgpool(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        
        return x * begin_input
9/12:
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
           
        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                               nn.ReLU(),
                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)
9/13:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

#             nn.Dropout(.3, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
9/14:
# model=my_resnet50()
# model
9/15:
# import torch
# import torch.nn as nn
# import math
# import torch.utils.model_zoo as model_zoo


# __all__ = ['ResNet', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam',
#            'resnet152_cbam']


# model_urls = {
#     'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
#     'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
#     'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
#     'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
#     'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
# }


# def conv3x3(in_planes, out_planes, stride=1):
#     "3x3 convolution with padding"
#     return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
#                      padding=1, bias=False)

# class ChannelAttention(nn.Module):
#     def __init__(self, in_planes, ratio=16):
#         super(ChannelAttention, self).__init__()
#         self.avg_pool = nn.AdaptiveAvgPool2d(1)
#         self.max_pool = nn.AdaptiveMaxPool2d(1)
           
#         self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
#                                nn.ReLU(),
#                                nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = self.fc(self.avg_pool(x))
#         max_out = self.fc(self.max_pool(x))
#         out = avg_out + max_out
#         return self.sigmoid(out)

# class SpatialAttention(nn.Module):
#     def __init__(self, kernel_size=7):
#         super(SpatialAttention, self).__init__()

#         self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = torch.mean(x, dim=1, keepdim=True)
#         max_out, _ = torch.max(x, dim=1, keepdim=True)
#         x = torch.cat([avg_out, max_out], dim=1)
#         x = self.conv1(x)
#         return self.sigmoid(x)

# class BasicBlock(nn.Module):
#     expansion = 1

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(BasicBlock, self).__init__()
#         self.conv1 = conv3x3(inplanes, planes, stride)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.relu = nn.ReLU(inplace=True)
#         self.conv2 = conv3x3(planes, planes)
#         self.bn2 = nn.BatchNorm2d(planes)

#         self.ca = ChannelAttention(planes)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class Bottleneck(nn.Module):
#     expansion = 4

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(Bottleneck, self).__init__()
#         self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
#                                padding=1, bias=False)
#         self.bn2 = nn.BatchNorm2d(planes)
#         self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)
#         self.bn3 = nn.BatchNorm2d(planes * 4)
#         self.relu = nn.ReLU(inplace=True)

#         self.ca = ChannelAttention(planes * 4)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)
#         out = self.relu(out)

#         out = self.conv3(out)
#         out = self.bn3(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class ResNet(nn.Module):

#     def __init__(self, block, layers, num_classes=1000):
#         self.inplanes = 64
#         super(ResNet, self).__init__()
#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
#                                bias=False)
#         self.bn1 = nn.BatchNorm2d(64)
#         self.relu = nn.ReLU(inplace=True)
#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
#         self.layer1 = self._make_layer(block, 64, layers[0])
#         self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
#         self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
#         self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
#         self.fc = nn.Linear(512 * block.expansion, num_classes)

#         for m in self.modules():
#             if isinstance(m, nn.Conv2d):
#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
#                 m.weight.data.normal_(0, math.sqrt(2. / n))
#             elif isinstance(m, nn.BatchNorm2d):
#                 m.weight.data.fill_(1)
#                 m.bias.data.zero_()

#     def _make_layer(self, block, planes, blocks, stride=1):
#         downsample = None
#         if stride != 1 or self.inplanes != planes * block.expansion:
#             downsample = nn.Sequential(
#                 nn.Conv2d(self.inplanes, planes * block.expansion,
#                           kernel_size=1, stride=stride, bias=False),
#                 nn.BatchNorm2d(planes * block.expansion),
#             )

#         layers = []
#         layers.append(block(self.inplanes, planes, stride, downsample))
#         self.inplanes = planes * block.expansion
#         for i in range(1, blocks):
#             layers.append(block(self.inplanes, planes))

#         return nn.Sequential(*layers)

#     def forward(self, x):
#         x = self.conv1(x)
#         x = self.bn1(x)
#         x = self.relu(x)
#         x = self.maxpool(x)

#         x = self.layer1(x)
#         x = self.layer2(x)
#         x = self.layer3(x)
#         x = self.layer4(x)

#         x = self.avgpool(x)
#         x = x.view(x.size(0), -1)
#         x = self.fc(x)
#         x = self.classifier_layer(x)

#         return torch.sigmoid(x)


# def resnet18_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-18 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet34_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-34 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet34'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet50_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-50 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet50'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet101_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-101 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet101'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet152_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-152 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet152'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model
9/16:

model=my_resnet50(weights="IMAGENET1K_V2")
9/17:

for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
    
# for name, param in model.named_parameters():
#     if 'classifier' not in name:
#         param.requires_grad = False
#     print(name, param.requires_grad)
9/18: model
9/19:
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True
    
#     import timm
# model = timm.create_model('ecaresnet50d', pretrained=True)
# model.reset_classifier(0)
# # #
# # #model=my_resnext50_32x4d(weights="IMAGENET1K_V2")
# # # model = efficientnet_v2_s(weights='DEFAULT')

# model = nn.Sequential(
#     model,
#     nn.Linear(2048 ,256),
#     nn.Dropout(.3),
# #     nn.BatchNorm1d(256),
#     nn.ReLU(),
#     nn.Linear(256,1),
#     nn.Sigmoid()
# )
# for name, param in model.named_parameters():
#     if (('layer' in name)|('conv' in name))&('se' not in name):
#         param.requires_grad = False
    #print(name, param.requires_grad)
    
# #from torchvision.models import efficientnet_v2_s  
# # model = CNN()
# model=my_resnet50(weights="IMAGENET1K_V2")



model.to(device)

# defining the optimizer
# For Calc Patches
# optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 850, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image masses
# optimizer = torch.optim.NAdam(model.parameters(), lr=8-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1150, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image calfications
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 15*(len(train_dataloader//batch_size), T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

optimizer = torch.optim.NAdam(model.parameters(), lr=1e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=1e-6, max_lr=4e-6,step_size_up = 20, cycle_momentum =False)
# epochs=90
# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr= 4e-5, total_steps=(len(train_dataset)//batch_size)*(epochs+1),pct_start=.3)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)
# scheduler2 = StepLR(optimizer, step_size=1200, gamma=0.15)
# scheduler3 = StepLR(optimizer, step_size=1100, gamma=0.15)
# scheduler4 = StepLR(optimizer, step_size=1200, gamma=0.15)

# # # scheduler2 = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, 2)
# # scheduler4 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,12,20,30], gamma=0.4)
# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2,scheduler3,scheduler4]
#                                                   , milestones=[60,120,180])
#scheduler=None

neg=0
pos=0
# for label in labels:
#     if label==1:
#         pos=pos+1
#     else:
#         neg=neg+1
w_pos = 2
w_neg = 1
print(f"Class weight for negative class: {w_neg}, and for positive {w_pos}")
#criterion = BCELoss_class_weighted(weights = [w_neg, w_pos])
criterion = nn.BCELoss()
# define early stopping
# earlystoper = EarlyStopper(patience = 30)

checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}
test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
print (dataset_sizes)
9/20:
# # optimizer.param_groups[0]['lr']=1e-5
#optimizer = torch.optim.NAdam(model.parameters(), lr=2e-5, weight_decay=.04)

#scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=200)
9/21:
for name, param in model.named_parameters():
    param.requires_grad = True
    
optimizer = torch.optim.NAdam(model.parameters(), lr=8e-6, weight_decay=.02) 

scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 800, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
scheduler1 = StepLR(optimizer, step_size=1600, gamma=0.1)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=75)
10/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/600x1000_v1_lightclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
10/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
10/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
    transforms.RandomAffine(degrees=(0,5),translate=(0.0, 0.05),  shear=(.2,.2)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
10/4:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
10/5:
batch_size = 12
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
10/6:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/600x1000_v1_lightclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
10/7:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
10/8:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
    transforms.RandomAffine(degrees=(0,5),translate=(0.0, 0.05),  shear=(.2,.2)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
10/9:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
10/10:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
10/11:
batch_size = 12
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
10/12:
rows = 3
cols = 5
plt.subplots(rows, cols, figsize = (30, 30),dpi=100)

batch_imgs, batch_labels = next(iter(train_dataloader))
i = 0
for img in batch_imgs:
    
    if i >= rows*cols:
        break
    plt.subplot(rows, cols, i + 1)
    #plt.figure(figsize=(6,6),dpi=300)
    plt.title("Cancer" if batch_labels[i] == 1 else "No cancer")
    
    plt.imshow(img.permute(1, 2, 0)[:,:,0])

    i += 1

labels_count = np.zeros(2)
for l in batch_labels:
    labels_count[l] += 1 
    
    
print(f'There are {labels_count[0]} negative and {labels_count[1]} positive samples in this batch.')
10/13:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="Mass_CBAMresnet50_600x1000_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "CBAMresnet50",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
10/14:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
10/15:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                           , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                           , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
10/16:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
10/17:
from functools import partial
from typing import Any, Callable, List, Optional, Type, Union

import torch
import torch.nn as nn
from torch import Tensor

from torchvision.transforms._presets import ImageClassification
from torchvision.utils import _log_api_usage_once
from torchvision.models._api import register_model, Weights, WeightsEnum
from torchvision.models._meta import _IMAGENET_CATEGORIES
from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface

class SElayer(nn.Module):
    def __init__(self, inplanes, reduction=16):
        super(SElayer,self).__init__()
        self.globalAvgpool = nn.AdaptiveAvgPool2d(1)#Squeeze操作
        self.fc1 = nn.Conv2d(inplanes, inplanes // reduction, kernel_size=1, stride=1)
        self.fc2 = nn.Conv2d(inplanes // reduction, inplanes, kernel_size=1, stride=1)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()
    def forward(self,x):
        begin_input = x
        x = self.globalAvgpool(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        
        return x * begin_input
10/18:
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
           
        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                               nn.ReLU(),
                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)
10/19:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

#             nn.Dropout(.3, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.2,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
10/20:

model=my_resnet50(weights="IMAGENET1K_V2")
10/21:

for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
    
# for name, param in model.named_parameters():
#     if 'classifier' not in name:
#         param.requires_grad = False
#     print(name, param.requires_grad)
10/22:
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True
    
#     import timm
# model = timm.create_model('ecaresnet50d', pretrained=True)
# model.reset_classifier(0)
# # #
# # #model=my_resnext50_32x4d(weights="IMAGENET1K_V2")
# # # model = efficientnet_v2_s(weights='DEFAULT')

# model = nn.Sequential(
#     model,
#     nn.Linear(2048 ,256),
#     nn.Dropout(.3),
# #     nn.BatchNorm1d(256),
#     nn.ReLU(),
#     nn.Linear(256,1),
#     nn.Sigmoid()
# )
# for name, param in model.named_parameters():
#     if (('layer' in name)|('conv' in name))&('se' not in name):
#         param.requires_grad = False
    #print(name, param.requires_grad)
    
# #from torchvision.models import efficientnet_v2_s  
# # model = CNN()
# model=my_resnet50(weights="IMAGENET1K_V2")



model.to(device)

# defining the optimizer
# For Calc Patches
# optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 850, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image masses
# optimizer = torch.optim.NAdam(model.parameters(), lr=8-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1150, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image calfications
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 15*(len(train_dataloader//batch_size), T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

optimizer = torch.optim.NAdam(model.parameters(), lr=3e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=1e-6, max_lr=4e-6,step_size_up = 20, cycle_momentum =False)
# epochs=90
# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr= 4e-5, total_steps=(len(train_dataset)//batch_size)*(epochs+1),pct_start=.3)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)
# scheduler2 = StepLR(optimizer, step_size=1200, gamma=0.15)
# scheduler3 = StepLR(optimizer, step_size=1100, gamma=0.15)
# scheduler4 = StepLR(optimizer, step_size=1200, gamma=0.15)

# # # scheduler2 = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, 2)
# # scheduler4 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,12,20,30], gamma=0.4)
# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2,scheduler3,scheduler4]
#                                                   , milestones=[60,120,180])
#scheduler=None

neg=0
pos=0
# for label in labels:
#     if label==1:
#         pos=pos+1
#     else:
#         neg=neg+1
w_pos = 2
w_neg = 1
print(f"Class weight for negative class: {w_neg}, and for positive {w_pos}")
#criterion = BCELoss_class_weighted(weights = [w_neg, w_pos])
criterion = nn.BCELoss()
# define early stopping
# earlystoper = EarlyStopper(patience = 30)

checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}
test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
print (dataset_sizes)
10/23:
# # optimizer.param_groups[0]['lr']=1e-5
#optimizer = torch.optim.NAdam(model.parameters(), lr=2e-5, weight_decay=.04)

#scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=200)
10/24:
for name, param in model.named_parameters():
    param.requires_grad = True
    
optimizer = torch.optim.NAdam(model.parameters(), lr=8e-6, weight_decay=.02) 

scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 800, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
scheduler1 = StepLR(optimizer, step_size=1600, gamma=0.1)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=75)
10/25:
# for name, param in model.named_parameters():
#     param.requires_grad = True
    
for name, param in model.named_parameters():
    if 'classifier' not in name:
        param.requires_grad = False
    
optimizer = torch.optim.NAdam(model.parameters(), lr=2e-6, weight_decay=.1) 

scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 800, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
scheduler1 = StepLR(optimizer, step_size=1600, gamma=0.1)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=75)
10/26:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .3)
wandb.finish()
11/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/600x1000_v1_lightclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
11/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
11/3: len(filenames_calc)
11/4:
# count=0
# for i in filenames_calc:
#     if i == np.nan:
#         filenames_calc.pop(count)
#         labels_calc.pop(count)
#     count=count+1

# count=0
# for i in filenames_test_calc:
#     if i == np.nan:
#         filenames_test_calc.pop(count)
#         labels_test_calc.pop(count)
#     count=count+1
11/5:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.RandomAffine(degrees=(0,5),translate=(0.0, 0.05),  shear=(.2,.2)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
11/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
11/7:
batch_size = 14
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=14)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=14 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=14)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
11/8:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="Mass_CBAMresnet50_600x1000_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "CBAMresnet50",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
11/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
11/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                           , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                           , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
11/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
11/12:
from functools import partial
from typing import Any, Callable, List, Optional, Type, Union

import torch
import torch.nn as nn
from torch import Tensor

from torchvision.transforms._presets import ImageClassification
from torchvision.utils import _log_api_usage_once
from torchvision.models._api import register_model, Weights, WeightsEnum
from torchvision.models._meta import _IMAGENET_CATEGORIES
from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface

class SElayer(nn.Module):
    def __init__(self, inplanes, reduction=16):
        super(SElayer,self).__init__()
        self.globalAvgpool = nn.AdaptiveAvgPool2d(1)#Squeeze操作
        self.fc1 = nn.Conv2d(inplanes, inplanes // reduction, kernel_size=1, stride=1)
        self.fc2 = nn.Conv2d(inplanes // reduction, inplanes, kernel_size=1, stride=1)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()
    def forward(self,x):
        begin_input = x
        x = self.globalAvgpool(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        
        return x * begin_input
11/13:
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
           
        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                               nn.ReLU(),
                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)
11/14:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

            nn.Dropout(.2, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
11/15:
# model=my_resnet50()
# model
11/16:
# import torch
# import torch.nn as nn
# import math
# import torch.utils.model_zoo as model_zoo


# __all__ = ['ResNet', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam',
#            'resnet152_cbam']


# model_urls = {
#     'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
#     'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
#     'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
#     'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
#     'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
# }


# def conv3x3(in_planes, out_planes, stride=1):
#     "3x3 convolution with padding"
#     return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
#                      padding=1, bias=False)

# class ChannelAttention(nn.Module):
#     def __init__(self, in_planes, ratio=16):
#         super(ChannelAttention, self).__init__()
#         self.avg_pool = nn.AdaptiveAvgPool2d(1)
#         self.max_pool = nn.AdaptiveMaxPool2d(1)
           
#         self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
#                                nn.ReLU(),
#                                nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = self.fc(self.avg_pool(x))
#         max_out = self.fc(self.max_pool(x))
#         out = avg_out + max_out
#         return self.sigmoid(out)

# class SpatialAttention(nn.Module):
#     def __init__(self, kernel_size=7):
#         super(SpatialAttention, self).__init__()

#         self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = torch.mean(x, dim=1, keepdim=True)
#         max_out, _ = torch.max(x, dim=1, keepdim=True)
#         x = torch.cat([avg_out, max_out], dim=1)
#         x = self.conv1(x)
#         return self.sigmoid(x)

# class BasicBlock(nn.Module):
#     expansion = 1

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(BasicBlock, self).__init__()
#         self.conv1 = conv3x3(inplanes, planes, stride)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.relu = nn.ReLU(inplace=True)
#         self.conv2 = conv3x3(planes, planes)
#         self.bn2 = nn.BatchNorm2d(planes)

#         self.ca = ChannelAttention(planes)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class Bottleneck(nn.Module):
#     expansion = 4

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(Bottleneck, self).__init__()
#         self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
#                                padding=1, bias=False)
#         self.bn2 = nn.BatchNorm2d(planes)
#         self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)
#         self.bn3 = nn.BatchNorm2d(planes * 4)
#         self.relu = nn.ReLU(inplace=True)

#         self.ca = ChannelAttention(planes * 4)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)
#         out = self.relu(out)

#         out = self.conv3(out)
#         out = self.bn3(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class ResNet(nn.Module):

#     def __init__(self, block, layers, num_classes=1000):
#         self.inplanes = 64
#         super(ResNet, self).__init__()
#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
#                                bias=False)
#         self.bn1 = nn.BatchNorm2d(64)
#         self.relu = nn.ReLU(inplace=True)
#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
#         self.layer1 = self._make_layer(block, 64, layers[0])
#         self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
#         self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
#         self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
#         self.fc = nn.Linear(512 * block.expansion, num_classes)

#         for m in self.modules():
#             if isinstance(m, nn.Conv2d):
#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
#                 m.weight.data.normal_(0, math.sqrt(2. / n))
#             elif isinstance(m, nn.BatchNorm2d):
#                 m.weight.data.fill_(1)
#                 m.bias.data.zero_()

#     def _make_layer(self, block, planes, blocks, stride=1):
#         downsample = None
#         if stride != 1 or self.inplanes != planes * block.expansion:
#             downsample = nn.Sequential(
#                 nn.Conv2d(self.inplanes, planes * block.expansion,
#                           kernel_size=1, stride=stride, bias=False),
#                 nn.BatchNorm2d(planes * block.expansion),
#             )

#         layers = []
#         layers.append(block(self.inplanes, planes, stride, downsample))
#         self.inplanes = planes * block.expansion
#         for i in range(1, blocks):
#             layers.append(block(self.inplanes, planes))

#         return nn.Sequential(*layers)

#     def forward(self, x):
#         x = self.conv1(x)
#         x = self.bn1(x)
#         x = self.relu(x)
#         x = self.maxpool(x)

#         x = self.layer1(x)
#         x = self.layer2(x)
#         x = self.layer3(x)
#         x = self.layer4(x)

#         x = self.avgpool(x)
#         x = x.view(x.size(0), -1)
#         x = self.fc(x)
#         x = self.classifier_layer(x)

#         return torch.sigmoid(x)


# def resnet18_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-18 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet34_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-34 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet34'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet50_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-50 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet50'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet101_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-101 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet101'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet152_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-152 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet152'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model
11/17:

model=my_resnet50(weights="IMAGENET1K_V2")
11/18:

for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
    
# for name, param in model.named_parameters():
#     if 'classifier' not in name:
#         param.requires_grad = False
#     print(name, param.requires_grad)
11/19: model
11/20:
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True
    
#     import timm
# model = timm.create_model('ecaresnet50d', pretrained=True)
# model.reset_classifier(0)
# # #
# # #model=my_resnext50_32x4d(weights="IMAGENET1K_V2")
# # # model = efficientnet_v2_s(weights='DEFAULT')

# model = nn.Sequential(
#     model,
#     nn.Linear(2048 ,256),
#     nn.Dropout(.3),
# #     nn.BatchNorm1d(256),
#     nn.ReLU(),
#     nn.Linear(256,1),
#     nn.Sigmoid()
# )
# for name, param in model.named_parameters():
#     if (('layer' in name)|('conv' in name))&('se' not in name):
#         param.requires_grad = False
    #print(name, param.requires_grad)
    
# #from torchvision.models import efficientnet_v2_s  
# # model = CNN()
# model=my_resnet50(weights="IMAGENET1K_V2")



model.to(device)

# defining the optimizer
# For Calc Patches
# optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 850, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image masses
# optimizer = torch.optim.NAdam(model.parameters(), lr=8-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1150, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image calfications
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 15*(len(train_dataloader//batch_size), T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

optimizer = torch.optim.NAdam(model.parameters(), lr=1e-4, weight_decay=.01)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=1e-6, max_lr=4e-6,step_size_up = 20, cycle_momentum =False)
# epochs=90
# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr= 4e-5, total_steps=(len(train_dataset)//batch_size)*(epochs+1),pct_start=.3)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)
# scheduler2 = StepLR(optimizer, step_size=1200, gamma=0.15)
# scheduler3 = StepLR(optimizer, step_size=1100, gamma=0.15)
# scheduler4 = StepLR(optimizer, step_size=1200, gamma=0.15)

# # # scheduler2 = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, 2)
# # scheduler4 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,12,20,30], gamma=0.4)
# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2,scheduler3,scheduler4]
#                                                   , milestones=[60,120,180])
#scheduler=None

neg=0
pos=0
# for label in labels:
#     if label==1:
#         pos=pos+1
#     else:
#         neg=neg+1
w_pos = 2
w_neg = 1
print(f"Class weight for negative class: {w_neg}, and for positive {w_pos}")
#criterion = BCELoss_class_weighted(weights = [w_neg, w_pos])
criterion = nn.BCELoss()
# define early stopping
# earlystoper = EarlyStopper(patience = 30)

checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}
test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
print (dataset_sizes)
11/21:
# # optimizer.param_groups[0]['lr']=1e-5
#optimizer = torch.optim.NAdam(model.parameters(), lr=2e-5, weight_decay=.04)

#scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=200)
12/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/600x1000_v1_lightclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
12/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
12/3: len(filenames_calc)
12/4:
# count=0
# for i in filenames_calc:
#     if i == np.nan:
#         filenames_calc.pop(count)
#         labels_calc.pop(count)
#     count=count+1

# count=0
# for i in filenames_test_calc:
#     if i == np.nan:
#         filenames_test_calc.pop(count)
#         labels_test_calc.pop(count)
#     count=count+1
12/5:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.RandomAffine(degrees=(0,5),translate=(0.0, 0.05),  shear=(.2,.2)),
  #  transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
12/6: fname
12/7:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
12/8:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
12/9:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.001
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
12/10:
# print (val_size, len(labels_test_calc),train_size, len(labels_calc))
# for i in range(len(labels_test_calc)):
#     if labels_test_calc[i] == 1:
#         print (filenames_test_calc[i])
12/11:
batch_size = 14
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=14)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=14 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=14)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
12/12:
# plt.figure(figsize=(4,4),dpi=200)
# plt.imshow(X[0,:,:,:].permute(1, 2, 0)[:,:,0])
# X
# # torch.min(X[0,0,:,:])
# torch.min(X[0])
# idx
fname
12/13:
rows = 3
cols = 5
plt.subplots(rows, cols, figsize = (30, 30),dpi=100)

batch_imgs, batch_labels = next(iter(train_dataloader))
i = 0
for img in batch_imgs:
    
    if i >= rows*cols:
        break
    plt.subplot(rows, cols, i + 1)
    #plt.figure(figsize=(6,6),dpi=300)
    plt.title("Cancer" if batch_labels[i] == 1 else "No cancer")
    
    plt.imshow(img.permute(1, 2, 0)[:,:,0])

    i += 1

labels_count = np.zeros(2)
for l in batch_labels:
    labels_count[l] += 1 
    
    
print(f'There are {labels_count[0]} negative and {labels_count[1]} positive samples in this batch.')
12/14:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="Mass_CBAMresnet50_600x1000_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "CBAMresnet50",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
12/15:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
12/16:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                           , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                           , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
12/17:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
12/18:
from functools import partial
from typing import Any, Callable, List, Optional, Type, Union

import torch
import torch.nn as nn
from torch import Tensor

from torchvision.transforms._presets import ImageClassification
from torchvision.utils import _log_api_usage_once
from torchvision.models._api import register_model, Weights, WeightsEnum
from torchvision.models._meta import _IMAGENET_CATEGORIES
from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface

class SElayer(nn.Module):
    def __init__(self, inplanes, reduction=16):
        super(SElayer,self).__init__()
        self.globalAvgpool = nn.AdaptiveAvgPool2d(1)#Squeeze操作
        self.fc1 = nn.Conv2d(inplanes, inplanes // reduction, kernel_size=1, stride=1)
        self.fc2 = nn.Conv2d(inplanes // reduction, inplanes, kernel_size=1, stride=1)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()
    def forward(self,x):
        begin_input = x
        x = self.globalAvgpool(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        
        return x * begin_input
12/19:
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
           
        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                               nn.ReLU(),
                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)
12/20:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

            nn.Dropout(.2, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
12/21:
# model=my_resnet50()
# model
12/22:
# import torch
# import torch.nn as nn
# import math
# import torch.utils.model_zoo as model_zoo


# __all__ = ['ResNet', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam',
#            'resnet152_cbam']


# model_urls = {
#     'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
#     'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
#     'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
#     'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
#     'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
# }


# def conv3x3(in_planes, out_planes, stride=1):
#     "3x3 convolution with padding"
#     return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
#                      padding=1, bias=False)

# class ChannelAttention(nn.Module):
#     def __init__(self, in_planes, ratio=16):
#         super(ChannelAttention, self).__init__()
#         self.avg_pool = nn.AdaptiveAvgPool2d(1)
#         self.max_pool = nn.AdaptiveMaxPool2d(1)
           
#         self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
#                                nn.ReLU(),
#                                nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = self.fc(self.avg_pool(x))
#         max_out = self.fc(self.max_pool(x))
#         out = avg_out + max_out
#         return self.sigmoid(out)

# class SpatialAttention(nn.Module):
#     def __init__(self, kernel_size=7):
#         super(SpatialAttention, self).__init__()

#         self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
#         self.sigmoid = nn.Sigmoid()

#     def forward(self, x):
#         avg_out = torch.mean(x, dim=1, keepdim=True)
#         max_out, _ = torch.max(x, dim=1, keepdim=True)
#         x = torch.cat([avg_out, max_out], dim=1)
#         x = self.conv1(x)
#         return self.sigmoid(x)

# class BasicBlock(nn.Module):
#     expansion = 1

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(BasicBlock, self).__init__()
#         self.conv1 = conv3x3(inplanes, planes, stride)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.relu = nn.ReLU(inplace=True)
#         self.conv2 = conv3x3(planes, planes)
#         self.bn2 = nn.BatchNorm2d(planes)

#         self.ca = ChannelAttention(planes)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class Bottleneck(nn.Module):
#     expansion = 4

#     def __init__(self, inplanes, planes, stride=1, downsample=None):
#         super(Bottleneck, self).__init__()
#         self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
#                                padding=1, bias=False)
#         self.bn2 = nn.BatchNorm2d(planes)
#         self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)
#         self.bn3 = nn.BatchNorm2d(planes * 4)
#         self.relu = nn.ReLU(inplace=True)

#         self.ca = ChannelAttention(planes * 4)
#         self.sa = SpatialAttention()

#         self.downsample = downsample
#         self.stride = stride

#     def forward(self, x):
#         residual = x

#         out = self.conv1(x)
#         out = self.bn1(out)
#         out = self.relu(out)

#         out = self.conv2(out)
#         out = self.bn2(out)
#         out = self.relu(out)

#         out = self.conv3(out)
#         out = self.bn3(out)

#         out = self.ca(out) * out
#         out = self.sa(out) * out

#         if self.downsample is not None:
#             residual = self.downsample(x)

#         out += residual
#         out = self.relu(out)

#         return out


# class ResNet(nn.Module):

#     def __init__(self, block, layers, num_classes=1000):
#         self.inplanes = 64
#         super(ResNet, self).__init__()
#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
#                                bias=False)
#         self.bn1 = nn.BatchNorm2d(64)
#         self.relu = nn.ReLU(inplace=True)
#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
#         self.layer1 = self._make_layer(block, 64, layers[0])
#         self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
#         self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
#         self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
#         self.fc = nn.Linear(512 * block.expansion, num_classes)

#         for m in self.modules():
#             if isinstance(m, nn.Conv2d):
#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
#                 m.weight.data.normal_(0, math.sqrt(2. / n))
#             elif isinstance(m, nn.BatchNorm2d):
#                 m.weight.data.fill_(1)
#                 m.bias.data.zero_()

#     def _make_layer(self, block, planes, blocks, stride=1):
#         downsample = None
#         if stride != 1 or self.inplanes != planes * block.expansion:
#             downsample = nn.Sequential(
#                 nn.Conv2d(self.inplanes, planes * block.expansion,
#                           kernel_size=1, stride=stride, bias=False),
#                 nn.BatchNorm2d(planes * block.expansion),
#             )

#         layers = []
#         layers.append(block(self.inplanes, planes, stride, downsample))
#         self.inplanes = planes * block.expansion
#         for i in range(1, blocks):
#             layers.append(block(self.inplanes, planes))

#         return nn.Sequential(*layers)

#     def forward(self, x):
#         x = self.conv1(x)
#         x = self.bn1(x)
#         x = self.relu(x)
#         x = self.maxpool(x)

#         x = self.layer1(x)
#         x = self.layer2(x)
#         x = self.layer3(x)
#         x = self.layer4(x)

#         x = self.avgpool(x)
#         x = x.view(x.size(0), -1)
#         x = self.fc(x)
#         x = self.classifier_layer(x)

#         return torch.sigmoid(x)


# def resnet18_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-18 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet34_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-34 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet34'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet50_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-50 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet50'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet101_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-101 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet101'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model


# def resnet152_cbam(pretrained=False, **kwargs):
#     """Constructs a ResNet-152 model.
#     Args:
#         pretrained (bool): If True, returns a model pre-trained on ImageNet
#     """
#     model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)
#     if pretrained:
#         pretrained_state_dict = model_zoo.load_url(model_urls['resnet152'])
#         now_state_dict        = model.state_dict()
#         now_state_dict.update(pretrained_state_dict)
#         model.load_state_dict(now_state_dict)
#     return model
12/23:

model=my_resnet50(weights="IMAGENET1K_V2")
12/24:

for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
    
# for name, param in model.named_parameters():
#     if 'classifier' not in name:
#         param.requires_grad = False
#     print(name, param.requires_grad)
12/25:
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True
    
#     import timm
# model = timm.create_model('ecaresnet50d', pretrained=True)
# model.reset_classifier(0)
# # #
# # #model=my_resnext50_32x4d(weights="IMAGENET1K_V2")
# # # model = efficientnet_v2_s(weights='DEFAULT')

# model = nn.Sequential(
#     model,
#     nn.Linear(2048 ,256),
#     nn.Dropout(.3),
# #     nn.BatchNorm1d(256),
#     nn.ReLU(),
#     nn.Linear(256,1),
#     nn.Sigmoid()
# )
# for name, param in model.named_parameters():
#     if (('layer' in name)|('conv' in name))&('se' not in name):
#         param.requires_grad = False
    #print(name, param.requires_grad)
    
# #from torchvision.models import efficientnet_v2_s  
# # model = CNN()
# model=my_resnet50(weights="IMAGENET1K_V2")



model.to(device)

# defining the optimizer
# For Calc Patches
# optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 850, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image masses
# optimizer = torch.optim.NAdam(model.parameters(), lr=8-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1150, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)
# For whole image calfications
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 15*(len(train_dataloader//batch_size), T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

optimizer = torch.optim.NAdam(model.parameters(), lr=5e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 900, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=1e-6, max_lr=4e-6,step_size_up = 20, cycle_momentum =False)
# epochs=90
# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr= 4e-5, total_steps=(len(train_dataset)//batch_size)*(epochs+1),pct_start=.3)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)
# scheduler2 = StepLR(optimizer, step_size=1200, gamma=0.15)
# scheduler3 = StepLR(optimizer, step_size=1100, gamma=0.15)
# scheduler4 = StepLR(optimizer, step_size=1200, gamma=0.15)

# # # scheduler2 = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, 2)
# # scheduler4 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,12,20,30], gamma=0.4)
# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2,scheduler3,scheduler4]
#                                                   , milestones=[60,120,180])
#scheduler=None

neg=0
pos=0
# for label in labels:
#     if label==1:
#         pos=pos+1
#     else:
#         neg=neg+1
w_pos = 2
w_neg = 1
print(f"Class weight for negative class: {w_neg}, and for positive {w_pos}")
#criterion = BCELoss_class_weighted(weights = [w_neg, w_pos])
criterion = nn.BCELoss()
# define early stopping
# earlystoper = EarlyStopper(patience = 30)

checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}
test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
print (dataset_sizes)
12/26:
# # optimizer.param_groups[0]['lr']=1e-5
#optimizer = torch.optim.NAdam(model.parameters(), lr=2e-5, weight_decay=.04)

#scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=200)
13/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_skresnet50_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
13/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('C:/Users/marcb/Downloads/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
13/3:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
13/4:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
13/5:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
13/6:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
13/7:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
13/8:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
13/9:
batch_size = 10
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=0 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=0)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
13/10:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=0 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=0)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
13/11:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
13/12:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
13/13:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
13/14:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
13/15:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
13/16:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
13/17:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
13/18:



import timm
model = timm.create_model('skresnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
13/19: !pip install timm
13/20:



import timm
model = timm.create_model('skresnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
13/21:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=16)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
13/22:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_ssl_resnet50_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
13/23:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
13/24:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
13/25:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
13/26:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
13/27:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
13/28:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
13/29:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
13/30:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
13/31:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
13/32:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
13/33:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
13/34:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=16)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
13/35:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_swsl_resnet50_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
13/36:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
13/37:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
13/38:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
13/39:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
13/40:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
13/41:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
13/42:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
13/43:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
13/44:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
13/45:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
13/46:



import timm
model = timm.create_model('swsl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
13/47:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=3e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1800, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=15)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
13/48:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_visformer_small_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
13/49:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
13/50:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
13/51:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
13/52:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
13/53:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
13/54:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
13/55:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
13/56:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
13/57:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
13/58:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
13/59:



import timm
model = timm.create_model('visformer_small', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
13/60:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
13/61:



import timm
model = timm.create_model('convnext_base', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
13/62:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
13/63:



import timm
model = timm.create_model('convnext_base', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
# model.fc = nn.Sequential(
#     nn.Dropout(.2),
#     nn.Linear(in_features=num_in_features, out_features=256, bias=False),
#     nn.LeakyReLU(.1,inplace=True),
#     nn.Linear(in_features=256, out_features=1, bias=False),
#     nn.Sigmoid())

model
13/64:



import timm
model = timm.create_model('convnext_base', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.head.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
13/65:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
15/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_convnext_base_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
15/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
15/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
15/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
15/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
15/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
15/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
15/8:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
15/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
15/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
15/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
15/12:



import timm
model = timm.create_model('convnext_base', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.head.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
15/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
16/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_convnext_small_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
16/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
16/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
16/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
16/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
16/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
16/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
16/8:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
16/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
16/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
16/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
16/12:



import timm
model = timm.create_model('convnext_small', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.head.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
16/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
16/14:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_eca_halonext26ts_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
16/15:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
16/16:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
16/17:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
16/18:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
16/19:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
16/20:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
16/21:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
16/22:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
16/23:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
16/24:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
16/25:



import timm
model = timm.create_model('eca_halonext26ts', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.head.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
16/26:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
16/27:



import timm
model = timm.create_model('haloregnetz_b', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.head.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
16/28:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
16/29:



import timm
model = timm.create_model('halonet50ts', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.head.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
16/30:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
16/31:



import timm
model = timm.create_model('hrnet_w40', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.head.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
16/32:



import timm
model = timm.create_model('hrnet_w40', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
# model.head.fc = nn.Sequential(
#     nn.Dropout(.2),
#     nn.Linear(in_features=num_in_features, out_features=256, bias=False),
#     nn.LeakyReLU(.1,inplace=True),
#     nn.Linear(in_features=256, out_features=1, bias=False),
#     nn.Sigmoid())

model
16/33:



import timm
model = timm.create_model('hrnet_w40', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
16/34:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
16/35:



import timm
model = timm.create_model('densenet201', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
16/36:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
17/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_ecaresnetlight_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
17/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
17/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
17/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
17/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
17/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
17/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
17/8:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
17/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
17/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
17/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
17/12:



import timm
model = timm.create_model('ecaresnetlight', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
17/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
17/14:



import timm
model = timm.create_model('ecaresnetlight', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
17/15:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
17/16:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_efficientnet_b3_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
17/17:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
17/18:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
17/19:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
17/20:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
17/21:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
17/22:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
17/23:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
17/24:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
17/25:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
17/26:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
17/27:



import timm
model = timm.create_model('ecaresnetlight', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
17/28:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
18/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_efficientnet_b2_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
18/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
18/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
18/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
18/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
18/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
18/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
18/8:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
18/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
18/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
18/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
18/12:



import timm
model = timm.create_model('efficientnet_b2', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
18/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
18/14:



import timm
model = timm.create_model('efficientnet_b2', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
18/15:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
18/16:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_efficientnet_b3_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
18/17:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
18/18:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
18/19:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
18/20:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
18/21:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
18/22:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
18/23:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
18/24:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
18/25:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
18/26:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
18/27:



import timm
model = timm.create_model('efficientnet_b3', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
18/28:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
18/29:
#efficientnetv2_s
#ecaresnext50t_32x4d
#ecaresnet50d
#ecaresnet50t
#ecaresnet101d
#efficientnet_b3_gn
#efficientnet_b3
# 'halo2botnet50ts_256',
# , 'halonet26t',
# , 'halonet50ts',
# , 'halonet_h1',
# , 'haloregnetz_b',
#legacy_seresnet50
#mobilenetv3_large_075
#mobilenetv3_small_100
#seresnet50
#seresnext50_32x4d
#skresnet50
#ssl_resnet50
#swsl_resnet50
#visformer_small
#tv_resnet50
#resnest50d  #split Attention
#regnetx_040
#twins_pcpvt_base
#twins_svt_base

### Crossvit Models ###
#  'crossvit_9_240',
# , 'crossvit_9_dagger_240',
# , 'crossvit_15_240',
# , 'crossvit_15_dagger_240',
# , 'crossvit_15_dagger_408',
# , 'crossvit_18_240',
# , 'crossvit_18_dagger_240',
# , 'crossvit_18_dagger_408',
# , 'crossvit_base_240',
# , 'crossvit_small_240',
# , 'crossvit_tiny_240',

### Swin Models ###
# , 'swin_base_patch4_window7_224',
# , 'swin_base_patch4_window7_224_in22k',
# , 'swin_base_patch4_window12_384',
# , 'swin_base_patch4_window12_384_in22k',
# , 'swin_large_patch4_window7_224',
# , 'swin_large_patch4_window7_224_in22k',
# , 'swin_large_patch4_window12_384',
# , 'swin_large_patch4_window12_384_in22k',
# , 'swin_s3_base_224',
# , 'swin_s3_small_224',
# , 'swin_s3_tiny_224',
# , 'swin_small_patch4_window7_224',
# , 'swin_tiny_patch4_window7_224',
# , 'swinv2_base_window8_256',
# , 'swinv2_base_window12_192_22k',
# , 'swinv2_base_window12to16_192to256_22kft1k',
# , 'swinv2_base_window12to24_192to384_22kft1k',
# , 'swinv2_base_window16_256',
# , 'swinv2_cr_base_224',
# , 'swinv2_cr_base_384',
# , 'swinv2_cr_base_ns_224',
# , 'swinv2_cr_giant_224',
# , 'swinv2_cr_giant_384',
# , 'swinv2_cr_huge_224',
# , 'swinv2_cr_huge_384',
# , 'swinv2_cr_large_224',
# , 'swinv2_cr_large_384',
# , 'swinv2_cr_small_224',
# , 'swinv2_cr_small_384',
# , 'swinv2_cr_small_ns_224',
# , 'swinv2_cr_tiny_224',
# , 'swinv2_cr_tiny_384',
# , 'swinv2_cr_tiny_ns_224',
# , 'swinv2_large_window12_192_22k',
# , 'swinv2_large_window12to16_192to256_22kft1k',
# , 'swinv2_large_window12to24_192to384_22kft1k',
# , 'swinv2_small_window8_256',
# , 'swinv2_small_window16_256',
# , 'swinv2_tiny_window8_256',
# , 'swinv2_tiny_window16_256',
###############################
18/30:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_efficientnet_b4_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
18/31:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
18/32:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
18/33:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
18/34:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
18/35:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
18/36:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
18/37:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
18/38:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
18/39:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
18/40:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
18/41:



import timm
model = timm.create_model('efficientnet_b4', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
18/42:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
19/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_darknet53_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
19/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
19/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
19/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
19/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
19/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
19/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
19/8:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
19/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
19/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
19/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
19/12:



import timm
model = timm.create_model('darknet53', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
19/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
19/14:



import timm
model = timm.create_model('darknet53', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.head.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
19/15:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1100, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
19/16:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_darknet53_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
19/17:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
19/18:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
19/19:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
19/20:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
19/21:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
19/22:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
19/23:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
19/24:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
19/25:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
19/26:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
19/27:



import timm
model = timm.create_model('darknet53', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.head.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
19/28:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=18)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
19/29:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_darknet53_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
19/30:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
19/31:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
19/32:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
19/33:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
19/34:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
19/35:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
19/36:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
19/37:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
19/38:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
19/39:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
19/40:



import timm
model = timm.create_model('darknet53', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.head.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
19/41:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.NAdam(model.parameters(), lr=3e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=18)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
20/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_resnet50_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
20/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
20/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
20/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
20/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
20/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
20/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
20/8:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
20/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
20/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
20/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
20/12:



import timm
model = timm.create_model('resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.head.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
20/13:



import timm
model = timm.create_model('resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier  nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
20/14:



import timm
model = timm.create_model('resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
20/15:



import timm
model = timm.create_model('resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
20/16:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=18)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
20/17:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.NAdam(model.parameters(), lr=2e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=18)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
20/18:



import timm
model = timm.create_model('resnet34', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
20/19:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-6, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=18)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
20/20:



import timm
model = timm.create_model('resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
20/21:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-6, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
20/22:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-6, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
20/23:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
20/24:



import timm
model = timm.create_model('resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
20/25:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
20/26:



import timm
model = timm.create_model('resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
20/27:



import timm
model = timm.create_model('resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
#     nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
20/28:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-6, weight_decay=.002)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
21/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
21/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
21/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
21/4:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
21/5:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
21/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
21/7:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
21/8:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=10)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=10 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=10)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
21/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
21/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
21/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
21/12:



import timm
model = timm.create_model('densenet169', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
#     nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
21/13:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_densenet169_900x1500_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
21/14:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
22/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_densenet169_900x1500_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
22/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
22/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
22/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
22/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
22/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
22/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
22/8:
batch_size = 8
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=8)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=8 )
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=8)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
22/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
22/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
22/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
22/12:



import timm
model = timm.create_model('densenet169', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
#     nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
22/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
23/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_densenet169_900x1500_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
23/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
23/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
23/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
23/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
23/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
23/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
23/8:
batch_size = 6
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=6)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=6)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=6)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
23/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
23/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
23/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
23/12:



import timm
model = timm.create_model('densenet169', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
#     nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
23/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
24/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_densenet121_900x1500_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
24/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
24/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
24/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
24/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
24/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
24/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
24/8:
batch_size = 6
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=6)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=6)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=6)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
24/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
24/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
24/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
24/12:



import timm
model = timm.create_model('densenet121', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
#     nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
24/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
25/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_densenet121_900x1500_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
25/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
25/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
25/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
25/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
25/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
25/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
25/8:
batch_size = 4
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=6)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=6)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=6)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
25/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
25/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
25/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
25/12:



import timm
model = timm.create_model('densenet121', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
#     nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
25/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
26/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_densenet121_900x1500_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
26/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
26/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
26/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
26/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
26/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
26/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
26/8:
batch_size = 4
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=6)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=6)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=6)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
26/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
26/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
26/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
26/12:



import timm
model = timm.create_model('densenet121', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
#     nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
26/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
28/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_densenet169_900x1500_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
28/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
28/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
28/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
28/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
28/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
28/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
28/8:
batch_size = 4
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
28/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
28/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
28/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
28/12:



import timm
model = timm.create_model('densenet169', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
#     nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
28/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 3800, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
29/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_densenet169_600x1000_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
29/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/900x1500_v1_noclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
29/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
29/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
29/5:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/600x1000_v1_lightclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
29/6:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
29/7:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
29/8:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
29/9:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
29/10:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
29/11:
batch_size = 4
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
29/12:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
29/13:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
29/14:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
29/15:
batch_size = 6
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
29/16:



import timm
model = timm.create_model('densenet169', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
#     nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
29/17:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 3800, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
30/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_densenet169_600x1000_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
30/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/600x1000_v1_lightclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
30/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
30/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
30/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
30/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
30/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
30/8:
batch_size = 5
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
30/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
30/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
30/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
30/12:



import timm
model = timm.create_model('densenet169', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
#     nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
30/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 3800, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
30/14:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()
31/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Mass_densenet169_600x1000_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
31/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['mass_case_description_test_set','mass_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/600x1000_v1_lightclahe/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
31/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
31/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
31/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
31/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
31/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
31/8:
batch_size = 5
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
31/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
31/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
31/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
31/12:



import timm
model = timm.create_model('densenet169', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
31/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-6, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 5000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
31/14:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()
32/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_CBAMresnet50_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
32/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
32/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
32/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
32/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
32/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
32/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
32/8:
batch_size = 14
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
32/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
32/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
32/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
32/12:
from functools import partial
from typing import Any, Callable, List, Optional, Type, Union

import torch
import torch.nn as nn
from torch import Tensor

from torchvision.transforms._presets import ImageClassification
from torchvision.utils import _log_api_usage_once
from torchvision.models._api import register_model, Weights, WeightsEnum
from torchvision.models._meta import _IMAGENET_CATEGORIES
from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface

class SElayer(nn.Module):
    def __init__(self, inplanes, reduction=16):
        super(SElayer,self).__init__()
        self.globalAvgpool = nn.AdaptiveAvgPool2d(1)#Squeeze操作
        self.fc1 = nn.Conv2d(inplanes, inplanes // reduction, kernel_size=1, stride=1)
        self.fc2 = nn.Conv2d(inplanes // reduction, inplanes, kernel_size=1, stride=1)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()
    def forward(self,x):
        begin_input = x
        x = self.globalAvgpool(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        
        return x * begin_input
32/13:
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
           
        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                               nn.ReLU(),
                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=8):
        super(SpatialAttention, self).__init__()

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)
32/14:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

            nn.Dropout(.2, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
32/15: model=my_resnet50(weights="IMAGENET1K_V2")
32/16:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=35)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
32/17:
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
           
        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                               nn.ReLU(),
                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)
32/18:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

            nn.Dropout(.2, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
32/19:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=35)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
32/20: model=my_resnet50(weights="IMAGENET1K_V2")
32/21:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=35)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
32/22:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

#             nn.Dropout(.2, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
32/23:
model=my_resnet50(weights="IMAGENET1K_V2")
for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
32/24:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
32/25:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=3e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=35)
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
32/26:
optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-6, weight_decay=.001)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 800, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=12)
32/27:
model=my_resnet50(weights="IMAGENET1K_V2")
for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
32/28:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.NAdam(model.parameters(), lr=1e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)
optimizer = torch.optim.NAdam(model.parameters(), lr=4e-6, weight_decay=.001)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 700, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)

test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish() 

gc.collect()
torch.cuda.empty_cache()  

# PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# torch.save(model.state_dict(), PATH)
# PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# torch.save(model, PATH)

gc.collect()
torch.cuda.empty_cache()
33/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_CBAMresnet50_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
33/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
33/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
33/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
33/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
33/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
33/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
33/8:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
33/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
33/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
33/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
33/12:
from functools import partial
from typing import Any, Callable, List, Optional, Type, Union

import torch
import torch.nn as nn
from torch import Tensor

from torchvision.transforms._presets import ImageClassification
from torchvision.utils import _log_api_usage_once
from torchvision.models._api import register_model, Weights, WeightsEnum
from torchvision.models._meta import _IMAGENET_CATEGORIES
from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface

class SElayer(nn.Module):
    def __init__(self, inplanes, reduction=16):
        super(SElayer,self).__init__()
        self.globalAvgpool = nn.AdaptiveAvgPool2d(1)#Squeeze操作
        self.fc1 = nn.Conv2d(inplanes, inplanes // reduction, kernel_size=1, stride=1)
        self.fc2 = nn.Conv2d(inplanes // reduction, inplanes, kernel_size=1, stride=1)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()
    def forward(self,x):
        begin_input = x
        x = self.globalAvgpool(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        
        return x * begin_input
33/13:
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
           
        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),
                               nn.ReLU(),
                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out)

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)
33/14:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

            nn.Dropout(.2, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
33/15:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

            nn.Dropout(.3, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
33/16:
model=my_resnet50(weights="IMAGENET1K_V2")
for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
33/17:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
33/18:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=50)
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-6, weight_decay=.001)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 700, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
# model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
33/19:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

            nn.Dropout(.6, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
33/20:
optimizer = torch.optim.NAdam(model.parameters(), lr=4e-6, weight_decay=.01)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1200, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
33/21:
__all__ = [
    "ResNet",
    "ResNet18_Weights",
    "ResNet34_Weights",
    "ResNet50_Weights",
    "ResNet101_Weights",
    "ResNet152_Weights",
    "ResNeXt50_32X4D_Weights",
    "ResNeXt101_32X8D_Weights",
    "ResNeXt101_64X4D_Weights",
    "Wide_ResNet50_2_Weights",
    "Wide_ResNet101_2_Weights",
    "resnet18",
    "resnet34",
    "resnet50",
    "resnet101",
    "resnet152",
    "resnext50_32x4d",
    "resnext101_32x8d",
    "resnext101_64x4d",
    "wide_resnet50_2",
    "wide_resnet101_2",
]


def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        stride=stride,
        padding=dilation,
        groups=groups,
        bias=False,
        dilation=dilation,
    )


def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.ca(out) * out
        out = self.sa(out) * out

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition" https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
    ) -> None:
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.0)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.ca = ChannelAttention(planes * 4)
        self.sa = SpatialAttention()
       # self.selayer = SElayer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x: Tensor) -> Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        out = self.ca(out) * out
        out = self.sa(out) * out
       # out = self.selayer(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        l1=256, l2=64,l3=.3,
    ) -> None:
        super().__init__()
        _log_api_usage_once(self)
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError(
                "replace_stride_with_dilation should be None "
                f"or a 3-element tuple, got {replace_stride_with_dilation}"
            )
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        #self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.classifier_layer = nn.Sequential(

            nn.Dropout(.6, inplace=True),
            nn.Linear(2048  , 256),
#             nn.Dropout(.5, inplace=True),
#             nn.BatchNorm1d(256),
            nn.LeakyReLU(.1,inplace=True),
#             nn.GELU(),
            nn.Linear(256 , 1),
#             nn.Dropout(.6, inplace=True),
#             nn.ReLU(inplace=True),
#             nn.Linear(128 , 1),
#             nn.Dropout(.5),
#             nn.BatchNorm1d(128),
#             nn.ReLU(),
#             nn.Linear(128,1)
#             nn.BatchNorm1d(256),
#             nn.ReLU(inplace=True),
#             #nn.Dropout(0.4),
#             nn.Linear(256 , 1),
#             nn.BatchNorm1d(128),
#             nn.LeakyReLU(.1),
#             nn.Dropout(0.6),
#             nn.Linear(256 , 1)
        )
        

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck) and m.bn3.weight is not None:
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]

    def _make_layer(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        planes: int,
        blocks: int,
        stride: int = 1,
        dilate: bool = False,
    ) -> nn.Sequential:
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer
            )
        )
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes,
                    planes,
                    groups=self.groups,
                    base_width=self.base_width,
                    dilation=self.dilation,
                    norm_layer=norm_layer,
                )
            )

        return nn.Sequential(*layers)

    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        #x = self.fc(x)
        x = self.classifier_layer(x)

        return torch.sigmoid(x)

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _resnet(
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    weights: Optional[WeightsEnum],
    progress: bool,
    **kwargs: Any,
) -> ResNet:
    if weights is not None:
        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))

    model = ResNet(block, layers, **kwargs)

    if weights is not None:
        model.load_state_dict(weights.get_state_dict(progress=progress),strict=False)

    return model


_COMMON_META = {
    "min_size": (1, 1),
    "categories": _IMAGENET_CATEGORIES,
}


class ResNet18_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 11689512,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 69.758,
                    "acc@5": 89.078,
                }
            },
            "_ops": 1.814,
            "_file_size": 44.661,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet34_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 21797672,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 73.314,
                    "acc@5": 91.420,
                }
            },
            "_ops": 3.664,
            "_file_size": 83.275,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    DEFAULT = IMAGENET1K_V1


class ResNet50_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 76.130,
                    "acc@5": 92.862,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.781,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25557032,
            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 80.858,
                    "acc@5": 95.434,
                }
            },
            "_ops": 4.089,
            "_file_size": 97.79,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet101_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.374,
                    "acc@5": 93.546,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.511,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 44549160,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.886,
                    "acc@5": 95.780,
                }
            },
            "_ops": 7.801,
            "_file_size": 170.53,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNet152_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.312,
                    "acc@5": 94.046,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.434,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 60192808,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.284,
                    "acc@5": 96.002,
                }
            },
            "_ops": 11.514,
            "_file_size": 230.474,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt50_32X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 77.618,
                    "acc@5": 93.698,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.789,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 25028904,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.198,
                    "acc@5": 95.340,
                }
            },
            "_ops": 4.23,
            "_file_size": 95.833,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_32X8D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 79.312,
                    "acc@5": 94.526,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.586,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 88791336,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.834,
                    "acc@5": 96.228,
                }
            },
            "_ops": 16.414,
            "_file_size": 339.673,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class ResNeXt101_64X4D_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 83455272,
            "recipe": "https://github.com/pytorch/vision/pull/5935",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 83.246,
                    "acc@5": 96.454,
                }
            },
            "_ops": 15.46,
            "_file_size": 319.318,
            "_docs": """
                These weights were trained from scratch by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V1


class Wide_ResNet50_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.468,
                    "acc@5": 94.086,
                }
            },
            "_ops": 11.398,
            "_file_size": 131.82,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 68883240,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 81.602,
                    "acc@5": 95.758,
                }
            },
            "_ops": 11.398,
            "_file_size": 263.124,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


class Wide_ResNet101_2_Weights(WeightsEnum):
    IMAGENET1K_V1 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
        transforms=partial(ImageClassification, crop_size=224),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 78.848,
                    "acc@5": 94.284,
                }
            },
            "_ops": 22.753,
            "_file_size": 242.896,
            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
        },
    )
    IMAGENET1K_V2 = Weights(
        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
        meta={
            **_COMMON_META,
            "num_params": 126886696,
            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
            "_metrics": {
                "ImageNet-1K": {
                    "acc@1": 82.510,
                    "acc@5": 96.020,
                }
            },
            "_ops": 22.753,
            "_file_size": 484.747,
            "_docs": """
                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
            """,
        },
    )
    DEFAULT = IMAGENET1K_V2


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
def my_resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet18_Weights.verify(weights)

    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet34_Weights.IMAGENET1K_V1))
def my_resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet34_Weights.verify(weights)

    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet50_Weights.IMAGENET1K_V1))
def my_resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet50_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet101_Weights.IMAGENET1K_V1))
def my_resnet101(*, weights: Optional[ResNet101_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet101_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNet152_Weights.IMAGENET1K_V1))
def my_resnet152(*, weights: Optional[ResNet152_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:

    weights = ResNet152_Weights.verify(weights)

    return _resnet(Bottleneck, [3, 8, 36, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt50_32X4D_Weights.IMAGENET1K_V1))
def my_resnext50_32x4d(
    *, weights: Optional[ResNeXt50_32X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt50_32X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_32X8D_Weights.IMAGENET1K_V1))
def my_resnext101_32x8d(
    *, weights: Optional[ResNeXt101_32X8D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_32X8D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 32)
    _ovewrite_named_param(kwargs, "width_per_group", 8)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", ResNeXt101_64X4D_Weights.IMAGENET1K_V1))
def my_resnext101_64x4d(
    *, weights: Optional[ResNeXt101_64X4D_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = ResNeXt101_64X4D_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "groups", 64)
    _ovewrite_named_param(kwargs, "width_per_group", 4)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet50_2_Weights.IMAGENET1K_V1))
def my_wide_resnet50_2(
    *, weights: Optional[Wide_ResNet50_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:

    weights = Wide_ResNet50_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)


#@register_model()
@handle_legacy_interface(weights=("pretrained", Wide_ResNet101_2_Weights.IMAGENET1K_V1))
def my_wide_resnet101_2(
    *, weights: Optional[Wide_ResNet101_2_Weights] = None, progress: bool = True, **kwargs: Any
) -> ResNet:
    """Wide ResNet-101-2 model from
    `Wide Residual Networks <https://arxiv.org/abs/1605.07146>`_.
    The model is the same as ResNet except for the bottleneck number of channels
    which is twice larger in every block. The number of channels in outer 1x1
    convolutions is the same, e.g. last block in ResNet-101 has 2048-512-2048
    channels, and in Wide ResNet-101-2 has 2048-1024-2048.
    Args:
        weights (:class:`~torchvision.models.Wide_ResNet101_2_Weights`, optional): The
            pretrained weights to use. See
            :class:`~torchvision.models.Wide_ResNet101_2_Weights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool, optional): If True, displays a progress bar of the
            download to stderr. Default is True.
        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_
            for more details about this class.
    .. autoclass:: torchvision.models.Wide_ResNet101_2_Weights
        :members:
    """
    weights = Wide_ResNet101_2_Weights.verify(weights)

    _ovewrite_named_param(kwargs, "width_per_group", 64 * 2)
    return _resnet(Bottleneck, [3, 4, 23, 3], weights, progress, **kwargs)
33/22:
model=my_resnet50(weights="IMAGENET1K_V2")
for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
33/23:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-4, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=80)
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-6, weight_decay=.001)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 700, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
# model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
33/24:
model=my_resnet50(weights="IMAGENET1K_V2")
for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
33/25:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=80)
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-6, weight_decay=.001)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 700, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
# model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
33/26:
optimizer = torch.optim.NAdam(model.parameters(), lr=1e-4, weight_decay=.01)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1200, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=100)
33/27:
# optimizer = torch.optim.NAdam(model.parameters(), lr=1e-4, weight_decay=.01)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1200, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=100)
33/28:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish()
36/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_ssl_resnet50_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
36/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
36/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
36/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.1, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
#     transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.2,.2)),
#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
36/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
36/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
36/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
36/8:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
36/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
36/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
36/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
36/12:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.classifier = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
36/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=80)
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-6, weight_decay=.001)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 700, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
# model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
36/14:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
36/15:
model=my_resnet50(weights="IMAGENET1K_V2")
for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
36/16:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.NAdam(model.parameters(), lr=4e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=80)
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-6, weight_decay=.001)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 700, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
# model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
36/17:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.6),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
36/18:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.NAdam(model.parameters(), lr=2e-5, weight_decay=.02)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=80)
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-6, weight_decay=.001)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 700, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
# model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
36/19:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
36/20:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.NAdam(model.parameters(), lr=2e-6, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=80)
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-6, weight_decay=.001)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 700, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
# model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
36/21:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=1, bias=False),
#     nn.LeakyReLU(.1,inplace=True),
#     nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
36/22:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-6, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=80)
# optimizer = torch.optim.NAdam(model.parameters(), lr=4e-6, weight_decay=.001)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 700, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
# model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
36/23:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=1, bias=False),
#     nn.LeakyReLU(.1,inplace=True),
#     nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
36/24:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-4, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)
optimizer = torch.optim.NAdam(model.parameters(), lr=1e-6, weight_decay=.001)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
36/25:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=1, bias=False),
#     nn.LeakyReLU(.1,inplace=True),
#     nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
36/26:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)
optimizer = torch.optim.NAdam(model.parameters(), lr=1e-6, weight_decay=.001)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
36/27:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=1, bias=False),
#     nn.LeakyReLU(.1,inplace=True),
#     nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
36/28:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)
optimizer = torch.optim.NAdam(model.parameters(), lr=5e-7, weight_decay=.001)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
36/29:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=1, bias=False),
#     nn.LeakyReLU(.1,inplace=True),
#     nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
36/30:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)
optimizer = torch.optim.NAdam(model.parameters(), lr=5e-7, weight_decay=.001)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
36/31:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
36/32:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)
optimizer = torch.optim.RMSprop(model.parameters(), lr=5e-7, weight_decay=.001)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
36/33:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
    transforms.RandomAdjustSharpness(2, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(16),
#     transforms.Resize(size=(500,300)),
    transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
36/34:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
    transforms.RandomAdjustSharpness(2, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(16),
#     transforms.Resize(size=(500,300)),
    transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
36/35:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
36/36:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
36/37:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
36/38:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
36/39:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
36/40:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
36/41:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
36/42:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
36/43:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
36/44:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)
optimizer = torch.optim.RMSprop(model.parameters(), lr=5e-7, weight_decay=.001)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
36/45:



import timm
model = timm.create_model('ssl_resnet50', pretrained=False)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
36/46:
model=my_resnet50(weights="IMAGENET1K_V2")
for name, param in model.named_parameters():
    if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
        param.requires_grad = False
    print(name, param.requires_grad)
36/47:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-6, weight_decay=.5)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 3000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
37/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_swsl_resnet50_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
37/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
37/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
37/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
    transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(15),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
37/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
37/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
37/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
37/8:
batch_size = 24
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
37/9:
batch_size = 32
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
37/10:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
37/11:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
37/12:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
37/13:



import timm
model = timm.create_model('ssl_resnet50', pretrained=False)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
37/14:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 3000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
38/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_swsl_resnet50_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
38/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
38/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
38/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
    transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(15),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
38/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
38/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
38/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
38/8:
batch_size = 26
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
38/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
38/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
38/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
38/12:



import timm
model = timm.create_model('ssl_resnet50', pretrained=False)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
38/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 3000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
38/14:
batch_size = 24
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
38/15:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
38/16:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
38/17:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
38/18:



import timm
model = timm.create_model('ssl_resnet50', pretrained=False)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
38/19:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 3000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
39/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_swsl_resnet50_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
39/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
39/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
39/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
    transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(15),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
39/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
39/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
39/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
39/8:
batch_size = 24
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
39/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
39/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
39/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
39/12:



import timm
model = timm.create_model('sssl_resnet50', pretrained=False)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
39/13:



import timm
model = timm.create_model('swsl_resnet50', pretrained=False)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
39/14:



import timm
model = timm.create_model('swsl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
39/15:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 3000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
39/16: device
39/17: torch.cuda
39/18: torch.cuda.is_available()
40/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_swsl_resnet50_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
40/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
40/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
40/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
    transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(15),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
40/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
40/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
40/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
40/8:
batch_size = 24
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
40/9:
batch_size = 32
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
40/10:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
40/11:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
40/12:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
40/13:



import timm
model = timm.create_model('swsl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
40/14:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 3000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
40/15:



import timm
model = timm.create_model('swsl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
40/16:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-6, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 800, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
40/17:
# optimizer = torch.optim.NAdam(model.parameters(), lr=1e-4, weight_decay=.01)
# scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1200, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=100)
41/1:
import os
import time

# Third-party library imports
import numpy as np
import pandas as pd
import cv2
import pydicom
import dicomsdl

# Visualization library imports
import matplotlib.pyplot as plt

# Progress bar library imports
from tqdm.notebook import tqdm, trange

# Parallel processing library imports
from joblib import Parallel, delayed

import gc
41/2: !pip install pydicom
41/3:
import os
import time

# Third-party library imports
import numpy as np
import pandas as pd
import cv2
import pydicom
import dicomsdl

# Visualization library imports
import matplotlib.pyplot as plt

# Progress bar library imports
from tqdm.notebook import tqdm, trange

# Parallel processing library imports
from joblib import Parallel, delayed

import gc
41/4:
import os
import time

# Third-party library imports
import numpy as np
import pandas as pd
import cv2
import pydicom
# import dicomsdl

# Visualization library imports
import matplotlib.pyplot as plt

# Progress bar library imports
from tqdm.notebook import tqdm, trange

# Parallel processing library imports
from joblib import Parallel, delayed

import gc
41/5:
class MammographyPreprocessor():
    
    # Constructor
    def __init__(self, size: tuple=None, breast_side: str='L',
                 csv_path=None, train_path=None):
        self.size = size
        os.makedirs(os.getcwd(), exist_ok=True)
        self.breast_side = breast_side
        assert breast_side in ['L', 'R'], "breast_side should be 'L' or 'R'"
        # implement the paths of the original RSNA dataset (V2)
#         self.csv_path = '/kaggle/input/rsna-breast-cancer-detection/train.csv'
#         self.train_path = '/kaggle/input/rsna-breast-cancer-detection/train_images'
#         if csv_path:
#             self.csv_path = csv_path
#         if train_path:
#             self.train_path = train_path
#         self.df = pd.read_csv(self.csv_path)
        self.save_root = os.getcwd()
    
#     # Get the paths from the preprocessor (V2)
#     def get_paths(self, n: int=None, shuffle: bool=False, return_cache: bool=False):
#         if n == None:
#             n = len(self.df)
#         if shuffle == True:
#             df = self.df.sample(frac=1, random_state=0).copy()
#         else:
#             df = self.df.copy()
#         paths = []
#         ids_cache = []
#         for i in range(n):
#             patient = str(df.iloc[i]['patient_id'])
#             scan = str(df.iloc[i]['image_id'])
#             paths.append(self.train_path + '/' + patient + '/' + scan + '.dcm')
#             ids_cache.append({'patient_id': patient, 'scan_id': scan})
#         if return_cache:
#             return paths, ids_cache
#         else:
#             return paths
    
    # Read from a path and convert to image array
    def read_image(self, path: str):
        scan = pydicom.dcmread(path)
        img = scan.pixel_array
        return img
    
    

    def apply_canny(self,image):
        from skimage.feature import canny
        from skimage.filters import sobel
        canny_img = canny(image, .0001)
#         plt.imshow(canny_img)
        return sobel(canny_img)
    
    
    
    def get_hough_lines(self,canny_img):
        from skimage.transform import hough_line, hough_line_peaks
        h, theta, d = hough_line(canny_img)
        lines = list()
#         print('\nAll hough lines')
        for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):
#             print("Angle: {:.2f}, Dist: {:.2f}".format(np.degrees(angle), dist))
            x1 = 0
            y1 = (dist - x1 * np.cos(angle)) / np.sin(angle)
            x2 = canny_img.shape[1]
            y2 = (dist - x2 * np.cos(angle)) / np.sin(angle)
            lines.append({
                'dist': dist,
                'angle': np.degrees(angle),
                'point1': [x1, y1],
                'point2': [x2, y2]
            })
        return lines
    
    
    def shortlist_lines(self,lines):
        MIN_ANGLE = 10
        MAX_ANGLE = 80
        MIN_DIST  = 5
        MAX_DIST  = 6000
        shortlisted_lines = [x for x in lines if 
                              (x['dist']>=MIN_DIST) &
                              (x['dist']<=MAX_DIST) &
                              (x['angle']>=MIN_ANGLE) &
                              (x['angle']<=MAX_ANGLE)
                            ]
#         print('\nShorlisted lines')
#         for i in shortlisted_lines:
#             print("Angle: {:.2f}, Dist: {:.2f}".format(i['angle'], i['dist']))
        return shortlisted_lines
    
    
    
    def remove_pectoral(self,shortlisted_lines,img):
        from skimage.draw import polygon
#         print (shortlisted_lines)
        shortlisted_lines.sort(key = lambda x: x['dist'])
#         try:
        pectoral_line = shortlisted_lines[0]
        if pectoral_line['dist'] > np.max([img.shape[0],img.shape[1]]):
            d = pectoral_line['dist']*.3
        else:
            d = pectoral_line['dist']*.7
        theta = np.radians(pectoral_line['angle'])   
        x_intercept = d/np.cos(theta)
        y_intercept = d/np.sin(theta)    
        return polygon([0, 0, y_intercept], [0, x_intercept, 0])


    ##################################################################
    ########## Single Image Preprocessing Final Function #############
    ##################################################################
    # Apply the preprocessing methods on one image
    def preprocess_single_image(self, path: str, save: bool=False,
                                save_dir: str=None, png: bool=True):
        scan = dicomsdl.open(path)
        img = scan.pixelData()
        dim=(img.shape[0],img.shape[1])
        n=.04
        img = self._fix_photometric_interpretation(img, scan)
        #img = self._normalize_to_255(img)
        img=255*(img/np.max(img))
        img = img[int(0+dim[0]*n*1.5):int(dim[0]-dim[0]*n*1.5),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
        breast_mask=segment_breast(img,low_int_threshold=1, crop=True)
#         img=remove_pectoral( img, breast_mask, high_int_threshold=.99, 
#                     morph_kn_size=40, n_morph_op=10, sm_kn_size=40)
#         img = self._windowing(img, scan)
        
        img = self._flip_breast_side(img)
        img = self._crop(img)
        
        
#         if 'MLO' in path:          
#             canny = self.apply_canny(img)
#             line = self.get_hough_lines(canny)
#             short = self.shortlist_lines(line)
#             try:
#                 rr, cc = self.remove_pectoral(short,img)
#     #             plt.plot(rr,cc)
#                 img[rr, cc] = 0
#                 breast_mask=segment_breast(img,low_int_threshold=1, crop=True)
#                 img = self._crop(img)
#             except:
#                 print ("removal didn't work")
#         breast_mask=segment_breast(img,low_int_threshold=1, crop=True)
#         img = self._crop(img)
        
        clahe = cv2.createCLAHE(clipLimit = 3,tileGridSize=(6,6))
        img = clahe.apply(img)
        
        if self.size:
            img = self._resize(img)

#         img=(img-np.min(img))/(np.max(img)-np.min(img))*255
#         img=img.astype('uint8')
        img=np.expand_dims(img, 2)
        img=np.tile(img, [1,1,3])
        from scipy import stats as st
        mode = st.mode(st.mode(img)[0][0])[0][0][0]
        img[img<=mode]=0
        return img
    

    
#     # Adjust the contrast of an image
#     def _windowing(self, img, scan):
#         center = (2**8-1)-60
#         width = 60
#         bits_stored = scan.BitsStored
#         function = scan.VOILUTFunction
#         if isinstance(center, list):
#             center = center[0]
#         if isinstance(width, list):
#             width = width[0] 
#         y_range = float(2**bits_stored - 1)
#         if function == 'SIGMOID':
#             img = y_range / (1 + np.exp(-4 * (img - center) / width))
#         else: # LINEAR
#             center -= 0.5
#             width -= 1
#             below = img <= (center - width / 2)
#             above = img > (center + width / 2)
#             between = np.logical_and(~below, ~above)
#             img[below] = 0
#             img[above] = y_range
#             img[between] = ((img[between] - center) / width + 0.5) * y_range
#         return img
    
    # Interpret pixels in a consistant way
    def _fix_photometric_interpretation(self, img, scan):
        if scan.PhotometricInterpretation == 'MONOCHROME1':
            return img.max() - img
        elif scan.PhotometricInterpretation == 'MONOCHROME2':
            return img - img.min()
        else:
            raise ValueError("Invalid Photometric Interpretation: {}"
                               .format(scan.PhotometricInterpretation))
    
    # Cast into 8-bits for saving
    def _normalize_to_255(self, img):
        if img.max() != 0:
            img = img / img.max()
        img *= 255
        return img.astype(np.uint8)
    
    # Flip the breast horizontally on the chosen side 
    def _flip_breast_side(self, img):
        img_breast_side = self._determine_breast_side(img)
        if img_breast_side == self.breast_side:
            return img
        else:
            return np.fliplr(img)    
    
    # Determine the current breast side
    def _determine_breast_side(self, img):
        col_sums_split = np.array_split(np.sum(img, axis=0), 2)
        left_col_sum = np.sum(col_sums_split[0])
        right_col_sum = np.sum(col_sums_split[1])
        if left_col_sum > right_col_sum:
            return 'L'
        else:
            return 'R'
    
    # Crop the useless background of the image
    def _crop(self, img):
        try:
            bin_img = self._binarize(img, threshold=1)
            contour = self._extract_contour(bin_img)
            img = self._erase_background(img, contour)
            x1, x2 = np.min(contour[:, :, 0]), np.max(contour[:, :, 0])
            y1, y2 = np.min(contour[:, :, 1]), np.max(contour[:, :, 1])
#             x1, x2 = int(0.99 * x1), int(1.01 * x2)
#             y1, y2 = int(0.99 * y1), int(1.01 * y2)
            return img[y1:y2, x1:x2]
        except:
            print ('crop didnt work')
            return img
    
    # Binarize the image at the threshold
    def _binarize(self, img, threshold):
        return (img > threshold).astype(np.uint8)
    
    # Get contour points of the breast
    def _extract_contour(self, bin_img):
        contours, _ = cv2.findContours(
            bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
        contour = max(contours, key=cv2.contourArea)
        return contour
    
    # Set to background pixels of the image to zero
    def _erase_background(self, img, contour):
        mask = np.zeros(img.shape, np.uint8)
        cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED)
        output = cv2.bitwise_and(img, mask)
        return output
    
    # Resize the image to the preprocessor size
    def _resize(self, img):
        return cv2.resize(img, self.size, interpolation=cv2.INTER_AREA)
    
    # Get the save path of a given dicom file
    def _get_save_path(self, path, png, save_dir):
        patient = path.split('/')[-2]
        filename = path.split('/')[-1]
        if png:
            filename = filename.replace('dcm', 'png')
        else:
            filename = filename.replace('dcm', 'jpeg')
        if save_dir:
            save_path = os.path.join(self.save_root, save_dir, patient, filename)
        else:
            save_path = os.path.join(self.save_root, patient, filename)
        return save_path
    
    # Save the preprocessed image
    def _save_image(self, img, path, png, save_dir):
        save_path = self._get_save_path(path, png, save_dir)
        patient_folder = os.path.split(save_path)[0]
        os.makedirs(patient_folder, exist_ok=True)
        cv2.imwrite(save_path, img)
        
def OpenMask(mask, ksize=(23, 23), operation="open"):
    kernel = cv2.getStructuringElement(shape=cv2.MORPH_RECT, ksize=ksize)    
    if operation == "open":
        edited_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    elif operation == "close":
        edited_mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)    
    # Then dilate
    edited_mask = cv2.morphologyEx(edited_mask, cv2.MORPH_DILATE, kernel)
    return edited_mask

def SortContoursByArea(contours, reverse=True):   
    '''
    ----------
    contours : {list}
        The list of contours to sort.        
    Returns
    -------
    sorted_contours : {list}
        The list of contours sorted by contour area in descending
        order.
    bounding_boxes : {list}
        The list of bounding boxes ordered corresponding to the
        contours in `sorted_contours`.
    '''   
    # Sort contours based on contour area.
    sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)    
    # Construct the list of corresponding bounding boxes.
    bounding_boxes = [cv2.boundingRect(c) for c in sorted_contours]
    return sorted_contours, bounding_boxes

def DrawContourID(img, bounding_box, contour_id):    
    '''
    ----------
    img: {numpy.ndarray}
        The image to draw the contour on.
    bounding_box : {tuple of int}
        The bounding_rect of the given contour.
    contour_id : {int or float}
        The corresponding ID of the given `contour`.        
    Returns
    -------
    img : {numpy.ndarray}
        The image after the `contour` and its ID is drawn on.
    ''' 
    # Center of bounding_rect.
    x, y, w, h = bounding_box
    center = ( ((x + w) // 2), ((y + h) // 2) )
    # Draw the countour number on the image
    cv2.putText(img=img,
                text=f"{contour_id}",
                org=center, # Bottom-left corner of the text string in the image.
                fontFace=cv2.FONT_HERSHEY_SIMPLEX,
                fontScale=10, 
                color=(255, 255, 255),
                thickness=40)
    return img

def XLargestBlobs(mask, top_X=None):
    
    '''
    ----------
    mask : {numpy.ndarray, dtype=np.uint8}
        The mask to get the top X largest blobs.
    top_X : {int}
        The top X contours to keep based on contour area
        ranked in decesnding order.
    Returns
    -------
    n_contours : {int}
        The number of contours found in the given `mask`.
    X_largest_blobs : {numpy.ndarray}
        The corresponding mask of the image containing only
        the top X largest contours in white.
    '''        
    # Find all contours from binarised image.
    # Note: parts of the image that you want to get should be white.
    contours, hierarchy = cv2.findContours(image=mask,
                                           mode=cv2.RETR_EXTERNAL,
                                           method=cv2.CHAIN_APPROX_NONE)   
    n_contours = len(contours)    
    # Only get largest blob if there is at least 1 contour.
    if n_contours > 0:        
        # Make sure that the number of contours to keep is at most equal 
        # to the number of contours present in the mask.
        if n_contours < top_X or top_X == None:
            top_X = n_contours        
        # Sort contours based on contour area.
        sorted_contours, bounding_boxes = SortContoursByArea(contours=contours,
                                                             reverse=True)        
        # Get the top X largest contours.
        X_largest_contours = sorted_contours[0:top_X]        
        # Create black canvas to draw contours on.
        to_draw_on = np.zeros(mask.shape, np.uint8)        
        # Draw contours in X_largest_contours.
        X_largest_blobs = cv2.drawContours(image=to_draw_on, # Draw the contours on `to_draw_on`.
                                           contours=X_largest_contours, # List of contours to draw.
                                           contourIdx=-1, # Draw all contours in `contours`.
                                           color=1, # Draw the contours in white.
                                           thickness=-1) # Thickness of the contour lines.        
    return n_contours, X_largest_blobs


import cv2
import numpy as np





def select_largest_obj(img_bin, lab_val=255, fill_holes=False, 
                       smooth_boundary=False, kernel_size=15):
    '''Select the largest object from a binary image and optionally
    fill holes inside it and smooth its boundary.
    Args:
        img_bin (2D array): 2D numpy array of binary image.
        lab_val ([int]): integer value used for the label of the largest 
                object. Default is 255.
        fill_holes ([boolean]): whether fill the holes inside the largest 
                object or not. Default is false.
        smooth_boundary ([boolean]): whether smooth the boundary of the 
                largest object using morphological opening or not. Default 
                is false.
        kernel_size ([int]): the size of the kernel used for morphological 
                operation. Default is 15.
    Returns:
        a binary image as a mask for the largest object.
    '''
    n_labels, img_labeled, lab_stats, _ = \
        cv2.connectedComponentsWithStats(img_bin, connectivity=8, 
                                         ltype=cv2.CV_32S)
    largest_obj_lab = np.argmax(lab_stats[1:, 4]) + 1
    largest_mask = np.zeros(img_bin.shape, dtype=np.uint8)
    largest_mask[img_labeled == largest_obj_lab] = lab_val
    # import pdb; pdb.set_trace()
    if fill_holes:
        bkg_locs = np.where(img_labeled == 0)
        bkg_seed = (bkg_locs[0][0], bkg_locs[1][0])
        img_floodfill = largest_mask.copy()
        h_, w_ = largest_mask.shape
        mask_ = np.zeros((h_ + 2, w_ + 2), dtype=np.uint8)
        cv2.floodFill(img_floodfill, mask_, seedPoint=bkg_seed, 
                      newVal=lab_val)
        holes_mask = cv2.bitwise_not(img_floodfill)  # mask of the holes.
        largest_mask = largest_mask + holes_mask
    if smooth_boundary:
        kernel_ = np.ones((kernel_size, kernel_size), dtype=np.uint8)
        largest_mask = cv2.morphologyEx(largest_mask, cv2.MORPH_OPEN, 
                                        kernel_)

    return largest_mask


def max_pix_val(dtype):
    if dtype == np.dtype('uint8'):
        maxval = 2**8 - 1
    elif dtype == np.dtype('uint16'):
        maxval = 2**16 - 1
    else:
        raise Exception('Unknown dtype found in input image array')
    return maxval


def suppress_artifacts( img, global_threshold=.05, fill_holes=False, 
                       smooth_boundary=True, kernel_size=15):
    '''Mask artifacts from an input image
    Artifacts refer to textual markings and other small objects that are 
    not related to the breast region.
    Args:
        img (2D array): input image as a numpy 2D array.
        global_threshold ([int]): a global threshold as a cutoff for low 
                intensities for image binarization. Default is 18.
        kernel_size ([int]): kernel size for morphological operations. 
                Default is 15.
    Returns:
        a tuple of (output_image, breast_mask). Both are 2D numpy arrays.
    '''
    maxval = max_pix_val(img.dtype)
    if global_threshold < 1.:
        low_th = int(img.max()*global_threshold)
    else:
        low_th = int(global_threshold)
    _, img_bin = cv2.threshold(img, low_th, maxval=maxval, 
                               type=cv2.THRESH_BINARY)
    breast_mask = select_largest_obj(img_bin, lab_val=maxval, 
                                          fill_holes=True, 
                                          smooth_boundary=True, 
                                          kernel_size=kernel_size)
    img_suppr = cv2.bitwise_and(img, breast_mask)

    return img_suppr


def segment_breast(img, low_int_threshold=.05, crop=True):
    '''Perform breast segmentation
    Args:
        low_int_threshold([float or int]): Low intensity threshold to 
                filter out background. It can be a fraction of the max 
                intensity value or an integer intensity value.
        crop ([bool]): Whether or not to crop the image.
    Returns:
        An image of the segmented breast.
    NOTES: the low_int_threshold is applied to an image of dtype 'uint8',
        which has a max value of 255.
    '''
    # Create img for thresholding and contours.
    img_8u = (img.astype('float32')/img.max()*255).astype('uint8')
    if low_int_threshold < 1.:
        low_th = int(img_8u.max()*low_int_threshold)
    else:
        low_th = int(low_int_threshold)
    _, img_bin = cv2.threshold(
        img_8u, low_th, maxval=255, type=cv2.THRESH_BINARY)
    ver = (cv2.__version__).split('.')
    if int(ver[0]) < 3:
        contours,_ = cv2.findContours(
            img_bin.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    else:
        contours,_ = cv2.findContours(
            img_bin.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cont_areas = [ cv2.contourArea(cont) for cont in contours ]
    idx = np.argmax(cont_areas)  # find the largest contour, i.e. breast.
    breast_mask = cv2.drawContours(
        np.zeros_like(img_bin), contours, idx, 255, -1)  # fill the contour.
#     # segment the breast.
#     img_breast_only = cv2.bitwise_and(img, img, mask=breast_mask)
#     x,y,w,h = cv2.boundingRect(contours[idx])
#     if crop:
#         img_breast_only = img_breast_only[y:y+h, x:x+w]
    return  breast_mask


def remove_pectoral( img, breast_mask, high_int_threshold=.8, 
                    morph_kn_size=3, n_morph_op=7, sm_kn_size=25):
    '''Remove the pectoral muscle region from an input image
    Args:
        img (2D array): input image as a numpy 2D array.
        breast_mask (2D array):
        high_int_threshold ([int]): a global threshold for high intensity 
                regions such as the pectoral muscle. Default is 200.
        morph_kn_size ([int]): kernel size for morphological operations 
                such as erosions and dilations. Default is 3.
        n_morph_op ([int]): number of morphological operations. Default is 7.
        sm_kn_size ([int]): kernel size for final smoothing (i.e. opening). 
                Default is 25.
    Returns:
        an output image with pectoral muscle region removed as a numpy 
        2D array.
    Notes: this has not been tested on .dcm files yet. It may not work!!!
    '''
    # Enhance contrast and then thresholding.
    img_equ = cv2.equalizeHist(img)
    if high_int_threshold < 1.:
        high_th = int(img.max()*high_int_threshold)
    else:
        high_th = int(high_int_threshold)
    maxval = max_pix_val(img.dtype)
    _, img_bin = cv2.threshold(img_equ, high_th, 
                               maxval=maxval, type=cv2.THRESH_BINARY)
    pect_marker_img = np.zeros(img_bin.shape, dtype=np.int32)
    # Sure foreground (shall be pectoral).
    pect_mask_init = select_largest_obj(img_bin, lab_val=maxval, 
                                             fill_holes=True, 
                                             smooth_boundary=False)
    kernel_ = np.ones((morph_kn_size, morph_kn_size), dtype=np.uint8)
    pect_mask_eroded = cv2.erode(pect_mask_init, kernel_, 
                                 iterations=n_morph_op)
    pect_marker_img[pect_mask_eroded > 0] = 255
    # Sure background - breast.
    pect_mask_dilated = cv2.dilate(pect_mask_init, kernel_, 
                                   iterations=n_morph_op)
    pect_marker_img[pect_mask_dilated == 0] = 128
    # Sure background - pure background.
    pect_marker_img[breast_mask == 0] = 64
    # Watershed segmentation.
    img_equ_3c = cv2.cvtColor(img_equ, cv2.COLOR_GRAY2BGR)
    cv2.watershed(img_equ_3c, pect_marker_img)
    img_equ_3c[pect_marker_img == -1] = (0, 0, 255)
    # Extract only the breast and smooth.
    breast_only_mask = pect_marker_img.copy()
    breast_only_mask[breast_only_mask == -1] = 0
    breast_only_mask = breast_only_mask.astype(np.uint8)
    breast_only_mask[breast_only_mask != 128] = 0
    breast_only_mask[breast_only_mask == 128] = 255
    kernel_ = np.ones((sm_kn_size, sm_kn_size), dtype=np.uint8)
    breast_only_mask = cv2.morphologyEx(breast_only_mask, cv2.MORPH_OPEN, 
                                        kernel_)
    img_breast_only = cv2.bitwise_and(img_equ, breast_only_mask)

    return (img_breast_only)


def process(self, img, median_filtering=True, blur_kn_size=3, 
            artif_suppression=True, low_int_threshold=.05, kernel_size=15,
            pect_removal=False, high_int_threshold=.8, **pect_kwargs):
    '''Perform multi-stage preprocessing on the input image
    Args:
        blur_kn_size ([int]): kernel size for median blurring.
        low_int_threshold ([int]): cutoff used in artifacts suppression.
        high_int_threshold ([int]): cutoff used in pectoral muscle removal.
    Returns:
        a tuple of (processed_image, color_image_with_boundary). If 
        pectoral removal was not called, the color image is None.
    '''
    img_proc = img.copy()
    if median_filtering:
        img_proc = cv2.medianBlur(img_proc, blur_kn_size)
    if artif_suppression:
        img_proc, mask_ = self.suppress_artifacts(
            img_proc, global_threshold=low_int_threshold, 
            kernel_size=kernel_size)
    else:
        _, mask_ = self.suppress_artifacts(img_proc)
    if pect_removal:
        img_proc, img_col = self.remove_pectoral(
            img_proc, mask_, high_int_threshold=high_int_threshold, 
            **pect_kwargs)
    else:
        img_col = None

    return (img_proc, img_col)
41/6:
def preprocess_new(image):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image)
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(12,12))
    image = clahe.apply(image)
#     #image = (image/np.max(image))*255
#     #image = image.astype('uint8')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    return image
41/7: im=cv2.imread('/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-png/Calc-Test_P_00038_LEFT_CC/1-1.png')
41/8:
image=preprocess_new(im)
plt.imshow(image)
41/9: im.shape
41/10:
def preprocess_new(image):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:.:.0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(12,12))
    image = clahe.apply(image)
#     #image = (image/np.max(image))*255
#     #image = image.astype('uint8')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    return image
41/11:
def preprocess_new(image):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(12,12))
    image = clahe.apply(image)
#     #image = (image/np.max(image))*255
#     #image = image.astype('uint8')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    return image
41/12:
image=preprocess_new(im)
plt.imshow(image)
41/13:
image=preprocess_new(im)
plt.imshow(image[:,:,0])
41/14:
def preprocess_new(image):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    #image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(12,12))
    image = clahe.apply(image)
#     #image = (image/np.max(image))*255
#     #image = image.astype('uint8')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    return image
41/15:
image=preprocess_new(im)
plt.imshow(image[:,:,0])
41/16:
def preprocess_new(image):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=_crop(image)
    #image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(12,12))
    image = clahe.apply(image)
#     #image = (image/np.max(image))*255
#     #image = image.astype('uint8')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    return image
41/17:
image=preprocess_new(im)
plt.imshow(image[:,:,0])
41/18:
class MammographyPreprocessor():
    
    # Constructor
    def __init__(self, size: tuple=None, breast_side: str='L',
                 csv_path=None, train_path=None):
        self.size = size
        os.makedirs(os.getcwd(), exist_ok=True)
        self.breast_side = breast_side
        assert breast_side in ['L', 'R'], "breast_side should be 'L' or 'R'"
        # implement the paths of the original RSNA dataset (V2)
#         self.csv_path = '/kaggle/input/rsna-breast-cancer-detection/train.csv'
#         self.train_path = '/kaggle/input/rsna-breast-cancer-detection/train_images'
#         if csv_path:
#             self.csv_path = csv_path
#         if train_path:
#             self.train_path = train_path
#         self.df = pd.read_csv(self.csv_path)
        self.save_root = os.getcwd()
    
#     # Get the paths from the preprocessor (V2)
#     def get_paths(self, n: int=None, shuffle: bool=False, return_cache: bool=False):
#         if n == None:
#             n = len(self.df)
#         if shuffle == True:
#             df = self.df.sample(frac=1, random_state=0).copy()
#         else:
#             df = self.df.copy()
#         paths = []
#         ids_cache = []
#         for i in range(n):
#             patient = str(df.iloc[i]['patient_id'])
#             scan = str(df.iloc[i]['image_id'])
#             paths.append(self.train_path + '/' + patient + '/' + scan + '.dcm')
#             ids_cache.append({'patient_id': patient, 'scan_id': scan})
#         if return_cache:
#             return paths, ids_cache
#         else:
#             return paths
    
    # Read from a path and convert to image array
    def read_image(self, path: str):
        scan = pydicom.dcmread(path)
        img = scan.pixel_array
        return img
    
    

    def apply_canny(self,image):
        from skimage.feature import canny
        from skimage.filters import sobel
        canny_img = canny(image, .0001)
#         plt.imshow(canny_img)
        return sobel(canny_img)
    
    
    
    def get_hough_lines(self,canny_img):
        from skimage.transform import hough_line, hough_line_peaks
        h, theta, d = hough_line(canny_img)
        lines = list()
#         print('\nAll hough lines')
        for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):
#             print("Angle: {:.2f}, Dist: {:.2f}".format(np.degrees(angle), dist))
            x1 = 0
            y1 = (dist - x1 * np.cos(angle)) / np.sin(angle)
            x2 = canny_img.shape[1]
            y2 = (dist - x2 * np.cos(angle)) / np.sin(angle)
            lines.append({
                'dist': dist,
                'angle': np.degrees(angle),
                'point1': [x1, y1],
                'point2': [x2, y2]
            })
        return lines
    
    
    def shortlist_lines(self,lines):
        MIN_ANGLE = 10
        MAX_ANGLE = 80
        MIN_DIST  = 5
        MAX_DIST  = 6000
        shortlisted_lines = [x for x in lines if 
                              (x['dist']>=MIN_DIST) &
                              (x['dist']<=MAX_DIST) &
                              (x['angle']>=MIN_ANGLE) &
                              (x['angle']<=MAX_ANGLE)
                            ]
#         print('\nShorlisted lines')
#         for i in shortlisted_lines:
#             print("Angle: {:.2f}, Dist: {:.2f}".format(i['angle'], i['dist']))
        return shortlisted_lines
    
    
    
    def remove_pectoral(self,shortlisted_lines,img):
        from skimage.draw import polygon
#         print (shortlisted_lines)
        shortlisted_lines.sort(key = lambda x: x['dist'])
#         try:
        pectoral_line = shortlisted_lines[0]
        if pectoral_line['dist'] > np.max([img.shape[0],img.shape[1]]):
            d = pectoral_line['dist']*.3
        else:
            d = pectoral_line['dist']*.7
        theta = np.radians(pectoral_line['angle'])   
        x_intercept = d/np.cos(theta)
        y_intercept = d/np.sin(theta)    
        return polygon([0, 0, y_intercept], [0, x_intercept, 0])


    ##################################################################
    ########## Single Image Preprocessing Final Function #############
    ##################################################################
    # Apply the preprocessing methods on one image
    def preprocess_single_image(self, path: str, save: bool=False,
                                save_dir: str=None, png: bool=True):
        scan = dicomsdl.open(path)
        img = scan.pixelData()
        dim=(img.shape[0],img.shape[1])
        n=.04
        img = self._fix_photometric_interpretation(img, scan)
        #img = self._normalize_to_255(img)
        img=255*(img/np.max(img))
        img = img[int(0+dim[0]*n*1.5):int(dim[0]-dim[0]*n*1.5),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
        breast_mask=segment_breast(img,low_int_threshold=1, crop=True)
#         img=remove_pectoral( img, breast_mask, high_int_threshold=.99, 
#                     morph_kn_size=40, n_morph_op=10, sm_kn_size=40)
#         img = self._windowing(img, scan)
        
        img = self._flip_breast_side(img)
        img = self._crop(img)
        
        
#         if 'MLO' in path:          
#             canny = self.apply_canny(img)
#             line = self.get_hough_lines(canny)
#             short = self.shortlist_lines(line)
#             try:
#                 rr, cc = self.remove_pectoral(short,img)
#     #             plt.plot(rr,cc)
#                 img[rr, cc] = 0
#                 breast_mask=segment_breast(img,low_int_threshold=1, crop=True)
#                 img = self._crop(img)
#             except:
#                 print ("removal didn't work")
#         breast_mask=segment_breast(img,low_int_threshold=1, crop=True)
#         img = self._crop(img)
        
        clahe = cv2.createCLAHE(clipLimit = 3,tileGridSize=(6,6))
        img = clahe.apply(img)
        
        if self.size:
            img = self._resize(img)

#         img=(img-np.min(img))/(np.max(img)-np.min(img))*255
#         img=img.astype('uint8')
        img=np.expand_dims(img, 2)
        img=np.tile(img, [1,1,3])
        from scipy import stats as st
        mode = st.mode(st.mode(img)[0][0])[0][0][0]
        img[img<=mode]=0
        return img
    

    
#     # Adjust the contrast of an image
#     def _windowing(self, img, scan):
#         center = (2**8-1)-60
#         width = 60
#         bits_stored = scan.BitsStored
#         function = scan.VOILUTFunction
#         if isinstance(center, list):
#             center = center[0]
#         if isinstance(width, list):
#             width = width[0] 
#         y_range = float(2**bits_stored - 1)
#         if function == 'SIGMOID':
#             img = y_range / (1 + np.exp(-4 * (img - center) / width))
#         else: # LINEAR
#             center -= 0.5
#             width -= 1
#             below = img <= (center - width / 2)
#             above = img > (center + width / 2)
#             between = np.logical_and(~below, ~above)
#             img[below] = 0
#             img[above] = y_range
#             img[between] = ((img[between] - center) / width + 0.5) * y_range
#         return img
    
    # Interpret pixels in a consistant way
    def _fix_photometric_interpretation(self, img, scan):
        if scan.PhotometricInterpretation == 'MONOCHROME1':
            return img.max() - img
        elif scan.PhotometricInterpretation == 'MONOCHROME2':
            return img - img.min()
        else:
            raise ValueError("Invalid Photometric Interpretation: {}"
                               .format(scan.PhotometricInterpretation))
    
    # Cast into 8-bits for saving
    def _normalize_to_255(self, img):
        if img.max() != 0:
            img = img / img.max()
        img *= 255
        return img.astype(np.uint8)
    
    # Flip the breast horizontally on the chosen side 
    def _flip_breast_side(self, img):
        img_breast_side = self._determine_breast_side(img)
        if img_breast_side == self.breast_side:
            return img
        else:
            return np.fliplr(img)    
    
    # Determine the current breast side
    def _determine_breast_side(self, img):
        col_sums_split = np.array_split(np.sum(img, axis=0), 2)
        left_col_sum = np.sum(col_sums_split[0])
        right_col_sum = np.sum(col_sums_split[1])
        if left_col_sum > right_col_sum:
            return 'L'
        else:
            return 'R'
    
    # Crop the useless background of the image
    def _crop(self, img):
        try:
            bin_img = self._binarize(img, threshold=1)
            contour = self._extract_contour(bin_img)
            img = self._erase_background(img, contour)
            x1, x2 = np.min(contour[:, :, 0]), np.max(contour[:, :, 0])
            y1, y2 = np.min(contour[:, :, 1]), np.max(contour[:, :, 1])
#             x1, x2 = int(0.99 * x1), int(1.01 * x2)
#             y1, y2 = int(0.99 * y1), int(1.01 * y2)
            return img[y1:y2, x1:x2]
        except:
            print ('crop didnt work')
            return img
    
    # Binarize the image at the threshold
    def _binarize(self, img, threshold):
        return (img > threshold).astype(np.uint8)
    
    # Get contour points of the breast
    def _extract_contour(self, bin_img):
        contours, _ = cv2.findContours(
            bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
        contour = max(contours, key=cv2.contourArea)
        return contour
    
    # Set to background pixels of the image to zero
    def _erase_background(self, img, contour):
        mask = np.zeros(img.shape, np.uint8)
        cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED)
        output = cv2.bitwise_and(img, mask)
        return output
    
    # Resize the image to the preprocessor size
    def _resize(self, img):
        return cv2.resize(img, self.size, interpolation=cv2.INTER_AREA)
    
    # Get the save path of a given dicom file
    def _get_save_path(self, path, png, save_dir):
        patient = path.split('/')[-2]
        filename = path.split('/')[-1]
        if png:
            filename = filename.replace('dcm', 'png')
        else:
            filename = filename.replace('dcm', 'jpeg')
        if save_dir:
            save_path = os.path.join(self.save_root, save_dir, patient, filename)
        else:
            save_path = os.path.join(self.save_root, patient, filename)
        return save_path
    
    # Save the preprocessed image
    def _save_image(self, img, path, png, save_dir):
        save_path = self._get_save_path(path, png, save_dir)
        patient_folder = os.path.split(save_path)[0]
        os.makedirs(patient_folder, exist_ok=True)
        cv2.imwrite(save_path, img)
        
def OpenMask(mask, ksize=(23, 23), operation="open"):
    kernel = cv2.getStructuringElement(shape=cv2.MORPH_RECT, ksize=ksize)    
    if operation == "open":
        edited_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    elif operation == "close":
        edited_mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)    
    # Then dilate
    edited_mask = cv2.morphologyEx(edited_mask, cv2.MORPH_DILATE, kernel)
    return edited_mask

def SortContoursByArea(contours, reverse=True):   
    '''
    ----------
    contours : {list}
        The list of contours to sort.        
    Returns
    -------
    sorted_contours : {list}
        The list of contours sorted by contour area in descending
        order.
    bounding_boxes : {list}
        The list of bounding boxes ordered corresponding to the
        contours in `sorted_contours`.
    '''   
    # Sort contours based on contour area.
    sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)    
    # Construct the list of corresponding bounding boxes.
    bounding_boxes = [cv2.boundingRect(c) for c in sorted_contours]
    return sorted_contours, bounding_boxes

def DrawContourID(img, bounding_box, contour_id):    
    '''
    ----------
    img: {numpy.ndarray}
        The image to draw the contour on.
    bounding_box : {tuple of int}
        The bounding_rect of the given contour.
    contour_id : {int or float}
        The corresponding ID of the given `contour`.        
    Returns
    -------
    img : {numpy.ndarray}
        The image after the `contour` and its ID is drawn on.
    ''' 
    # Center of bounding_rect.
    x, y, w, h = bounding_box
    center = ( ((x + w) // 2), ((y + h) // 2) )
    # Draw the countour number on the image
    cv2.putText(img=img,
                text=f"{contour_id}",
                org=center, # Bottom-left corner of the text string in the image.
                fontFace=cv2.FONT_HERSHEY_SIMPLEX,
                fontScale=10, 
                color=(255, 255, 255),
                thickness=40)
    return img

def XLargestBlobs(mask, top_X=None):
    
    '''
    ----------
    mask : {numpy.ndarray, dtype=np.uint8}
        The mask to get the top X largest blobs.
    top_X : {int}
        The top X contours to keep based on contour area
        ranked in decesnding order.
    Returns
    -------
    n_contours : {int}
        The number of contours found in the given `mask`.
    X_largest_blobs : {numpy.ndarray}
        The corresponding mask of the image containing only
        the top X largest contours in white.
    '''        
    # Find all contours from binarised image.
    # Note: parts of the image that you want to get should be white.
    contours, hierarchy = cv2.findContours(image=mask,
                                           mode=cv2.RETR_EXTERNAL,
                                           method=cv2.CHAIN_APPROX_NONE)   
    n_contours = len(contours)    
    # Only get largest blob if there is at least 1 contour.
    if n_contours > 0:        
        # Make sure that the number of contours to keep is at most equal 
        # to the number of contours present in the mask.
        if n_contours < top_X or top_X == None:
            top_X = n_contours        
        # Sort contours based on contour area.
        sorted_contours, bounding_boxes = SortContoursByArea(contours=contours,
                                                             reverse=True)        
        # Get the top X largest contours.
        X_largest_contours = sorted_contours[0:top_X]        
        # Create black canvas to draw contours on.
        to_draw_on = np.zeros(mask.shape, np.uint8)        
        # Draw contours in X_largest_contours.
        X_largest_blobs = cv2.drawContours(image=to_draw_on, # Draw the contours on `to_draw_on`.
                                           contours=X_largest_contours, # List of contours to draw.
                                           contourIdx=-1, # Draw all contours in `contours`.
                                           color=1, # Draw the contours in white.
                                           thickness=-1) # Thickness of the contour lines.        
    return n_contours, X_largest_blobs


import cv2
import numpy as np





def select_largest_obj(img_bin, lab_val=255, fill_holes=False, 
                       smooth_boundary=False, kernel_size=15):
    '''Select the largest object from a binary image and optionally
    fill holes inside it and smooth its boundary.
    Args:
        img_bin (2D array): 2D numpy array of binary image.
        lab_val ([int]): integer value used for the label of the largest 
                object. Default is 255.
        fill_holes ([boolean]): whether fill the holes inside the largest 
                object or not. Default is false.
        smooth_boundary ([boolean]): whether smooth the boundary of the 
                largest object using morphological opening or not. Default 
                is false.
        kernel_size ([int]): the size of the kernel used for morphological 
                operation. Default is 15.
    Returns:
        a binary image as a mask for the largest object.
    '''
    n_labels, img_labeled, lab_stats, _ = \
        cv2.connectedComponentsWithStats(img_bin, connectivity=8, 
                                         ltype=cv2.CV_32S)
    largest_obj_lab = np.argmax(lab_stats[1:, 4]) + 1
    largest_mask = np.zeros(img_bin.shape, dtype=np.uint8)
    largest_mask[img_labeled == largest_obj_lab] = lab_val
    # import pdb; pdb.set_trace()
    if fill_holes:
        bkg_locs = np.where(img_labeled == 0)
        bkg_seed = (bkg_locs[0][0], bkg_locs[1][0])
        img_floodfill = largest_mask.copy()
        h_, w_ = largest_mask.shape
        mask_ = np.zeros((h_ + 2, w_ + 2), dtype=np.uint8)
        cv2.floodFill(img_floodfill, mask_, seedPoint=bkg_seed, 
                      newVal=lab_val)
        holes_mask = cv2.bitwise_not(img_floodfill)  # mask of the holes.
        largest_mask = largest_mask + holes_mask
    if smooth_boundary:
        kernel_ = np.ones((kernel_size, kernel_size), dtype=np.uint8)
        largest_mask = cv2.morphologyEx(largest_mask, cv2.MORPH_OPEN, 
                                        kernel_)

    return largest_mask


def max_pix_val(dtype):
    if dtype == np.dtype('uint8'):
        maxval = 2**8 - 1
    elif dtype == np.dtype('uint16'):
        maxval = 2**16 - 1
    else:
        raise Exception('Unknown dtype found in input image array')
    return maxval


def suppress_artifacts( img, global_threshold=.05, fill_holes=False, 
                       smooth_boundary=True, kernel_size=15):
    '''Mask artifacts from an input image
    Artifacts refer to textual markings and other small objects that are 
    not related to the breast region.
    Args:
        img (2D array): input image as a numpy 2D array.
        global_threshold ([int]): a global threshold as a cutoff for low 
                intensities for image binarization. Default is 18.
        kernel_size ([int]): kernel size for morphological operations. 
                Default is 15.
    Returns:
        a tuple of (output_image, breast_mask). Both are 2D numpy arrays.
    '''
    maxval = max_pix_val(img.dtype)
    if global_threshold < 1.:
        low_th = int(img.max()*global_threshold)
    else:
        low_th = int(global_threshold)
    _, img_bin = cv2.threshold(img, low_th, maxval=maxval, 
                               type=cv2.THRESH_BINARY)
    breast_mask = select_largest_obj(img_bin, lab_val=maxval, 
                                          fill_holes=True, 
                                          smooth_boundary=True, 
                                          kernel_size=kernel_size)
    img_suppr = cv2.bitwise_and(img, breast_mask)

    return img_suppr


def segment_breast(img, low_int_threshold=.05, crop=True):
    '''Perform breast segmentation
    Args:
        low_int_threshold([float or int]): Low intensity threshold to 
                filter out background. It can be a fraction of the max 
                intensity value or an integer intensity value.
        crop ([bool]): Whether or not to crop the image.
    Returns:
        An image of the segmented breast.
    NOTES: the low_int_threshold is applied to an image of dtype 'uint8',
        which has a max value of 255.
    '''
    # Create img for thresholding and contours.
    img_8u = (img.astype('float32')/img.max()*255).astype('uint8')
    if low_int_threshold < 1.:
        low_th = int(img_8u.max()*low_int_threshold)
    else:
        low_th = int(low_int_threshold)
    _, img_bin = cv2.threshold(
        img_8u, low_th, maxval=255, type=cv2.THRESH_BINARY)
    ver = (cv2.__version__).split('.')
    if int(ver[0]) < 3:
        contours,_ = cv2.findContours(
            img_bin.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    else:
        contours,_ = cv2.findContours(
            img_bin.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cont_areas = [ cv2.contourArea(cont) for cont in contours ]
    idx = np.argmax(cont_areas)  # find the largest contour, i.e. breast.
    breast_mask = cv2.drawContours(
        np.zeros_like(img_bin), contours, idx, 255, -1)  # fill the contour.
#     # segment the breast.
    img_breast_only = cv2.bitwise_and(img, img, mask=breast_mask)
    x,y,w,h = cv2.boundingRect(contours[idx])
    if crop:
        img_breast_only = img_breast_only[y:y+h, x:x+w]
    return  breast_mask


def remove_pectoral( img, breast_mask, high_int_threshold=.8, 
                    morph_kn_size=3, n_morph_op=7, sm_kn_size=25):
    '''Remove the pectoral muscle region from an input image
    Args:
        img (2D array): input image as a numpy 2D array.
        breast_mask (2D array):
        high_int_threshold ([int]): a global threshold for high intensity 
                regions such as the pectoral muscle. Default is 200.
        morph_kn_size ([int]): kernel size for morphological operations 
                such as erosions and dilations. Default is 3.
        n_morph_op ([int]): number of morphological operations. Default is 7.
        sm_kn_size ([int]): kernel size for final smoothing (i.e. opening). 
                Default is 25.
    Returns:
        an output image with pectoral muscle region removed as a numpy 
        2D array.
    Notes: this has not been tested on .dcm files yet. It may not work!!!
    '''
    # Enhance contrast and then thresholding.
    img_equ = cv2.equalizeHist(img)
    if high_int_threshold < 1.:
        high_th = int(img.max()*high_int_threshold)
    else:
        high_th = int(high_int_threshold)
    maxval = max_pix_val(img.dtype)
    _, img_bin = cv2.threshold(img_equ, high_th, 
                               maxval=maxval, type=cv2.THRESH_BINARY)
    pect_marker_img = np.zeros(img_bin.shape, dtype=np.int32)
    # Sure foreground (shall be pectoral).
    pect_mask_init = select_largest_obj(img_bin, lab_val=maxval, 
                                             fill_holes=True, 
                                             smooth_boundary=False)
    kernel_ = np.ones((morph_kn_size, morph_kn_size), dtype=np.uint8)
    pect_mask_eroded = cv2.erode(pect_mask_init, kernel_, 
                                 iterations=n_morph_op)
    pect_marker_img[pect_mask_eroded > 0] = 255
    # Sure background - breast.
    pect_mask_dilated = cv2.dilate(pect_mask_init, kernel_, 
                                   iterations=n_morph_op)
    pect_marker_img[pect_mask_dilated == 0] = 128
    # Sure background - pure background.
    pect_marker_img[breast_mask == 0] = 64
    # Watershed segmentation.
    img_equ_3c = cv2.cvtColor(img_equ, cv2.COLOR_GRAY2BGR)
    cv2.watershed(img_equ_3c, pect_marker_img)
    img_equ_3c[pect_marker_img == -1] = (0, 0, 255)
    # Extract only the breast and smooth.
    breast_only_mask = pect_marker_img.copy()
    breast_only_mask[breast_only_mask == -1] = 0
    breast_only_mask = breast_only_mask.astype(np.uint8)
    breast_only_mask[breast_only_mask != 128] = 0
    breast_only_mask[breast_only_mask == 128] = 255
    kernel_ = np.ones((sm_kn_size, sm_kn_size), dtype=np.uint8)
    breast_only_mask = cv2.morphologyEx(breast_only_mask, cv2.MORPH_OPEN, 
                                        kernel_)
    img_breast_only = cv2.bitwise_and(img_equ, breast_only_mask)

    return (img_breast_only)


def process(self, img, median_filtering=True, blur_kn_size=3, 
            artif_suppression=True, low_int_threshold=.05, kernel_size=15,
            pect_removal=False, high_int_threshold=.8, **pect_kwargs):
    '''Perform multi-stage preprocessing on the input image
    Args:
        blur_kn_size ([int]): kernel size for median blurring.
        low_int_threshold ([int]): cutoff used in artifacts suppression.
        high_int_threshold ([int]): cutoff used in pectoral muscle removal.
    Returns:
        a tuple of (processed_image, color_image_with_boundary). If 
        pectoral removal was not called, the color image is None.
    '''
    img_proc = img.copy()
    if median_filtering:
        img_proc = cv2.medianBlur(img_proc, blur_kn_size)
    if artif_suppression:
        img_proc, mask_ = self.suppress_artifacts(
            img_proc, global_threshold=low_int_threshold, 
            kernel_size=kernel_size)
    else:
        _, mask_ = self.suppress_artifacts(img_proc)
    if pect_removal:
        img_proc, img_col = self.remove_pectoral(
            img_proc, mask_, high_int_threshold=high_int_threshold, 
            **pect_kwargs)
    else:
        img_col = None

    return (img_proc, img_col)
41/19:
def preprocess_new(image):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=_crop(image)
    #image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(12,12))
    image = clahe.apply(image)
#     #image = (image/np.max(image))*255
#     #image = image.astype('uint8')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    return image
41/20:
def preprocess_new(image):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
#     image=_crop(image)
    image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(12,12))
    image = clahe.apply(image)
#     #image = (image/np.max(image))*255
#     #image = image.astype('uint8')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    return image
41/21:
image=preprocess_new(im)
plt.imshow(image[:,:,0])
41/22:
 def crop( img):
    try:
        bin_img = binarize(img, threshold=1)
        contour = extract_contour(bin_img)
        img = erase_background(img, contour)
        x1, x2 = np.min(contour[:, :, 0]), np.max(contour[:, :, 0])
        y1, y2 = np.min(contour[:, :, 1]), np.max(contour[:, :, 1])
#             x1, x2 = int(0.99 * x1), int(1.01 * x2)
#             y1, y2 = int(0.99 * y1), int(1.01 * y2)
        return img[y1:y2, x1:x2]
    except:
        print ('crop didnt work')
        return img
    
def _binarize( img, threshold):
    return (img > threshold).astype(np.uint8)
    
    # Get contour points of the breast
def _extract_contour( bin_img):
    contours, _ = cv2.findContours(
        bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    contour = max(contours, key=cv2.contourArea)
    return contour
    
# Set to background pixels of the image to zero
def _erase_background( img, contour):
    mask = np.zeros(img.shape, np.uint8)
    cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED)
    output = cv2.bitwise_and(img, mask)
    return output
41/23:
def preprocess_new(image):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=_crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(12,12))
    image = clahe.apply(image)
#     #image = (image/np.max(image))*255
#     #image = image.astype('uint8')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    return image
41/24:
image=preprocess_new(im)
plt.imshow(image[:,:,0])
41/25:
 def crop( img):
    try:
        bin_img = binarize(img, threshold=1)
        contour = extract_contour(bin_img)
        img = erase_background(img, contour)
        x1, x2 = np.min(contour[:, :, 0]), np.max(contour[:, :, 0])
        y1, y2 = np.min(contour[:, :, 1]), np.max(contour[:, :, 1])
#             x1, x2 = int(0.99 * x1), int(1.01 * x2)
#             y1, y2 = int(0.99 * y1), int(1.01 * y2)
        return img[y1:y2, x1:x2]
    except:
        print ('crop didnt work')
        return img
    
def binarize( img, threshold):
    return (img > threshold).astype(np.uint8)
    
    # Get contour points of the breast
def extract_contour( bin_img):
    contours, _ = cv2.findContours(
        bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    contour = max(contours, key=cv2.contourArea)
    return contour
    
# Set to background pixels of the image to zero
def erase_background( img, contour):
    mask = np.zeros(img.shape, np.uint8)
    cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED)
    output = cv2.bitwise_and(img, mask)
    return output
41/26:
def preprocess_new(image):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(12,12))
    image = clahe.apply(image)
#     #image = (image/np.max(image))*255
#     #image = image.astype('uint8')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    return image
41/27:
image=preprocess_new(im)
plt.imshow(image[:,:,0])
41/28:
image=preprocess_new(im)
plt.figure(figsize=(10,10))
plt.imshow(image[:,:,0])
41/29:
image=preprocess_new(im)
plt.figure(figsize=(20,20))
plt.imshow(image[:,:,0])
41/30:
image=preprocess_new(im)
plt.figure(figsize=(20,20). dpi=200)
plt.imshow(image[:,:,0])
41/31:
image=preprocess_new(im)
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,0])
41/32:
image=preprocess_new(im)
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,:])
41/33:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 12,tileGridSize=(12,12))
    image = clahe.apply(image)
#     #image = (image/np.max(image))*255
#     #image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/34:
image=preprocess_new(im)
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,:])
41/35:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,:])
41/36:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(12,12))
    image = clahe.apply(image)
#     #image = (image/np.max(image))*255
#     #image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/37:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,:])
41/38:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
    image = clahe.apply(image)
#     #image = (image/np.max(image))*255
#     #image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/39:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,:])
41/40:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,0], cmap='jet')
41/41:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
    image = clahe.apply(image)
    image = (image/np.max(image))*255
    image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/42:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,0], cmap='jet')
41/43:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/44:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/45: im=cv2.imread('/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-png/Calc-Test_P_00038_LEFT_CC/1-1.png')
41/46: im.shape
41/47:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/48:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.03
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/49:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/50:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.02
    n2=.04
    image = image[int(0+dim[0]*n2):int(dim[0]-dim[0]*n2),int(0+dim[1]*n):int(dim[1]-dim[1]*n)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/51:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/52:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.02
    n2=.04
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/53:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/54:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.02
    n2=.001
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/55:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/56:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    n2=.001
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/57:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/58:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.06
    n2=.001
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/59:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/60:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.06
    n2=.01
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/61:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/62:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,:], cmap='jet')
41/63:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.06
    n2=.01
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 6,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/64:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/65:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.06
    n2=.01
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 6,tileGridSize=(24,24))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/66:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/67:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,:], cmap='jet')
41/68:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/69:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.06
    n2=.01
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(18,18))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/70:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/71:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,:], cmap='jet')
41/72:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.06
    n2=.01
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(18,18))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_AREA)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/73:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/74:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.06
    n2=.01
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(20, 20), operation="open")
    blob_img=select_largest_obj(mask_img)
    #_, blob_img = np.array(XLargestBlobs(mask=mask_img, top_X=1))
    image[blob_img==0]=0
    if np.mean(np.where(image[int(dim[1]*.4),:]>20)) > dim[0]*.4:
        image=np.fliplr(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 4,tileGridSize=(18,18))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/75:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/76:
import warnings
warnings.filterwarnings("ignore")
# mp = MammographyPreprocessor(size=(300, 500))
PNG = True
# !pip install dicom
import pydicom as dicom
# Specify the .dcm folder path
folder_path = "/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-png/"
# Specify the output jpg/png folder path
jpg_folder_path = "/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6"
folders=os.listdir(folder_path)
count=1
for i in folders:
    if 'LICENSE' in i:
        continue
    else:
        #if 'Test' in i:
        folder1=os.listdir(os.path.join(folder_path, i))
        folder2 = os.listdir(os.path.join(folder_path, i,folder1[0]))
        if "mammogram" in folder2[0]:
            images_path=os.listdir(os.path.join(folder_path, i,folder1[0],folder2[0]))
            #print (images_path)
            try:
                os.makedirs(os.path.join(jpg_folder_path,i))
            except:
                continue
            for im_path in images_path:
                image_path = os.path.join(folder_path, i,folder1[0],folder2[0],im_path)
#                 path=os.path.join(folder_path, i,folder1[0],folder2[0],image)
#                 pixel_array_numpy = mp.preprocess_single_image(path=path, save=False)
                image = cv2.imread(image_path)
                image=preprocess_new(image,(300,500))
#                 ds = dicom.dcmread(os.path.join(folder_path, i,folder1[0],folder2[0],image))
#                 pixel_array_numpy = ds.pixel_array
#                 pixel_array_numpy = (pixel_array_numpy/np.max(pixel_array_numpy))*255
                
#                 pixel_array_numpy = preprocess(pixel_array_numpy)
                if PNG == False:
                    image = image.replace('.dcm', '.jpg')
                else:
                    image = image.replace('.dcm', '.png')

                cv2.imwrite(os.path.join(jpg_folder_path,i, image), pixel_array_numpy)
41/77: folder1
41/78: images_path=os.listdir(os.path.join(folder_path, i,folder1[0])
41/79: images_path=os.listdir(os.path.join(folder_path, i,folder1[0]))
41/80: images_path=os.path.join(folder_path, i,folder1[0])
41/81:
images_path=os.path.join(folder_path, i,folder1[0])
images_path
41/82:
import warnings
warnings.filterwarnings("ignore")
# mp = MammographyPreprocessor(size=(300, 500))
PNG = True
# !pip install dicom
import pydicom as dicom
# Specify the .dcm folder path
folder_path = "/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-png/"
# Specify the output jpg/png folder path
jpg_folder_path = "/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6"
folders=os.listdir(folder_path)
count=1
for i in folders:
    if 'LICENSE' in i:
        continue
    else:
        #if 'Test' in i:
        folder1=os.listdir(os.path.join(folder_path, i))
        #folder2 = os.listdir(os.path.join(folder_path, i,folder1[0]))
        #if "mammogram" in folder2[0]:
        image_path=os.path.join(folder_path, i,folder1[0])
        #print (images_path)
        try:
            os.makedirs(os.path.join(jpg_folder_path,i))
        except:
            continue
#         for im_path in images_path:
#         image_path = os.path.join(folder_path, i,folder1[0],folder2[0],im_path)
#                 path=os.path.join(folder_path, i,folder1[0],folder2[0],image)
#                 pixel_array_numpy = mp.preprocess_single_image(path=path, save=False)
        image = cv2.imread(image_path)
        image=preprocess_new(image,(300,500))
#                 ds = dicom.dcmread(os.path.join(folder_path, i,folder1[0],folder2[0],image))
#                 pixel_array_numpy = ds.pixel_array
#                 pixel_array_numpy = (pixel_array_numpy/np.max(pixel_array_numpy))*255



        cv2.imwrite(os.path.join(jpg_folder_path,i, folder1[0]), image)
40/18:
optimizer = torch.optim.RMSprop(model.parameters(), lr=4e-6, weight_decay=.01)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=100)
42/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_swsl_resnet50_baseline_test",
    
    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
42/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v4/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
42/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
42/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
42/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
42/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
42/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
42/8:
batch_size = 24
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
42/9:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
42/10:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
42/11:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
42/12:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
42/13:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
42/14:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
42/15:
batch_size = 24
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
42/16:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
42/17:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
42/18:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
42/19:



import timm
model = timm.create_model('swsl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
42/20:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-6, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1200, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=30)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=30)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
42/21:
optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-6, weight_decay=.01)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 600, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=100)
41/83:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.06
    n2=.01
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(14, 14), operation="open")
    blob_img=select_largest_obj(mask_img)
    image[blob_img==0]=0
    image=flip_breast(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 6,tileGridSize=(24,24))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/84: im=cv2.imread('/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-png/Calc-Test_P_00038_LEFT_CC/1-1.png')
41/85: im.shape
41/86:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/87:
 def crop( img):
    try:
        bin_img = binarize(img, threshold=1)
        contour = extract_contour(bin_img)
        img = erase_background(img, contour)
        x1, x2 = np.min(contour[:, :, 0]), np.max(contour[:, :, 0])
        y1, y2 = np.min(contour[:, :, 1]), np.max(contour[:, :, 1])
#             x1, x2 = int(0.99 * x1), int(1.01 * x2)
#             y1, y2 = int(0.99 * y1), int(1.01 * y2)
        return img[y1:y2, x1:x2]
    except:
        print ('crop didnt work')
        return img
    
def binarize( img, threshold):
    return (img > threshold).astype(np.uint8)
    
    # Get contour points of the breast
def extract_contour( bin_img):
    contours, _ = cv2.findContours(
        bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    contour = max(contours, key=cv2.contourArea)
    return contour
    
# Set to background pixels of the image to zero
def erase_background( img, contour):
    mask = np.zeros(img.shape, np.uint8)
    cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED)
    output = cv2.bitwise_and(img, mask)
    return output

 def flip_breast( img):
        col_sums_split = np.array_split(np.sum(img, axis=0), 2)
        left_col_sum = np.sum(col_sums_split[0])
        right_col_sum = np.sum(col_sums_split[1])
        if left_col_sum > right_col_sum:
            return np.fliplr(img)
        else:
            return img
41/88:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/89:
 def crop( img):
    try:
        bin_img = binarize(img, threshold=1)
        contour = extract_contour(bin_img)
        img = erase_background(img, contour)
        x1, x2 = np.min(contour[:, :, 0]), np.max(contour[:, :, 0])
        y1, y2 = np.min(contour[:, :, 1]), np.max(contour[:, :, 1])
#             x1, x2 = int(0.99 * x1), int(1.01 * x2)
#             y1, y2 = int(0.99 * y1), int(1.01 * y2)
        return img[y1:y2, x1:x2]
    except:
        print ('crop didnt work')
        return img
    
def binarize( img, threshold):
    return (img > threshold).astype(np.uint8)
    
    # Get contour points of the breast
def extract_contour( bin_img):
    contours, _ = cv2.findContours(
        bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    contour = max(contours, key=cv2.contourArea)
    return contour
    
# Set to background pixels of the image to zero
def erase_background( img, contour):
    mask = np.zeros(img.shape, np.uint8)
    cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED)
    output = cv2.bitwise_and(img, mask)
    return output

 def flip_breast( img):
        col_sums_split = np.array_split(np.sum(img, axis=0), 2)
        left_col_sum = np.sum(col_sums_split[0])
        right_col_sum = np.sum(col_sums_split[1])
        if left_col_sum > right_col_sum:
            return img
        else:
            return np.fliplr(img)
41/90:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.06
    n2=.01
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(14, 14), operation="open")
    blob_img=select_largest_obj(mask_img)
    image[blob_img==0]=0
    image=flip_breast(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 6,tileGridSize=(24,24))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/91:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=400)
plt.imshow(image[:,:,0], cmap='jet')
41/92:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.04
    n2=.01
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(14, 14), operation="open")
    blob_img=select_largest_obj(mask_img)
    image[blob_img==0]=0
    image=flip_breast(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 6,tileGridSize=(24,24))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/93:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,0], cmap='jet')
41/94:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.04
    n2=.006
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(14, 14), operation="open")
    blob_img=select_largest_obj(mask_img)
    image[blob_img==0]=0
    image=flip_breast(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 6,tileGridSize=(24,24))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_LANCZOS4)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/95:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,0], cmap='jet')
41/96:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.04
    n2=.006
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(14, 14), operation="open")
    blob_img=select_largest_obj(mask_img)
    image[blob_img==0]=0
    image=flip_breast(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 6,tileGridSize=(24,24))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_CUBIC)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/97:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,0], cmap='jet')
41/98:
image=preprocess_new(im,(300,500))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,:], cmap='jet')
41/99:
image=preprocess_new(im,(600,1000))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,:], cmap='jet')
42/22:
optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=40)
42/23:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish()
42/24:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
42/25:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 800, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
41/100:
image=preprocess_new(im,(600,1000))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,:], cmap='jet')
41/101:
image=preprocess_new(im,(600,1000))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,:], cmap='jet')
image
41/102:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.04
    n2=.006
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(14, 14), operation="open")
    blob_img=select_largest_obj(mask_img)
    image[blob_img==0]=0
    image=flip_breast(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 8,tileGridSize=(24,24))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_CUBIC)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/103:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.04
    n2=.006
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(14, 14), operation="open")
    blob_img=select_largest_obj(mask_img)
    image[blob_img==0]=0
    image=flip_breast(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 6,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_CUBIC)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/104:
image=preprocess_new(im,(600,1000))
plt.figure(figsize=(20,20), dpi=200)
plt.imshow(image[:,:,:], cmap='jet')
41/105:
# import warnings
# warnings.filterwarnings("ignore")
# # mp = MammographyPreprocessor(size=(300, 500))
# PNG = True
# # !pip install dicom
# import pydicom as dicom
# Specify the .dcm folder path
folder_path = "/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-png/"
# Specify the output jpg/png folder path
jpg_folder_path = "/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v7"
folders=os.listdir(folder_path)
count=1
for i in folders:

    folder1=os.listdir(os.path.join(folder_path, i))
    image_path=os.path.join(folder_path, i,folder1[0])
    try:
        os.makedirs(os.path.join(jpg_folder_path,i))
    except:
        continue
    image = cv2.imread(image_path)
    image=preprocess_new(image,(300,500))
    cv2.imwrite(os.path.join(jpg_folder_path,i, folder1[0]), image)
41/106:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.04
    n2=.02
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(14, 14), operation="open")
    blob_img=select_largest_obj(mask_img)
    image[blob_img==0]=0
    image=flip_breast(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 6,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_CUBIC)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/107:
# import warnings
# warnings.filterwarnings("ignore")
# # mp = MammographyPreprocessor(size=(300, 500))
# PNG = True
# # !pip install dicom
# import pydicom as dicom
# Specify the .dcm folder path
folder_path = "/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-png/"
# Specify the output jpg/png folder path
jpg_folder_path = "/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v7"
folders=os.listdir(folder_path)
count=1
for i in folders:

    folder1=os.listdir(os.path.join(folder_path, i))
    image_path=os.path.join(folder_path, i,folder1[0])
    try:
        os.makedirs(os.path.join(jpg_folder_path,i))
    except:
        continue
    image = cv2.imread(image_path)
    image=preprocess_new(image,(300,500))
    cv2.imwrite(os.path.join(jpg_folder_path,i, folder1[0]), image)
42/26:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_swsl_resnet50_baseline_test",
    

    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
42/27:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 800, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
41/108:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.05
    n2=.02
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(14, 14), operation="open")
    blob_img=select_largest_obj(mask_img)
    image[blob_img==0]=0
    image=flip_breast(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 6,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_CUBIC)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/109:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.06
    n2=.02
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(14, 14), operation="open")
    blob_img=select_largest_obj(mask_img)
    image[blob_img==0]=0
    image=flip_breast(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 6,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_CUBIC)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/110:
# import warnings
# warnings.filterwarnings("ignore")
# # mp = MammographyPreprocessor(size=(300, 500))
# PNG = True
# # !pip install dicom
# import pydicom as dicom
# Specify the .dcm folder path
folder_path = "/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-png/"
# Specify the output jpg/png folder path
jpg_folder_path = "/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v7"
folders=os.listdir(folder_path)
count=1
for i in folders:

    folder1=os.listdir(os.path.join(folder_path, i))
    image_path=os.path.join(folder_path, i,folder1[0])
    try:
        os.makedirs(os.path.join(jpg_folder_path,i))
    except:
        continue
    image = cv2.imread(image_path)
    image=preprocess_new(image,(300,500))
    cv2.imwrite(os.path.join(jpg_folder_path,i, folder1[0]), image)
41/111:
def preprocess_new(image,size):
    #image = cv2.resize(image, (1200, 1600),interpolation = cv2.INTER_CUBIC)
    dim=(image.shape[0],image.shape[1])
    n=.06
    n2=.03
    image = image[int(0+dim[0]*n):int(dim[0]-dim[0]*n),int(0+dim[1]*n2):int(dim[1]-dim[1]*n2)].astype('uint8')
    image=suppress_artifacts(image[:,:,0])
    mask_img = OpenMask(mask=image, ksize=(14, 14), operation="open")
    blob_img=select_largest_obj(mask_img)
    image[blob_img==0]=0
    image=flip_breast(image)
    image=crop(image)
#     image=segment_breast(image,low_int_threshold=.1, crop=True)
    
    #image=image[:,:-40]
#     image = cv2.resize(image, (300, 500),interpolation = cv2.INTER_AREA)
    clahe = cv2.createCLAHE(clipLimit = 6,tileGridSize=(12,12))
    image = clahe.apply(image)
#     image = (image/np.max(image))*255
#     image = image.astype('uint8')
    image=cv2.resize(image,size,interpolation = cv2.INTER_CUBIC)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    
    return image
41/112:
# import warnings
# warnings.filterwarnings("ignore")
# # mp = MammographyPreprocessor(size=(300, 500))
# PNG = True
# # !pip install dicom
# import pydicom as dicom
# Specify the .dcm folder path
folder_path = "/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-png/"
# Specify the output jpg/png folder path
jpg_folder_path = "/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v7"
folders=os.listdir(folder_path)
count=1
for i in folders:

    folder1=os.listdir(os.path.join(folder_path, i))
    image_path=os.path.join(folder_path, i,folder1[0])
    try:
        os.makedirs(os.path.join(jpg_folder_path,i))
    except:
        continue
    image = cv2.imread(image_path)
    image=preprocess_new(image,(300,500))
    cv2.imwrite(os.path.join(jpg_folder_path,i, folder1[0]), image)
43/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_swsl_resnet50_baseline_test",
    

    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
43/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
43/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
43/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
43/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
43/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
43/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
43/8:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
43/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
43/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
43/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
43/12:



import timm
model = timm.create_model('swsl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
43/13:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=10)
optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
43/14:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
43/15:
gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-5, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=6)
optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-7, weight_decay=.2)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
43/16:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
43/17:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-6, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 500, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
43/18:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
43/19:
# model=my_resnet50(weights="IMAGENET1K_V2")
# for name, param in model.named_parameters():
#     if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
#         param.requires_grad = False
#     print(name, param.requires_grad)
43/20:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-6, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
43/21:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
43/22:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=6)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-6, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=60)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
43/23: model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=30)
43/24:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish()
43/25:
PATH='/home/mbadhan/Desktop/mberghouse/pytorch_models/weights/final/CBAMresnet50_mass_NAdam_run3_weights'
torch.save(model.state_dict(), PATH)
PATH='/home/mbadhan/Desktop/mberghouse/pytorch_models/models/final/CBAMresnet50_mass_NAdam_run3_model'
torch.save(model, PATH)
43/26:
PATH='/home/mbadhan/Desktop/mberghouse/pytorch_models/weights/final/CBAMresnet50_mass_NAdam_run3_weights'
torch.save(model.state_dict(), PATH)
PATH='/home/mbadhan/Desktop/mberghouse/pytorch_models/models/final/CBAMresnet50_mass_NAdam_run3_model'
torch.save(model, PATH)
45/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_ssl_resnet50_baseline_test",
    

    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
45/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/v7/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
45/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
45/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
45/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
45/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
45/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
45/8:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
45/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
45/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
45/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
45/12:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
45/13:
# model=my_resnet50(weights="IMAGENET1K_V2")
# for name, param in model.named_parameters():
#     if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
#         param.requires_grad = False
#     print(name, param.requires_grad)
45/14:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=6)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-6, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=90)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
45/15:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish()
45/16:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
45/17:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 300, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-6, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=90)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
48/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_ssl_resnet50_baseline_test",
    

    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
48/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
48/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
48/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
48/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
48/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
48/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
48/8:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
48/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
48/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
48/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
48/12:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
48/13:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 300, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-6, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=90)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
48/14:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish()
48/15:
PATH='/home/mbadhan/Desktop/mberghouse/pytorch_models/weights/final/SSLresnet50_calc_RMS_run2_weights'
torch.save(model.state_dict(), PATH)
PATH='/home/mbadhan/Desktop/mberghouse/pytorch_models/models/final/CSSLresnet50_calc_RMS_run2_model'
torch.save(model, PATH)
49/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_swsl_resnet50_baseline_test",
    

    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
49/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
49/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
49/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
49/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
49/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
49/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
49/8:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
49/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
49/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
49/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
49/12:



import timm
model = timm.create_model('swsl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
49/13:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 330, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=13)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-6, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=25)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
49/14:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish()
50/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_ssl_resnet50_baseline_test",
    

    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
50/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
50/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
50/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
50/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
50/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
50/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
50/8:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
50/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
50/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
50/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
50/12:



import timm
model = timm.create_model('swsl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
50/13:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
50/14:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 330, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=13)
optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-6, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1000, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=25)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
50/15:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.2),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
50/16:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1.5e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 320, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=13)
optimizer = torch.optim.RMSprop(model.parameters(), lr=2e-7, weight_decay=.1)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=25)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
50/17:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
50/18:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1.0e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 350, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-7, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=25)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
50/19:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
50/20:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2.0e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 380, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=16)
optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-7, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=25)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
50/21:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish()
51/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_ssl_resnet50_baseline_test",
    

    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
51/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
51/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
51/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
51/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
51/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
51/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
51/8:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
51/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
51/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
51/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
51/12:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.5),
    nn.Linear(in_features=num_in_features, out_features=512, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=512, out_features=1, bias=False),
    nn.Sigmoid())

model
51/13:
# model=my_resnet50(weights="IMAGENET1K_V2")
# for name, param in model.named_parameters():
#     if ('sa' not in name)&('ca' not in name)&('classifier' not in name)&('se' not in name):
#         param.requires_grad = False
#     print(name, param.requires_grad)
51/14:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2.0e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 380, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=16)
optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-7, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=20)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
51/15:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish()
52/1:
import wandb
# start a new wandb run to track this script
wandb.init(
    # set the wandb project where this run will be logged
    project="FINAL_Calc_ssl_resnet50_baseline_test",
    

    # track hyperparameters and run metadata
    config={
    "learning_rate": 1e-5,
    "architecture": "resnet101",
    "dataset": "CBIS-DDSM - mass",
    "epochs": 120,
    "batch size": 32,
    "misc": "custom staircase restart LR with NAdam and .3 dropout",
    "trainable": "Class + CBAM for 15 epochs, all layers for 30 epochs"
    }
)
52/2:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
52/3:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
52/4:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
52/5:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
52/6:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
52/7:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
52/8:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
52/9:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
52/10:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    scheduler1=scheduler[1]
    scheduler=scheduler[0]
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = (outputs > threshold).double()
                    #print(all_outputs)
                    #print(outputs)
                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  
                    #print(labels)
                    # _, preds = torch.max(outputs, 1)
#                     loss=criterion(model(inputs)[model(inputs)>0], labels[model(inputs)>0])
                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()
                        scheduler1.step()
#                         start=scheduler.state_dict()
                        sched_steps.append(optimizer.param_groups[0]['lr'])
#                         if epoch == 18:
#                             lower=scheduler.state_dict()
#                         if epoch ==40:
# #                             optimizer = torch.optim.NAdam(model.parameters(), lr=1e-5, weight_decay=.1)
# #                             scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 1600, T_mult=2, eta_min=1e-10, last_epoch=- 1, verbose=False)

#                             for name, param in model.named_parameters():
#                                 param.requires_grad = True
#                         if epoch ==60:
#                             optimizer.param_groups[0]['lr']=1e-5
#                             scheduler.load_state_dict(start)


                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return model, train_metrics, val_metrics, sched_steps
52/11:
def test_model(model,criterion,dataloader, threshold=.5):
    device='cuda'
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    stop_count = 0
    best_f1 = -1.0
    test_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
#     threshold = 0.5
    print('Starting testing...')
    # empty 'all' tensors for saving
    all_outputs = torch.Tensor([])
    all_labels = torch.Tensor([])
    model.eval()   # Set model to evaluate mode
    running_loss = 0.0
    n_samples = 0
    n_correct = 0
    running_f1 = 0.0
    # Iterate over data.
    for inputs, labels in tqdm(dataloader):
        labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
        #labels=torch.tensor(labels)
        inputs = inputs.float()
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
        # zero the parameter gradients
            outputs = model(inputs)
            #preds = (outputs > threshold).double()
            # concatenating all outputs and labels for calculation aoc and new threshold
            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
            all_labels = torch.cat((all_labels, labels.to('cpu')))                  
            #print(labels)
            # _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
        running_loss += loss.item()
        #n_correct += (preds == labels).sum().item()
        # collect any unused memmory
        gc.collect()
        torch.cuda.empty_cache()  
        
    # statistics
    epoch_loss = running_loss / len(dataloader)            
    # find true positive and false positive rates for ROC curve
    #print ('outputs: ', all_outputs, 'labels', all_labels)
    all_labels=all_labels.to(dtype=torch.long)
    fpr, tpr, thresholds = roc(all_outputs, all_labels)
    epoch_auc = auc(all_outputs, all_labels)
    # find new threshold
    threshold, _ = find_optim_thres(fpr, tpr, thresholds)
    print(f'New threshold is {threshold}')
    # calculate metrics using new optimized threshold
    epoch_f1 = metricf1(all_outputs > threshold, all_labels)
    epoch_acc = accuracy(all_outputs > threshold, all_labels)
    epoch_precision = precision(all_outputs > threshold, all_labels)
    epoch_recall = recall(all_outputs > threshold, all_labels)
    # save all of the statistics for latter analysis
    test_metrics['loss'].append(epoch_loss)
    test_metrics['acc'].append(epoch_acc)
    test_metrics['f1'].append(epoch_f1)
    test_metrics['precision'].append(epoch_precision)
    test_metrics['recall'].append(epoch_recall)
    test_metrics['auc'].append(epoch_auc)               
    time_elapsed = time.time() - since
    wandb.log({"test_acc": epoch_acc, "test_loss": epoch_loss, "test_f1": epoch_f1, "test_precision": epoch_precision
                         , "test_recall": epoch_recall, "test_auc": epoch_auc})
    print(f'Inference complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'F1 Score = : {epoch_f1:4f}')
    print(f'AUC Score = : {epoch_auc:4f}')
    print(f'Acc Score = : {epoch_acc:4f}')
    return test_metrics
52/12:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
52/13:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=2.0e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 380, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=16)
optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-7, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=26)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
52/14:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
52/15:
#### gc.collect()
torch.cuda.empty_cache() 

device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.benchmark = True

model.to(device)

optimizer = torch.optim.RMSprop(model.parameters(), lr=1.0e-5, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 340, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

scheduler1 = StepLR(optimizer, step_size=2000000, gamma=0.1)

criterion = nn.BCELoss()

test_size=len(test_dataset)
dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
dataset_sizes = {'train': train_size, 'val' : test_size}
checkpoint = {'model': model,
          'state_dict': model.state_dict(),
          'optimizer' : optimizer.state_dict(),
             'threshold' : 0.5}

model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=14)
optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-7, weight_decay=.05)
scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=26)

# test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
# wandb.finish() 

# gc.collect()
# torch.cuda.empty_cache()  

# # PATH='C:/Users/marcb/Desktop/pytorch_models/weights/final2/densenet169_mass_NAdam_run3_weights'
# # torch.save(model.state_dict(), PATH)
# # PATH='C:/Users/marcb/Desktop/pytorch_models/models/final2/densenet169_mass_NAdam_run3_model'
# # torch.save(model, PATH)

# gc.collect()
# torch.cuda.empty_cache()
52/16: model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=26)
52/17:
test_metrics = test_model(model, criterion,test_dataloader, threshold = .4)
wandb.finish()
53/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
53/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
53/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
53/4:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
53/5:
batch_size = 24
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
53/6:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
53/7:
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(model, criterion, optimizer, scheduler, num_epochs=30),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/8: !pip install optuna
53/9:
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=1.2e-5, weight_decay=.05)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 340, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

    model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=15)
    optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-7, weight_decay=.05)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/10:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(model, criterion, optimizer, scheduler, num_epochs=30),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/11:
def train_model( criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=1.2e-5, weight_decay=.05)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 340, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

    model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=15)
    optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-7, weight_decay=.05)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/12:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(criterion, optimizer, scheduler, num_epochs=30),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/13:
def train_model( num_epochs=25):
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=1.2e-5, weight_decay=.05)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 340, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

    model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=15)
    optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-7, weight_decay=.05)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/14:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(num_epochs=30),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/15:
def train_model( num_epochs=25):
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=1.2e-5, weight_decay=.05)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 340, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

    model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=15)
    optimizer = torch.optim.RMSprop(model.parameters(), lr=8e-7, weight_decay=.05)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/16:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(num_epochs=30),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/17:
def train_model(trial:
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    weight_decay = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = trial.suggest_uniform('num_epochs',[4,30])
    c = trial.suggest_uniform('c',[200,800])
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, c, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/18:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(num_epochs=30),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/19:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    weight_decay = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = trial.suggest_uniform('num_epochs',[4,30])
    c = trial.suggest_uniform('c',[200,800])
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, c, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/20:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(trial,n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/21:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(trial),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/22:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    weight_decay = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = trial.suggest_uniform('num_epochs',4,30)
    c = trial.suggest_uniform('c',[200,800])
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, c, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/23:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(trial),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/24:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    weight_decay = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = trial.suggest_uniform('num_epochs',4,30)
    c = trial.suggest_uniform('c',200,800)
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, c, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/25:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(trial),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/26:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    wd = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = trial.suggest_uniform('num_epochs',4,30)
    c = trial.suggest_uniform('c',200,800)
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, c, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/27:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(trial),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/28:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    wd = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',4,30))
    c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, c, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
                    best_model_wts = model.state_dict()
                    checkpoint['threshold'] = threshold
                    torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
        tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
        lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
        print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Vall f1: {val_f1:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_rec:.4f}, Val AUC: {val_auc:.4f}')       
#         if epoch == 0:
#             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/29:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(trial),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/30:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    wd = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',4,30))
    c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, c, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
#                 wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
#                          , "train_recall": epoch_recall, "train_auc": epoch_auc})
#                 train_metrics['loss'].append(epoch_loss)
#                 train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
#                 train_metrics['precision'].append(epoch_precision)
#                 train_metrics['recall'].append(epoch_recall)
#                 train_metrics['auc'].append(epoch_auc)
            else:
#                 wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
#                          , "val_recall": epoch_recall, "val_auc": epoch_auc})
#                 val_metrics['loss'].append(epoch_loss)
#                 val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
#                 val_metrics['precision'].append(epoch_precision)
#                 val_metrics['recall'].append(epoch_recall)
#                 val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
#                     best_model_wts = model.state_dict()
#                     checkpoint['threshold'] = threshold
#                     torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
#         val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}')       
# #         if epoch == 0:
# #             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/31:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(trial),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/32:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    wd = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',4,30))
    c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, c, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
#                 wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
#                          , "train_recall": epoch_recall, "train_auc": epoch_auc})
#                 train_metrics['loss'].append(epoch_loss)
#                 train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
#                 train_metrics['precision'].append(epoch_precision)
#                 train_metrics['recall'].append(epoch_recall)
#                 train_metrics['auc'].append(epoch_auc)
            else:
#                 wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
#                          , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
#                 val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
#                 val_metrics['precision'].append(epoch_precision)
#                 val_metrics['recall'].append(epoch_recall)
#                 val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
#                     best_model_wts = model.state_dict()
#                     checkpoint['threshold'] = threshold
#                     torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
#         val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_metrics['loss'][-1]:.4f}, Val f1: {val_metrics['f1'][-1]:.4f}')       
# #         if epoch == 0:
# #             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/33:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(trial),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/34:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    wd = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',4,30))
    c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, c, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
#                 wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
#                          , "train_recall": epoch_recall, "train_auc": epoch_auc})
#                 train_metrics['loss'].append(epoch_loss)
#                 train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
#                 train_metrics['precision'].append(epoch_precision)
#                 train_metrics['recall'].append(epoch_recall)
#                 train_metrics['auc'].append(epoch_auc)
            else:
#                 wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
#                          , "val_recall": epoch_recall, "val_auc": epoch_auc})
#                 val_metrics['loss'].append(epoch_loss)
#                 val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
#                 val_metrics['precision'].append(epoch_precision)
#                 val_metrics['recall'].append(epoch_recall)
#                 val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
#                     best_model_wts = model.state_dict()
#                     checkpoint['threshold'] = threshold
#                     torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
#         val_loss, val_acc, val_f1, val_prec, val_rec, val_auc = val_metrics['loss'][-1], val_metrics['acc'][-1], val_metrics['f1'][-1], val_metrics['precision'][-1], val_metrics['recall'][-1], val_metrics['auc'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_metrics['f1'][-1]:.4f}, Val f1: {val_f1:.4f}')       
# #         if epoch == 0:
# #             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/35:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    wd = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',4,30))
    c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, c, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
#                 wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
#                          , "train_recall": epoch_recall, "train_auc": epoch_auc})
#                 train_metrics['loss'].append(epoch_loss)
#                 train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
#                 train_metrics['precision'].append(epoch_precision)
#                 train_metrics['recall'].append(epoch_recall)
#                 train_metrics['auc'].append(epoch_auc)
            else:
#                 wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
#                          , "val_recall": epoch_recall, "val_auc": epoch_auc})
#                 val_metrics['loss'].append(epoch_loss)
#                 val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
#                 val_metrics['precision'].append(epoch_precision)
#                 val_metrics['recall'].append(epoch_recall)
#                 val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
#                     best_model_wts = model.state_dict()
#                     checkpoint['threshold'] = threshold
#                     torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}')       
# #         if epoch == 0:
# #             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/36:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(trial),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/37:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    wd = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',4,30))
    c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, c, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
            print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in tqdm(dataloaders[phase]):
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
#                 wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
#                          , "train_recall": epoch_recall, "train_auc": epoch_auc})
#                 train_metrics['loss'].append(epoch_loss)
#                 train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
#                 train_metrics['precision'].append(epoch_precision)
#                 train_metrics['recall'].append(epoch_recall)
#                 train_metrics['auc'].append(epoch_auc)
            else:
#                 wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
#                          , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
#                 val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
#                 val_metrics['precision'].append(epoch_precision)
#                 val_metrics['recall'].append(epoch_recall)
#                 val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
#                     best_model_wts = model.state_dict()
#                     checkpoint['threshold'] = threshold
#                     torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}')       
# #         if epoch == 0:
# #             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/38:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(trial),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
53/39:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    wd = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',4,30))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    model.to(device)

    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}
    checkpoint = {'model': model,
              'state_dict': model.state_dict(),
              'optimizer' : optimizer.state_dict(),
                 'threshold' : 0.5}

#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
#             print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
#             epoch_acc = accuracy(all_outputs > threshold, all_labels)
#             epoch_precision = precision(all_outputs > threshold, all_labels)
#             epoch_recall = recall(all_outputs > threshold, all_labels)
#             print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
#                 wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
#                          , "train_recall": epoch_recall, "train_auc": epoch_auc})
#                 train_metrics['loss'].append(epoch_loss)
#                 train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
#                 train_metrics['precision'].append(epoch_precision)
#                 train_metrics['recall'].append(epoch_recall)
#                 train_metrics['auc'].append(epoch_auc)
            else:
#                 wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
#                          , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
#                 val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
#                 val_metrics['precision'].append(epoch_precision)
#                 val_metrics['recall'].append(epoch_recall)
#                 val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
#                     best_model_wts = model.state_dict()
#                     checkpoint['threshold'] = threshold
#                     torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        gc.collect()
        torch.cuda.empty_cache() 
# #         if epoch == 0:
# #             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
53/40:
import optuna
study = optuna.create_study(direction='maximize')
study.optimize(lambda trial: train_model(trial),n_trials=100)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
55/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
55/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
55/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
55/4:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
55/5:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
55/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
55/7:
batch_size = 24
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
55/8:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
55/9:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    wd = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',10,30))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
         if stop_count >= 2:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
#             print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
#             epoch_acc = accuracy(all_outputs > threshold, all_labels)
#             epoch_precision = precision(all_outputs > threshold, all_labels)
#             epoch_recall = recall(all_outputs > threshold, all_labels)
#             print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
#                 wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
#                          , "train_recall": epoch_recall, "train_auc": epoch_auc})
#                 train_metrics['loss'].append(epoch_loss)
#                 train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
#                 train_metrics['precision'].append(epoch_precision)
#                 train_metrics['recall'].append(epoch_recall)
#                 train_metrics['auc'].append(epoch_auc)
            else:
#                 wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
#                          , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
#                 val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
#                 val_metrics['precision'].append(epoch_precision)
#                 val_metrics['recall'].append(epoch_recall)
#                 val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
#                     best_model_wts = model.state_dict()
#                     checkpoint['threshold'] = threshold
#                     torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
# #         if epoch == 0:
# #             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
55/11:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 1e-6, 1e-4)
    wd = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',10,30))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 2:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
#             print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
#             epoch_acc = accuracy(all_outputs > threshold, all_labels)
#             epoch_precision = precision(all_outputs > threshold, all_labels)
#             epoch_recall = recall(all_outputs > threshold, all_labels)
#             print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
#                 wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
#                          , "train_recall": epoch_recall, "train_auc": epoch_auc})
#                 train_metrics['loss'].append(epoch_loss)
#                 train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
#                 train_metrics['precision'].append(epoch_precision)
#                 train_metrics['recall'].append(epoch_recall)
#                 train_metrics['auc'].append(epoch_auc)
            else:
#                 wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
#                          , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
#                 val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
#                 val_metrics['precision'].append(epoch_precision)
#                 val_metrics['recall'].append(epoch_recall)
#                 val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
#                     best_model_wts = model.state_dict()
#                     checkpoint['threshold'] = threshold
#                     torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
# #         if epoch == 0:
# #             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
55/12:
import optuna
study = optuna.create_study(pruner=optuna.pruners.MedianPruner(),direction='maximize')
study.optimize(lambda trial: train_model(trial),n_trials=30)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
55/13:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 2:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
#             print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
#             epoch_acc = accuracy(all_outputs > threshold, all_labels)
#             epoch_precision = precision(all_outputs > threshold, all_labels)
#             epoch_recall = recall(all_outputs > threshold, all_labels)
#             print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
#                 wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
#                          , "train_recall": epoch_recall, "train_auc": epoch_auc})
#                 train_metrics['loss'].append(epoch_loss)
#                 train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
#                 train_metrics['precision'].append(epoch_precision)
#                 train_metrics['recall'].append(epoch_recall)
#                 train_metrics['auc'].append(epoch_auc)
            else:
#                 wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
#                          , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
#                 val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
#                 val_metrics['precision'].append(epoch_precision)
#                 val_metrics['recall'].append(epoch_recall)
#                 val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
#                     best_model_wts = model.state_dict()
#                     checkpoint['threshold'] = threshold
#                     torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(1-val_loss, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
# #         if epoch == 0:
# #             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
55/14:
import optuna
study = optuna.create_study(pruner=optuna.pruners.MedianPruner(),direction='maximize')
study.optimize(lambda trial: train_model(trial),n_trials=30)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
55/15: best_params
55/16:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-4, 1e-1)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 2:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
            scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            # find true positive and false positive rates for ROC curve
            #print ('outputs: ', all_outputs, 'labels', all_labels)
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            # find new threshold
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
#             print(f'New threshold is {threshold}')
            # calculate metrics using new optimized threshold
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
#             epoch_acc = accuracy(all_outputs > threshold, all_labels)
#             epoch_precision = precision(all_outputs > threshold, all_labels)
#             epoch_recall = recall(all_outputs > threshold, all_labels)
#             print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
#                 wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
#                          , "train_recall": epoch_recall, "train_auc": epoch_auc})
#                 train_metrics['loss'].append(epoch_loss)
#                 train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
#                 train_metrics['precision'].append(epoch_precision)
#                 train_metrics['recall'].append(epoch_recall)
#                 train_metrics['auc'].append(epoch_auc)
            else:
#                 wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
#                          , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
#                 val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
#                 val_metrics['precision'].append(epoch_precision)
#                 val_metrics['recall'].append(epoch_recall)
#                 val_metrics['auc'].append(epoch_auc)

            # deep copy the model
                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]
#                     best_model_wts = model.state_dict()
#                     checkpoint['threshold'] = threshold
#                     torch.save(checkpoint, 'checkpoint.pth')
               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
# #         if epoch == 0:
# #             val_f1_best=val_f1
#         else:
#             if val_f1 > val_f1_best:
#                 val_f1_best=val_f1
#                 stop_count = 0
#             else:
#                 stop_count = stop_count + 1
        
#         if stop_count == 160:
#             break
                
#         if earlystoper.early_stop(val_f1):
#             break       
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
55/17:
import optuna
study = optuna.create_study(pruner=optuna.pruners.HyperbandPruner(min_resource=1, max_resource=30,reduction_factor=4),direction='maximize')
study.optimize(train_model,n_trials=30)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
57/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
57/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
57/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
57/4:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
57/5:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
57/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
57/7:
batch_size = 24
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
57/8:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
57/9:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 2:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

#                 if val_metrics['f1'][-1] > best_f1:
#                     best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
        
        if epoch == 0:
            best_f1=val_f1
        else:
            if val_f1 > best_f1:
                best_f1_=val_f1
                stop_count = 0
            else:
                stop_count = stop_count + 1
        
        if stop_count == 6:
            break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
57/10:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(pruner=optuna.pruners.HyperbandPruner(min_resource=1, max_resource=30,reduction_factor=4),direction='maximize')
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
57/11:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 5:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

#                 if val_metrics['f1'][-1] > best_f1:
#                     best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
        
        if epoch == 0:
            best_f1=val_f1
        else:
            if val_f1 > best_f1:
                best_f1_=val_f1
                stop_count = 0
            else:
                stop_count = stop_count + 1
        
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
57/12:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(pruner=optuna.pruners.HyperbandPruner(min_resource=1, max_resource=30,reduction_factor=4),direction='maximize')
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
58/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
58/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
58/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
58/4:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
58/5:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
58/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
58/7:
batch_size = 24
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
58/8:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
58/9:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 4:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

#                 if val_metrics['f1'][-1] > best_f1:
#                     best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
        
        if epoch == 0:
            best_f1=val_f1
        else:
            if val_f1 > best_f1:
                best_f1_=val_f1
                stop_count = 0
            else:
                stop_count = stop_count + 1
        
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
58/10:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
58/11:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 4:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

#                 if val_metrics['f1'][-1] > best_f1:
#                     best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
             
        if val_f1 > best_f1:
            best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
        
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
58/12:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 4:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

#                 if val_metrics['f1'][-1] > best_f1:
#                     best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
             
        if val_f1 > best_f1:
            best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
        print(f'Best val auc: {best_f1:4f}')
        
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
58/13:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
58/14:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 4:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

#                 if val_metrics['f1'][-1] > best_f1:
#                     best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
             
        if val_f1 < best_f1:
            best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
        print(f'Best val auc: {best_f1:4f}')
        
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
58/15:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
58/16:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 4:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

#                 if val_metrics['f1'][-1] > best_f1:
#                     best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
        best_f1=val_f1
             
#         if val_f1 < best_f1:
#             best_f1_=val_f1
#             stop_count = 0
#         else:
#             stop_count = stop_count + 1
        print(f'Best val f1: {best_f1:4f}')
        
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
58/17:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
58/18:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 4:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
        best_f1=val_f1
             
        if val_f1 > best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
        print(f'Best val f1: {best_f1:4f}')
        
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
58/19:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
58/20:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 6:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1
             
        if val_f1 > best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
        print(f'Best val f1: {best_f1:4f}')
        print(f'Stop Count: {stop_count}')
        
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
58/21:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
58/22:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 6:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1
             
        if val_f1 > best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
        print(f'Best val f1: {best_f1:4f}')
        print(f'Stop Count: {stop_count}')
        
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    print (val_f1>best_f1)
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
58/23:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
59/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
59/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
59/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
59/4:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
59/5:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
59/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
59/7:
batch_size = 24
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=12)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=12)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=12)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
59/8:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
59/9:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 6:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1
             
        if val_f1 > best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
        print(f'Best val f1: {best_f1:4f}')
        print(f'Stop Count: {stop_count}')
        
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    print (val_f1>best_f1)
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
59/10:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
59/11:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 6:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1
        print (val_f1,best_f1)
             
        if val_f1 > best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
        print(f'Best val f1: {best_f1:4f}')
        print(f'Stop Count: {stop_count}')
        print (val_f1>best_f1)
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
59/12:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
59/13:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 6:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1
        print (val_f1,best_f1)
             
        if torch.gt(val_f1,best_f1)
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
        print(f'Best val f1: {best_f1:4f}')
        print(f'Stop Count: {stop_count}')
        print (val_f1>best_f1)
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
59/14:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 6:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1
        print (val_f1,best_f1)
             
        if torch.gt(val_f1,best_f1):
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
        print(f'Best val f1: {best_f1:4f}')
        print(f'Stop Count: {stop_count}')
        print (val_f1>best_f1)
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
59/15:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
59/16:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,24))
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model('ssl_resnet50', pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    model.fc = nn.Sequential(
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    nn.Dropout(dropout_rate),
    nn.Linear(in_features=hidden_size, out_features=1, bias=False),
    nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 6:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1
        print (val_f1,best_f1)
             
        if val_f1>=best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
        print(f'Best val f1: {best_f1:4f}')
        print(f'Stop Count: {stop_count}')
        print (val_f1>=best_f1)
#         if stop_count == 6:
#             break
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
59/17:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
60/1:



import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/2: model
60/3:
model
for name, param in model.named_parameters():
    print (name)
60/4:
model
# for name, param in model.named_parameters():
#     print (name)
name
60/5:
model
for name, param in model.named_parameters():
#     print (name)
name
60/6:
model
for name, param in model.named_parameters():
    ijk=0
name
60/7:
model
for name, param in model.named_parameters():
    ijk=0
if "fc" in name:
    classifier_name='fc'
classifier_name
60/8:
model
for name, param in model.named_parameters():
    ijk=0
if "fc" in name:
    classifier_name='fc'
model.classifier_name
60/9:
model
for name, param in model.named_parameters():
    ijk=0
if "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/10:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
60/11:
model
for name, param in model.named_parameters():
    ijk=0
if "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/12:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('efficientnet_b2', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/13:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('densenet201', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/14:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('twins_pcpvt_base', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/15:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('twins_pcpvt_base', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/16:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('twins_svt_base', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/17:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('regnetx_040', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/18:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('efficientnetv2_s', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/19:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('tv_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/20:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('ssl_resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/21:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('ecaresnet101d', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/22:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('resnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/23:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('skresnet50', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/24:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('densenet169', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())

model
60/25:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('densenet169', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
if "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
60/26:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('densenet169', pretrained=True)

num_in_features = model.get_classifier().in_features

# Replace the existing classifier. It's named: classifier
if "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/27:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('densenet169', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
    ijk=0
# Replace the existing classifier. It's named: classifier
if "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/28:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('efficientnet_b2', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
    ijk=0
# Replace the existing classifier. It's named: classifier
if "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/29:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('twins_pcpvt_base', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
    ijk=0
# Replace the existing classifier. It's named: classifier
if "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/30:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('regnetx_040', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
    ijk=0
# Replace the existing classifier. It's named: classifier
if "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/31:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('regnetx_040', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
    print (name?)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/32:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('regnetx_040', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
    print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/33:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('regnetx_040', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
    print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/34:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('resnest50d', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
    print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/35:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('skresnet50', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/36:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('seresnet50', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/37:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('ecaresnet101d', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/38:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('efficientnet_b5', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/39:
# "efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
# "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
# "ecaresnet101d","resnet50","resnet34","resnet101"


import timm
model = timm.create_model('resnet101', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
60/40:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,32))
    optimizer_name = trial.suggest_categorical("optimizer_name", ["LBFGS","RAdam","Adam", "RMSprop", "ASGD", "NAdam", "Adagrad","AdamW","Adamax"])
    model_name = trial.suggest_categorical("model_name", ["efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
                                                          "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
                                                          "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
                                                          "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
                                                          "ecaresnet101d","resnet50","resnet34","resnet101"])
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model(model_name, pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    num_in_features = model.get_classifier().in_features
    for name, param in model.named_parameters():
    #     print (name)
        ijk=0
    # Replace the existing classifier. It's named: classifier
    if "head.fc" in name:
        model.head.fc = nn.Sequential(
        nn.Dropout(.3),
        nn.Linear(in_features=num_in_features, out_features=256, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        #nn.Dropout(.5),
        nn.Linear(in_features=256, out_features=1, bias=False),
        nn.Sigmoid())
    elif "fc" in name:
        model.fc = nn.Sequential(
        nn.Dropout(.3),
        nn.Linear(in_features=num_in_features, out_features=256, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        #nn.Dropout(.5),
        nn.Linear(in_features=256, out_features=1, bias=False),
        nn.Sigmoid())
    elif "classifier" in name:
        model.classifier = nn.Sequential(
        nn.Dropout(.3),
        nn.Linear(in_features=num_in_features, out_features=256, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        #nn.Dropout(.5),
        nn.Linear(in_features=256, out_features=1, bias=False),
        nn.Sigmoid())
    elif "head" in name:
        model.head = nn.Sequential(
        nn.Dropout(.3),
        nn.Linear(in_features=num_in_features, out_features=256, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        #nn.Dropout(.5),
        nn.Linear(in_features=256, out_features=1, bias=False),
        nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    if optimizer_name == "Adam":
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "AdamW":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "NAdam":
        optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RAdam":
        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "LBFGS":
        optimizer = torch.optim.LFBGS(model.parameters(), lr=lr)
    elif optimizer_name == "Adadelta":
        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adagrad":
        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adamax":
        optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RMSprop":
        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    else:
        optimizer = torch.optim.ASGD(model.parameters(), lr=lr, weight_decay=wd)
        
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 4:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1

             
        if val_f1>=best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
60/41:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
61/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
61/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
61/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
61/4:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
61/5:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
61/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
61/7:
batch_size = 20
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=20)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=20)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=20)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
61/8:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
61/9:
#efficientnetv2_s
#ecaresnext50t_32x4d
#ecaresnet50d
#ecaresnet50t
#ecaresnet101d
#efficientnet_b3_gn
#efficientnet_b3
# 'halo2botnet50ts_256',
# , 'halonet26t',
# , 'halonet50ts',
# , 'halonet_h1',
# , 'haloregnetz_b',
#legacy_seresnet50
#mobilenetv3_large_075
#mobilenetv3_small_100
#seresnet50
#seresnext50_32x4d
#skresnet50
#ssl_resnet50
#swsl_resnet50
#visformer_small
#tv_resnet50
#resnest50d  #split Attention
#regnetx_040
#twins_pcpvt_base
#twins_svt_base
61/10:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.5)
    hidden_size = trial.suggest_categorical("hidden_size", [128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,32))
    optimizer_name = trial.suggest_categorical("optimizer_name", ["LBFGS","RAdam","Adam", "RMSprop", "ASGD", "NAdam", "Adagrad","AdamW","Adamax"])
    model_name = trial.suggest_categorical("model_name", ["efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
                                                          "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
                                                          "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
                                                          "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
                                                          "ecaresnet101d","resnet50","resnet34","resnet101"])
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model(model_name, pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    num_in_features = model.get_classifier().in_features
    for name, param in model.named_parameters():
    #     print (name)
        ijk=0
    # Replace the existing classifier. It's named: classifier
    if "head.fc" in name:
        model.head.fc = nn.Sequential(
        nn.Dropout(.3),
        nn.Linear(in_features=num_in_features, out_features=256, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        #nn.Dropout(.5),
        nn.Linear(in_features=256, out_features=1, bias=False),
        nn.Sigmoid())
    elif "fc" in name:
        model.fc = nn.Sequential(
        nn.Dropout(.3),
        nn.Linear(in_features=num_in_features, out_features=256, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        #nn.Dropout(.5),
        nn.Linear(in_features=256, out_features=1, bias=False),
        nn.Sigmoid())
    elif "classifier" in name:
        model.classifier = nn.Sequential(
        nn.Dropout(.3),
        nn.Linear(in_features=num_in_features, out_features=256, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        #nn.Dropout(.5),
        nn.Linear(in_features=256, out_features=1, bias=False),
        nn.Sigmoid())
    elif "head" in name:
        model.head = nn.Sequential(
        nn.Dropout(.3),
        nn.Linear(in_features=num_in_features, out_features=256, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        #nn.Dropout(.5),
        nn.Linear(in_features=256, out_features=1, bias=False),
        nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    if optimizer_name == "Adam":
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "AdamW":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "NAdam":
        optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RAdam":
        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "LBFGS":
        optimizer = torch.optim.LFBGS(model.parameters(), lr=lr)
    elif optimizer_name == "Adadelta":
        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adagrad":
        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adamax":
        optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RMSprop":
        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    else:
        optimizer = torch.optim.ASGD(model.parameters(), lr=lr, weight_decay=wd)
        
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 4:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1

             
        if val_f1>=best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
61/11:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
61/12:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 4e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.3)
    hidden_size = trial.suggest_categorical("hidden_size", [128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,32))
    optimizer_name = trial.suggest_categorical("optimizer_name", ["LBFGS","RAdam","Adam", "RMSprop", "ASGD", "NAdam", "Adagrad","AdamW","Adamax"])
    model_name = trial.suggest_categorical("model_name", ["efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
                                                          "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
                                                          "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
                                                          "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
                                                          "ecaresnet101d","resnet50","resnet34","resnet101"])
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model(model_name, pretrained=True)
    num_in_features = model.get_classifier().in_features
    
    
    # Replace the existing classifier. It's named: classifier
    ##############################
    num_in_features = model.get_classifier().in_features
    for name, param in model.named_parameters():
    #     print (name)
        ijk=0
    if "head.fc" in name:
        model.head.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "fc" in name:
        model.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "classifier" in name:
        model.classifier = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "head" in name:
        model.head = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    ##############################
    
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    if optimizer_name == "Adam":
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "AdamW":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "NAdam":
        optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RAdam":
        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "LBFGS":
        optimizer = torch.optim.LBFGS(model.parameters(), lr=lr)
    elif optimizer_name == "Adadelta":
        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adagrad":
        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adamax":
        optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RMSprop":
        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    else:
        optimizer = torch.optim.ASGD(model.parameters(), lr=lr, weight_decay=wd)
        
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 4:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1

             
        if val_f1>=best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
61/13:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 3e-6, 4e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.3)
    hidden_size = trial.suggest_categorical("hidden_size", [128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',8,32))
    optimizer_name = trial.suggest_categorical("optimizer_name", ["LBFGS","RAdam","Adam", "RMSprop", "ASGD", "NAdam", "Adagrad","AdamW","Adamax"])
    model_name = trial.suggest_categorical("model_name", ["efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
                                                          "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
                                                          "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
                                                          "efficientnetv2_s","efficientnet_b3","efficientnet_b4","ecaresnet50d",
                                                          "ecaresnet101d","resnet50","resnet34","resnet101"])
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model(model_name, pretrained=True)
    num_in_features = model.get_classifier().in_features
    
    
    # Replace the existing classifier. It's named: classifier
    ##############################
    num_in_features = model.get_classifier().in_features
    for name, param in model.named_parameters():
    #     print (name)
        ijk=0
    if "head.fc" in name:
        model.head.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "fc" in name:
        model.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "classifier" in name:
        model.classifier = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "head" in name:
        model.head = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    ##############################
    
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    if optimizer_name == "Adam":
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "AdamW":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "NAdam":
        optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RAdam":
        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "LBFGS":
        optimizer = torch.optim.LBFGS(model.parameters(), lr=lr)
    elif optimizer_name == "Adadelta":
        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adagrad":
        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adamax":
        optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RMSprop":
        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    else:
        optimizer = torch.optim.ASGD(model.parameters(), lr=lr, weight_decay=wd)
        
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 4:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1

             
        if val_f1>=best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
61/14:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=100)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
61/15:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 2e-6, 6e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.3)
    hidden_size = trial.suggest_categorical("hidden_size", [128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',6,32))
    optimizer_name = trial.suggest_categorical("optimizer_name", ["RAdam","Adam", "RMSprop", "ASGD", "NAdam", "Adagrad","AdamW","Adamax"])
    model_name = trial.suggest_categorical("model_name", ["efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
                                                          "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
                                                          "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
                                                          "efficientnet_b3","efficientnet_b4","ecaresnet50d",
                                                          "ecaresnet101d","resnet50","resnet34","resnet101"])
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model(model_name, pretrained=True)
    num_in_features = model.get_classifier().in_features
    
    
    # Replace the existing classifier. It's named: classifier
    ##############################
    num_in_features = model.get_classifier().in_features
    for name, param in model.named_parameters():
    #     print (name)
        ijk=0
    if "head.fc" in name:
        model.head.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "fc" in name:
        model.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "classifier" in name:
        model.classifier = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "head" in name:
        model.head = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    ##############################
    
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    if optimizer_name == "Adam":
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "AdamW":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "NAdam":
        optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RAdam":
        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adadelta":
        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adagrad":
        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adamax":
        optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RMSprop":
        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    else:
        optimizer = torch.optim.ASGD(model.parameters(), lr=lr, weight_decay=wd)
        
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 5:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1

             
        if val_f1>=best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
61/16:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=200)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
61/17:
def train_model(trial):
    lr = trial.suggest_loguniform("lr", 2e-6, 6e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.3)
    hidden_size = trial.suggest_categorical("hidden_size", [128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',6,32))
    optimizer_name = trial.suggest_categorical("optimizer_name", ["RAdam","Adam", "RMSprop", "ASGD", "NAdam", "Adagrad","AdamW","Adamax"])
    model_name = trial.suggest_categorical("model_name", ["efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
                                                          "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
                                                          "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
                                                          "efficientnet_b3","efficientnet_b4","ecaresnet50d",
                                                          "ecaresnet101d","resnet50","resnet34","resnet101"])
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model(model_name, pretrained=True)
    num_in_features = model.get_classifier().in_features
    
    
    # Replace the existing classifier. It's named: classifier
    ##############################
    num_in_features = model.get_classifier().in_features
    for name, param in model.named_parameters():
    #     print (name)
        ijk=0
    if "head.fc" in name:
        model.head.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "fc" in name:
        model.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "classifier" in name:
        model.classifier = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "head" in name:
        model.head = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    ##############################
    
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    if optimizer_name == "Adam":
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "AdamW":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "NAdam":
        optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RAdam":
        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adadelta":
        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adagrad":
        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adamax":
        optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=wd)
#     elif optimizer_name == "RMSprop":
    else:
        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
#     else:
#         optimizer = torch.optim.ASGD(model.parameters(), lr=lr, weight_decay=wd)
        
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 5:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1

             
        if val_f1>=best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
61/18:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=200)
best_params2 = study.best_params
best_f12 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
62/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
62/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
62/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
62/4:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
62/5:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
62/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
62/7:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
62/8:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
62/9:
#efficientnetv2_s
#ecaresnext50t_32x4d
#ecaresnet50d
#ecaresnet50t
#ecaresnet101d
#efficientnet_b3_gn
#efficientnet_b3
# 'halo2botnet50ts_256',
# , 'halonet26t',
# , 'halonet50ts',
# , 'halonet_h1',
# , 'haloregnetz_b',
#legacy_seresnet50
#mobilenetv3_large_075
#mobilenetv3_small_100
#seresnet50
#seresnext50_32x4d
#skresnet50
#ssl_resnet50
#swsl_resnet50
#visformer_small
#tv_resnet50
#resnest50d  #split Attention
#regnetx_040
#twins_pcpvt_base
#twins_svt_base
62/10:
def train_model(trial):
    try:
        lr = trial.suggest_loguniform("lr", 2e-6, 6e-5)
        wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
        dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.3)
        hidden_size = trial.suggest_categorical("hidden_size", [128, 256, 512])
        num_epochs = round(trial.suggest_uniform('num_epochs',6,32))
        optimizer_name = trial.suggest_categorical("optimizer_name", ["RAdam","Adam", "RMSprop", "ASGD", "NAdam", "Adagrad","AdamW","Adamax"])
        model_name = trial.suggest_categorical("model_name", ["efficientnet_b2","efficientnet_b5","densenet264","densenet201","densenet121",
                                                              "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
                                                              "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
                                                              "efficientnet_b3","efficientnet_b4","ecaresnet50d",
                                                              "ecaresnet101d","resnet50","resnet34","resnet101"])
        #c = round(trial.suggest_uniform('c',200,800))
        since = time.time()
        metricf1 = BinaryF1Score()
        precision = BinaryPrecision()
        recall = BinaryRecall()
        accuracy = BinaryAccuracy()
        roc = BinaryROC()
        auc = BinaryAUROC()
        #best_model_wts = model.state_dict()
        stop_count = 0
        best_f1 = -1.0
        train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
        val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
        # inital threshold for first epoch, it will change afterwards
        threshold = 0.5
        sched_steps=[]
        print('Starting training...')
        print('-' * 20)


        ## Import Model
        import timm
        model = timm.create_model(model_name, pretrained=True)
        num_in_features = model.get_classifier().in_features


        # Replace the existing classifier. It's named: classifier
        ##############################
        num_in_features = model.get_classifier().in_features
        for name, param in model.named_parameters():
        #     print (name)
            ijk=0
        if "head.fc" in name:
            model.head.fc = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
            nn.LeakyReLU(.1,inplace=True),
            nn.Dropout(dropout_rate),
            nn.Linear(in_features=hidden_size, out_features=1, bias=False),
            nn.Sigmoid())
        elif "fc" in name:
            model.fc = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
            nn.LeakyReLU(.1,inplace=True),
            nn.Dropout(dropout_rate),
            nn.Linear(in_features=hidden_size, out_features=1, bias=False),
            nn.Sigmoid())
        elif "classifier" in name:
            model.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
            nn.LeakyReLU(.1,inplace=True),
            nn.Dropout(dropout_rate),
            nn.Linear(in_features=hidden_size, out_features=1, bias=False),
            nn.Sigmoid())
        elif "head" in name:
            model.head = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
            nn.LeakyReLU(.1,inplace=True),
            nn.Dropout(dropout_rate),
            nn.Linear(in_features=hidden_size, out_features=1, bias=False),
            nn.Sigmoid())
        ##############################

        print ('model imported')
        ## Model Imported
        torch.cuda.empty_cache() 

        device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
        if torch.cuda.is_available():
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.benchmark = True


        if optimizer_name == "Adam":
            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
        elif optimizer_name == "AdamW":
            optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
        elif optimizer_name == "NAdam":
            optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)
        elif optimizer_name == "RAdam":
            optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=wd)
        elif optimizer_name == "Adadelta":
            optimizer = torch.optim.Adadelta(model.parameters(), lr=lr, weight_decay=wd)
        elif optimizer_name == "Adagrad":
            optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=wd)
        elif optimizer_name == "Adamax":
            optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=wd)
    #     elif optimizer_name == "RMSprop":
        else:
            optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    #     else:
    #         optimizer = torch.optim.ASGD(model.parameters(), lr=lr, weight_decay=wd)

        scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
        model.to(device)


        criterion = nn.BCELoss()

        test_size=len(test_dataset)
        dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
        dataset_sizes = {'train': train_size, 'val' : test_size}


    #     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
    #     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
    #     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


        for epoch in range(num_epochs):
            if stop_count >= 5:
                print('Early stopping due to lack of validation improvement')
                break

            # Each epoch has a training and validation phase
            for phase in ['train', 'val']:
                # empty 'all' tensors for saving
                # for calculating aoc at the end of epoch, and for calculating new threshold
                all_outputs = torch.Tensor([])
                all_labels = torch.Tensor([])
                if phase == 'train':
                    model.train()  # Set model to training mode
                else:
                    model.eval()   # Set model to evaluate mode
                running_loss = 0.0
                n_samples = 0
                n_correct = 0
                running_f1 = 0.0
                # Iterate over data.
    #             print(f'{phase} for epoch {epoch + 1}')
                for inputs, labels in dataloaders[phase]:
                    labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                    #labels=torch.tensor(labels)
                    inputs = inputs.float()
                    inputs = inputs.to(device)
                    labels = labels.to(device)
                    # zero the parameter gradients
                    optimizer.zero_grad()
                    # forward
                    # track history if only in train
                    with torch.set_grad_enabled(phase == 'train'):
                        outputs = model(inputs)

                        # concatenating all outputs and labels for calculation aoc and new threshold
                        all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                        all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                        loss = criterion(outputs, labels)
                        # backward + optimize only if in training phase
                        if phase == 'train':
                            loss.backward()
                            optimizer.step()
                            scheduler.step()

                    running_loss += loss.item()
                    # collect any unused memmory
                    gc.collect()
                    torch.cuda.empty_cache()           
                # statistics
    #             scheduler.step()
                epoch_loss = running_loss / len(dataloaders[phase])            
                all_labels=all_labels.to(dtype=torch.long)
                fpr, tpr, thresholds = roc(all_outputs, all_labels)
                epoch_auc = auc(all_outputs, all_labels)
                threshold, _ = find_optim_thres(fpr, tpr, thresholds)
                epoch_f1 = metricf1(all_outputs > threshold, all_labels)

                if phase == 'train':
                    train_metrics['f1'].append(epoch_f1)

                else:
                    val_metrics['loss'].append(epoch_loss)
                    val_metrics['f1'].append(epoch_f1)

                    if val_metrics['f1'][-1] > best_f1:
                        best_f1 = val_metrics['f1'][-1]


            # cant be formated in strin g
    #         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
            val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
    #         lr = optimizer.param_groups[0]['lr']
            print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
    #         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
            print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
            trial.report(val_f1, epoch)

            # Handle pruning based on the intermediate value.
            if trial.should_prune():
                raise optuna.TrialPruned()

            
    #         best_f1=val_f1


            if val_f1>=best_f1:
    #             best_f1_=val_f1
                stop_count = 0
            else:
                stop_count = stop_count + 1


        time_elapsed = time.time() - since
        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
        print(f'Best val auc: {best_f1:4f}')
        gc.collect()
        torch.cuda.empty_cache() 

        # load best model weights
    #     model.load_state_dict(best_model_wts)
        return best_f1
    except:
        gc.collect()
        torch.cuda.empty_cache() 
        ('error with model')
        return None
62/11:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=200)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
64/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
64/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
64/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
64/4:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
64/5:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
64/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.1
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
64/7:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
64/8:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
64/9:
#efficientnetv2_s
#ecaresnext50t_32x4d
#ecaresnet50d
#ecaresnet50t
#ecaresnet101d
#efficientnet_b3_gn
#efficientnet_b3
# 'halo2botnet50ts_256',
# , 'halonet26t',
# , 'halonet50ts',
# , 'halonet_h1',
# , 'haloregnetz_b',
#legacy_seresnet50
#mobilenetv3_large_075
#mobilenetv3_small_100
#seresnet50
#seresnext50_32x4d
#skresnet50
#ssl_resnet50
#swsl_resnet50
#visformer_small
#tv_resnet50
#resnest50d  #split Attention
#regnetx_040
#twins_pcpvt_base
#twins_svt_base
64/10:
def train_model(trial):
    #try:
    lr = trial.suggest_loguniform("lr", 2e-6, 6e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.3)
    hidden_size = trial.suggest_categorical("hidden_size", [128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',6,32))
    optimizer_name = trial.suggest_categorical("optimizer_name", ["RAdam","Adam", "RMSprop", "SGD", "NAdam","AdamW"])
    model_name = trial.suggest_categorical("model_name", ["efficientnet_b2","densenet264","densenet201","densenet121",
                                                          "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
                                                          "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
                                                          "efficientnet_b3","efficientnet_b4","ecaresnet50d",
                                                          "ecaresnet101d","resnet50","resnet34","resnet101"])
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)


    ## Import Model
    import timm
    model = timm.create_model(model_name, pretrained=True)
    num_in_features = model.get_classifier().in_features


    # Replace the existing classifier. It's named: classifier
    ##############################
    num_in_features = model.get_classifier().in_features
    for name, param in model.named_parameters():
    #     print (name)
        ijk=0
    if "head.fc" in name:
        model.head.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "fc" in name:
        model.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "classifier" in name:
        model.classifier = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "head" in name:
        model.head = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    ##############################

    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True


    if optimizer_name == "Adam":
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "AdamW":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "NAdam":
        optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RAdam":
        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "SGD":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adagrad":
        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adamax":
        optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=wd)
#     elif optimizer_name == "RMSprop":
    else:
        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
#     else:
#         optimizer = torch.optim.ASGD(model.parameters(), lr=lr, weight_decay=wd)

    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    for epoch in range(num_epochs):
        if stop_count >= 6:
            print('Early stopping due to lack of validation improvement')
            break

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]


        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()


#         best_f1=val_f1


        if val_f1>=best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1


    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    gc.collect()
    torch.cuda.empty_cache() 

    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
    #except:
    #    gc.collect()
    #    torch.cuda.empty_cache() 
    #    ('error with model')
    #    return None
64/11:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=200)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
64/12:
batch_size = 16
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size, drop_last=True)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size, drop_last=True)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size, drop_last=True)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
65/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
65/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
65/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
65/4:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
65/5:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
65/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.01
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
65/7:
batch_size = 18
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size, drop_last=True)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size, drop_last=True)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size, drop_last=True)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
65/8:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
65/9:
#efficientnetv2_s
#ecaresnext50t_32x4d
#ecaresnet50d
#ecaresnet50t
#ecaresnet101d
#efficientnet_b3_gn
#efficientnet_b3
# 'halo2botnet50ts_256',
# , 'halonet26t',
# , 'halonet50ts',
# , 'halonet_h1',
# , 'haloregnetz_b',
#legacy_seresnet50
#mobilenetv3_large_075
#mobilenetv3_small_100
#seresnet50
#seresnext50_32x4d
#skresnet50
#ssl_resnet50
#swsl_resnet50
#visformer_small
#tv_resnet50
#resnest50d  #split Attention
#regnetx_040
#twins_pcpvt_base
#twins_svt_base
65/10:
def train_model(trial):
    #try:
    lr = trial.suggest_loguniform("lr", 2e-6, 6e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.3)
    hidden_size = trial.suggest_categorical("hidden_size", [128, 256, 512])
    num_epochs = round(trial.suggest_uniform('num_epochs',6,32))
    optimizer_name = trial.suggest_categorical("optimizer_name", ["RAdam","Adam", "RMSprop", "SGD", "NAdam","AdamW"])
    model_name = trial.suggest_categorical("model_name", ["efficientnet_b2","densenet264","densenet201","densenet121",
                                                          "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040",
                                                          "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50",
                                                          "efficientnet_b3","efficientnet_b4","ecaresnet50d",
                                                          "ecaresnet101d","resnet50","resnet34","resnet101"])
    #c = round(trial.suggest_uniform('c',200,800))
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)


    ## Import Model
    import timm
    model = timm.create_model(model_name, pretrained=True)
    num_in_features = model.get_classifier().in_features


    # Replace the existing classifier. It's named: classifier
    ##############################
    num_in_features = model.get_classifier().in_features
    for name, param in model.named_parameters():
    #     print (name)
        ijk=0
    if "head.fc" in name:
        model.head.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "fc" in name:
        model.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "classifier" in name:
        model.classifier = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "head" in name:
        model.head = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    ##############################

    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True


    if optimizer_name == "Adam":
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "AdamW":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "NAdam":
        optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RAdam":
        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "SGD":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adagrad":
        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adamax":
        optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=wd)
#     elif optimizer_name == "RMSprop":
    else:
        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
#     else:
#         optimizer = torch.optim.ASGD(model.parameters(), lr=lr, weight_decay=wd)

    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)


    for epoch in range(num_epochs):
        if stop_count >= 6:
            print('Early stopping due to lack of validation improvement')
            break

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)

            if phase == 'train':
                train_metrics['f1'].append(epoch_f1)

            else:
                val_metrics['loss'].append(epoch_loss)
                val_metrics['f1'].append(epoch_f1)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]


        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()


#         best_f1=val_f1


        if val_f1>=best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1


    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    gc.collect()
    torch.cuda.empty_cache() 

    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
    #except:
    #    gc.collect()
    #    torch.cuda.empty_cache() 
    #    ('error with model')
    #    return None
65/11:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))
study.optimize(train_model,n_trials=200)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
66/1:
#efficientnetv2_s
#ecaresnext50t_32x4d
#ecaresnet50d
#ecaresnet50t
#ecaresnet101d
#efficientnet_b3_gn
#efficientnet_b3
# 'halo2botnet50ts_256',
# , 'halonet26t',
# , 'halonet50ts',
# , 'halonet_h1',
# , 'haloregnetz_b',
#legacy_seresnet50
#mobilenetv3_large_075
#mobilenetv3_small_100
#seresnet50
#seresnext50_32x4d
#skresnet50
#ssl_resnet50
#swsl_resnet50
#visformer_small
#tv_resnet50
#resnest50d  #split Attention
#regnetx_040
#twins_pcpvt_base
#twins_svt_base
import timm
timm.list_models()
66/2:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('efficientformer_l3', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/3:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('ig_resnext101_32x8d', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/4:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
66/5:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('ig_resnext101_32x8d', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/6:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('tf_efficientnet_b3', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/7:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('regnety_064', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/8:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('mobilenetv2_100', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/9:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('resnetv2_50', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/10: model
66/11:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('seresnet50t', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/12:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('vgg19_bn', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/13:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('sedarknet21', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/14:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('gcresnet50t', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/15:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('gluon_seresnext50_32x4d', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/16:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('gluon_seresnext50_32x4d', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/17:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('ecaresnext50t_32x4d', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/18:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('ecaresnet101d', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
66/19:
# ["efficientnet_b2","densenet264","densenet201","densenet121","efficientformer_l3","ig_resnext101_32x8d","tf_efficientnet_b3",
# "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
# "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","resnetv2_50","seresnet50t",
# "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
# "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])


import timm
model = timm.create_model('resnest50d', pretrained=True)

num_in_features = model.get_classifier().in_features
for name, param in model.named_parameters():
#     print (name)
    ijk=0
# Replace the existing classifier. It's named: classifier
if "head.fc" in name:
    model.head.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "fc" in name:
    model.fc = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "classifier" in name:
    model.classifier = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
elif "head" in name:
    model.head = nn.Sequential(
    nn.Dropout(.3),
    nn.Linear(in_features=num_in_features, out_features=256, bias=False),
    nn.LeakyReLU(.1,inplace=True),
    #nn.Dropout(.5),
    nn.Linear(in_features=256, out_features=1, bias=False),
    nn.Sigmoid())
model
67/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
67/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
67/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
67/4:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
67/5:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
67/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.01
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
67/7:
batch_size = 18
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size, drop_last=True)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size, drop_last=True)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size, drop_last=True)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
67/8:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
67/9:
def train_model(trial):
    import wandb
    
    lr = trial.suggest_loguniform("lr", 5e-6, 5e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.3)
    hidden_size = trial.suggest_categorical("hidden_size", [64,128, 256,512])
    #batch_size = trial.suggest_categorical("batch_size", [8, 12])
    num_epochs = trial.suggest_int('num_epochs',8,32)
    optimizer_name = trial.suggest_categorical("optimizer_name", ["RAdam","Adam", "RMSprop", "SGD", "NAdam", "AdamW"])
    model_name = trial.suggest_categorical("model_name", ["efficientnet_b2","densenet264","densenet201","densenet121","ig_resnext101_32x8d","tf_efficientnet_b3",
                                                          "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
                                                          "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","seresnet50t",
                                                          "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
                                                          "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])
    #c = round(trial.suggest_int('c',200,800))
#     model_name='densenet169'
    
    # start a new wandb run to track this script
    wandb.init(
        # set the wandb project where this run will be logged
        project="Optuna Model and Hyperparameter Training",
        # track hyperparameters and run metadata
        config={
        "learning_rate": lr,
        "architecture": model_name,
        "dataset": "v7-calc",
        "epochs": num_epochs,
        "batch size": batch_size,
        "hidden size": hidden_size, 
        "optimizer_name": optimizer_name,
        "dropout_rate": dropout_rate,
        "weight decay": wd,       
        }
    )
    
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model(model_name, pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    num_in_features = model.get_classifier().in_features
    for name, param in model.named_parameters():
    #     print (name)
        ijk=0
    # Replace the existing classifier. It's named: classifier
    if "head.fc" in name:
        model.head.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "fc" in name:
        model.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "classifier" in name:
        model.classifier = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "head" in name:
        model.head = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    if optimizer_name == "Adam":
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "AdamW":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "NAdam":
        optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RAdam":
        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=wd)

    elif optimizer_name == "Adadelta":
        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adagrad":
        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adamax":
        optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RMSprop":
        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    else:
        optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd)
        
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 6:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1

             
        if val_f1>=best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    wandb.finish()
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
67/10:
def train_model(trial):
    import wandb
    
    lr = trial.suggest_loguniform("lr", 5e-6, 5e-5)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.3)
    hidden_size = trial.suggest_categorical("hidden_size", [64,128, 256,512])
    #batch_size = trial.suggest_categorical("batch_size", [8, 12])
    num_epochs = trial.suggest_int('num_epochs',10,32)
    optimizer_name = trial.suggest_categorical("optimizer_name", ["RAdam","Adam", "RMSprop", "SGD", "NAdam", "AdamW"])
    model_name = trial.suggest_categorical("model_name", ["efficientnet_b2","densenet264","densenet201","densenet121","ig_resnext101_32x8d","tf_efficientnet_b3",
                                                          "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
                                                          "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","seresnet50t",
                                                          "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
                                                          "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])
    #c = round(trial.suggest_int('c',200,800))
#     model_name='densenet169'
    
    # start a new wandb run to track this script
    wandb.init(
        # set the wandb project where this run will be logged
        project="Optuna Model and Hyperparameter Training",
        # track hyperparameters and run metadata
        config={
        "learning_rate": lr,
        "architecture": model_name,
        "dataset": "v7-calc",
        "epochs": num_epochs,
        "batch size": batch_size,
        "hidden size": hidden_size, 
        "optimizer_name": optimizer_name,
        "dropout_rate": dropout_rate,
        "weight decay": wd,       
        }
    )
    
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model(model_name, pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    num_in_features = model.get_classifier().in_features
    for name, param in model.named_parameters():
    #     print (name)
        ijk=0
    # Replace the existing classifier. It's named: classifier
    if "head.fc" in name:
        model.head.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "fc" in name:
        model.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "classifier" in name:
        model.classifier = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "head" in name:
        model.head = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    if optimizer_name == "Adam":
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "AdamW":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "NAdam":
        optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RAdam":
        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=wd)

    elif optimizer_name == "Adadelta":
        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adagrad":
        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adamax":
        optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RMSprop":
        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    else:
        optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd)
        
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 6:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
            epoch_precision = precision(all_outputs > threshold, all_labels)
            epoch_recall = recall(all_outputs > threshold, all_labels)
            print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_precision": epoch_precision
                         , "train_recall": epoch_recall, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
                train_metrics['precision'].append(epoch_precision)
                train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1, "val_precision": epoch_precision
                         , "val_recall": epoch_recall, "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
                val_metrics['precision'].append(epoch_precision)
                val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1

             
        if val_f1>=best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    wandb.finish()
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
67/11:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=7))
study.optimize(train_model,n_trials=300)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
68/1:
from __future__ import print_function, division
import numpy as np
import pandas as pd
import os


import torch
from skimage import io, transform
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torchvision import datasets
from torchvision.transforms import ToTensor
import cv2
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
# from torch.optim import Adam, SGD
from torch.autograd import Variable
from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from torchvision import models
from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC
import PIL
from PIL import Image

# visualisation
import seaborn as sns

# helpers
from tqdm import tqdm
import time
import copy
import gc
from enum import Enum

import warnings
warnings.filterwarnings('ignore')

metadata_list=['calc_case_description_test_set','calc_case_description_train_set']
#'mass_case_description_test_set','mass_case_description_train_set',
df_list=[]
for j in range(len(metadata_list)):
    print (metadata_list[j])
    df=pd.read_csv('/home/mbadhan/Desktop/mberghouse/'+metadata_list[j]+'.csv')
    print (len(df))
    
    fname=[]

    df=df.rename(columns={"file path": "filename","pathology":"class", 'image file path':'filename','cropped image file path':'patch_filename'})
###Remove multiple-counted images for whole image
    for k in range(len(df)):
        fname.append(df['filename'].loc[k])
        if k>0:
            if fname[k] == fname[k-1]:
                df.drop(k, inplace=True)
    print ('df length after removal of repeats: ', len(df))
    
    
    nan_count=0

    for i in range(len(df)):
### For whole images
        df.filename.iloc[i]='/home/mbadhan/Desktop/mberghouse/CBIS-DDSM-preprocessed/300x500_v6/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.png'
        #df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
        if 'MALIGNANT' in df['class'].iloc[i]:
            df['class'].iloc[i]=1
        else:
            df['class'].iloc[i]=0
    df_list.append(df)
    
### For patches
        ##i=i-nan_count
       ## df.filename.iloc[i]='C:/Users/marcb/Desktop/CBIS-DDSM-preprocessed/v4_3d/'+df.filename.iloc[i].rsplit('/',3)[0]+'/1-1.jpg'
        ##df.filename[i]='F:/CBIS_DDSM_redo/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-png/'+df.filename[i].rsplit('/',3)[0]+'/1-1.png'
### For Masses
#         try:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/CBIS-DDSM-mask/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#         except:
#             path1 = 'F:/CBIS_DDSM/manifest-ZkhPvrLo5216730872708713142/cropped/'+df.patch_filename.iloc[i].rsplit('/',3)[0]
#             folder1=os.listdir(path1)[0]
#             folder2=os.listdir(os.path.join(path1,folder1))[0]
#             img = os.listdir(os.path.join(path1,folder1,folder2))
#             im0_path=os.path.join(path1,folder1,folder2,img[0])
#             im0=cv2.imread(im0_path)
#             if len(img)>1:               
#                 if np.median(im0)==0:
#                     img_path = os.path.join(path1,folder1,folder2,img[1])
#                 else:
#                     img_path = im0_path
#             else:
#                 if np.median(im0)==0:
#                     img_path = np.nan
#                     nan_count = nan_count+1
#                 else:
#                     img_path = im0_path
#             df.patch_filename.iloc[i]=img_path
#             #df.dropna(inplace=True)
        
#         if 'MALIGNANT' in df['class'].iloc[i]:
#             df['class'].iloc[i]=1
#         else:
#             df['class'].iloc[i]=0
#     df.dropna(inplace=True)
#     df_list.append(df)
#df_list
# df_mass_test=df_list[0]
# df_mass_train=df_list[1]
df_calc_test=df_list[0]
df_calc_train=df_list[1]

# filenames=[]
# labels=[]
# for i in range(len(df_mass_train)):
#     filenames.append(df_mass_train.filename.iloc[i])
#     labels.append(df_mass_train['class'].iloc[i])

# filenames_test=[]
# labels_test=[]
# for i in range(len(df_mass_test)):
#     filenames_test.append(df_mass_test.filename.iloc[i])
#     labels_test.append(df_mass_test['class'].iloc[i])
    
# filenames_calc=[]
# labels_calc=[]
# for i in range(len(df_calc_train)):
#     filenames_calc.append(df_calc_train.filename.iloc[i])
#     labels_calc.append(df_calc_train['class'].iloc[i])

# filenames_test_calc=[]
# labels_test_calc=[]
# for i in range(len(df_calc_test)):
#     filenames_test_calc.append(df_calc_test.filename.iloc[i])
#     labels_test_calc.append(df_calc_test['class'].iloc[i])
68/2:
filenames_calc=[]
labels_calc=[]
for i in range(len(df_calc_train)):
    filenames_calc.append(df_calc_train.filename.iloc[i])
    labels_calc.append(df_calc_train['class'].iloc[i])

filenames_test_calc=[]
labels_test_calc=[]
for i in range(len(df_calc_test)):
    filenames_test_calc.append(df_calc_test.filename.iloc[i])
    labels_test_calc.append(df_calc_test['class'].iloc[i])
68/3:

import torchvision
import numpy.matlib as np_mlb
#torchvision.disable_beta_transforms_warning()
#import torchvision.transforms.v2 as transforms

#plt.ion()   # interactive mode

##########################################
##### HERE ARE THE AUGMENTATIONS!!! ######
##########################################
# affine_transfomer = T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))

augmentator = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    
    transforms.ColorJitter(brightness=(.6,1.2)),
#     transforms.Pad(padding=(12,3)),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(),
#     transforms.RandomAdjustSharpness(1.5, p=0.5),
#     transforms.RandomPhotometricDistort(),
    #transforms.RandomZoomOut(fill = 0, side_range = (1, 1.3)),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.RandomRotation(8),
#     transforms.Resize(size=(500,300)),
    #transforms.RandomAffine(degrees=(0,10),translate=(0.01, 0.02),  shear=(.5,.5)),
    #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(.5)),
#     transforms.RandomEqualize(p=.1),
#    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    #transforms.ConvertImageDtype(torch.float32),# return it as a tensor and transforms it to [0, 1]
])

small_aug = transforms.Compose([
    # input for augmentator is always PIL image
    transforms.ToPILImage(),
    #transforms.Pad(10),
    #torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()
    transforms.ToTensor(),
    #transforms.v2.ConvertImageDtype(torch.float32)# return it as a tensor and transforms it to [0, 1]
])

def show_landmarks(image, label):
    """Show image with landmarks"""
    plt.imshow(image)
    if label==0:
        classif='Benign'
    else:
        classif='Malignant'
    print ('Class: ',classif)
    plt.pause(0.001)  # pause a bit so that plots are updated

class CBISDataset(Dataset):
    """CBIS-DDSM dataset."""

    def __init__(self, labels, filenames, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.labels = labels
        self.filenames = filenames
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        fname = self.filenames[idx]
        image = cv2.imread(fname)
#         image = cv2.resize(image, (344,344))
#         image = (((image-np.min(image))/(np.max(image)-np.min(image)))*255).astype('uint8')
#         clahe = cv2.createCLAHE(clipLimit = 2,tileGridSize=(12,12))
#         image = clahe.apply(image[:,:,0])
#         image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)
       # image = torchvision.io.read_image(fname)#, torchvision.io.ImageReadMode.RGB)
       # image = image.repeat([3, 1, 1])
        label = self.labels[idx]    
        if self.transform:
            image = self.transform(image)

        return image, label
68/4:
# filenames_calc.pop(375)
# filenames_calc.pop(494)
# filenames_calc.pop(705)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# filenames_calc.pop(928)
# labels_calc.pop(375)
# labels_calc.pop(494)
# labels_calc.pop(705)
# labels_calc.pop(928)
# labels_calc.pop(928)
# labels_calc.pop(928)
68/5:
# filenames_calc.pop(520)
# filenames_calc.pop(520)
# filenames_calc.pop(838)
# filenames_calc.pop(1107)
# filenames_calc.pop(1107)

# labels_calc.pop(520)
# labels_calc.pop(520)
# labels_calc.pop(838)
# labels_calc.pop(1107)
# labels_calc.pop(1107)
68/6:
dataset = CBISDataset(labels_calc,filenames_calc,transform=augmentator)

val_pct = 0.01
val_size = int(val_pct * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
test_dataset = CBISDataset(labels_test_calc,filenames_test_calc, transform=small_aug)
val_size =  len(val_dataset)
train_size = len(train_dataset)
68/7:
batch_size = 18
#try pin memory = False

# Create data loaders.
#train_dataloader = DataLoader(dataset, batch_size=batch_size,
#                        shuffle=True)#, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, pin_memory = True,num_workers=batch_size, drop_last=True)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, pin_memory = True,num_workers=batch_size, drop_last=True)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True, pin_memory = True,num_workers=batch_size, drop_last=True)


for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    #img=X
    break
plt.imshow(X[0,0,:,:])
68/8:

    
    
# create class for earlystopping
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_loss = np.inf

    def early_stop(self, loss):
        if loss <= self.min_loss:
            self.min_loss = loss
            self.counter = 0
        elif loss > (self.min_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
    
def BCELoss_class_weighted(weights):
    """
    weights[0] is weight for class 0 (negative class)
    weights[1] is weight for class 1 (positive class)
    """
    def loss(y_pred, target):
        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability
        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)
        return torch.mean(bce)

    return loss

def find_optim_thres(fpr, tpr, thresholds):
    optim_thres = thresholds[0]
    inx = 0
    min_dist = 1.0
    for i in range(len(fpr)):
        dist = np.linalg.norm(np.array([0.0, 1.0]) - np.array([fpr[i], tpr[i]]))
        if dist < min_dist:
            min_dist = dist
            optim_thres = thresholds[i]
            inx = i
            
    return optim_thres, inx
68/9:
#efficientnetv2_s
#ecaresnext50t_32x4d
#ecaresnet50d
#ecaresnet50t
#ecaresnet101d
#efficientnet_b3_gn
#efficientnet_b3
# 'halo2botnet50ts_256',
# , 'halonet26t',
# , 'halonet50ts',
# , 'halonet_h1',
# , 'haloregnetz_b',
#legacy_seresnet50
#mobilenetv3_large_075
#mobilenetv3_small_100
#seresnet50
#seresnext50_32x4d
#skresnet50
#ssl_resnet50
#swsl_resnet50
#visformer_small
#tv_resnet50
#resnest50d  #split Attention
#regnetx_040
#twins_pcpvt_base
#twins_svt_base
# import timm
# timm.list_models()
68/10:
def train_model(trial):
    import wandb
    
    lr = trial.suggest_loguniform("lr", 5e-6, 1e-4)
    wd = trial.suggest_loguniform("wd", 1e-5, 1e-2)
    dropout_rate = trial.suggest_uniform("dropout_rate", 0.0, 0.3)
    hidden_size = trial.suggest_categorical("hidden_size", [64,128, 256,512])
    #batch_size = trial.suggest_categorical("batch_size", [8, 12])
    num_epochs = trial.suggest_int('num_epochs',10,40)
    optimizer_name = trial.suggest_categorical("optimizer_name", ["RAdam","Adam", "RMSprop", "SGD", "NAdam", "AdamW"])
    model_name = trial.suggest_categorical("model_name", ["efficientnet_b2","densenet201","densenet121","ig_resnext101_32x8d","tf_efficientnet_b3",
                                                          "densenet169","densenet161","twins_pcpvt_base","twins_svt_base","regnetx_040","regnetx_064","regnety_040","regnety_064",
                                                          "resnest50d","tv_resnet50","skresnet50","seresnet50","ssl_resnet50","swsl_resnet50","seresnet50t",
                                                          "efficientnet_b3","efficientnet_b4","ecaresnet50d","ecaresnext50t_32x4d","mobilenetv2_050","mobilenetv2_100","vgg19_bn",
                                                          "ecaresnet101d","resnet50","resnet34","resnet101","darknet53","sedarknet21","darknet21","gcresnet50t","gluon_seresnext50_32x4d"])
    #c = round(trial.suggest_int('c',200,800))
#     model_name='densenet169'
    
    # start a new wandb run to track this script
    wandb.init(
        # set the wandb project where this run will be logged
        project="Optuna Model and Hyperparameter Training",
        # track hyperparameters and run metadata
        config={
        "learning_rate": lr,
        "architecture": model_name,
        "dataset": "v7-calc",
        "epochs": num_epochs,
        "batch size": batch_size,
        "hidden size": hidden_size, 
        "optimizer_name": optimizer_name,
        "dropout_rate": dropout_rate,
        "weight decay": wd,       
        }
    )
    
    since = time.time()
    metricf1 = BinaryF1Score()
    precision = BinaryPrecision()
    recall = BinaryRecall()
    accuracy = BinaryAccuracy()
    roc = BinaryROC()
    auc = BinaryAUROC()
    #best_model_wts = model.state_dict()
    stop_count = 0
    best_f1 = -1.0
    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    val_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}
    # inital threshold for first epoch, it will change afterwards
    threshold = 0.5
    sched_steps=[]
    print('Starting training...')
    print('-' * 20)
    
    
    ## Import Model
    import timm
    model = timm.create_model(model_name, pretrained=True)
    num_in_features = model.get_classifier().in_features
    # Replace the existing classifier. It's named: classifier
    num_in_features = model.get_classifier().in_features
    for name, param in model.named_parameters():
    #     print (name)
        ijk=0
    # Replace the existing classifier. It's named: classifier
    if "head.fc" in name:
        model.head.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "fc" in name:
        model.fc = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "classifier" in name:
        model.classifier = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    elif "head" in name:
        model.head = nn.Sequential(
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=num_in_features, out_features=hidden_size, bias=False),
        nn.LeakyReLU(.1,inplace=True),
        nn.Dropout(dropout_rate),
        nn.Linear(in_features=hidden_size, out_features=1, bias=False),
        nn.Sigmoid())
    print ('model imported')
    ## Model Imported
    torch.cuda.empty_cache() 

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

    
    if optimizer_name == "Adam":
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "AdamW":
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "NAdam":
        optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RAdam":
        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=wd)

    elif optimizer_name == "Adadelta":
        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adagrad":
        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "Adamax":
        optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=wd)
    elif optimizer_name == "RMSprop":
        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)
    else:
        optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd)
        
    scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)
    model.to(device)


    criterion = nn.BCELoss()

    test_size=len(test_dataset)
    dataloaders = {'train' : train_dataloader, 'val' : test_dataloader}
    dataset_sizes = {'train': train_size, 'val' : test_size}


#     model, train_metrics, val_metrics, sched_steps = train_model(model, criterion, optimizer, [scheduler,scheduler1], num_epochs=e1)
#     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr2, weight_decay=wd1)
#     scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 400, T_mult=2, eta_min=1e-12, last_epoch=- 1, verbose=False)

    
    for epoch in range(num_epochs):
        if stop_count >= 6:
            print('Early stopping due to lack of validation improvement')
            break
        
        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            # empty 'all' tensors for saving
            # for calculating aoc at the end of epoch, and for calculating new threshold
            all_outputs = torch.Tensor([])
            all_labels = torch.Tensor([])
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            running_loss = 0.0
            n_samples = 0
            n_correct = 0
            running_f1 = 0.0
            # Iterate over data.
#             print(f'{phase} for epoch {epoch + 1}')
            for inputs, labels in dataloaders[phase]:
                labels = torch.unsqueeze(torch.tensor(labels), 1).to(dtype=torch.float)               
                #labels=torch.tensor(labels)
                inputs = inputs.float()
                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    # concatenating all outputs and labels for calculation aoc and new threshold
                    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                    all_labels = torch.cat((all_labels, labels.to('cpu')))                  

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                        scheduler.step()

                running_loss += loss.item()
                # collect any unused memmory
                gc.collect()
                torch.cuda.empty_cache()           
            # statistics
#             scheduler.step()
            epoch_loss = running_loss / len(dataloaders[phase])            
            all_labels=all_labels.to(dtype=torch.long)
            fpr, tpr, thresholds = roc(all_outputs, all_labels)
            epoch_auc = auc(all_outputs, all_labels)
            threshold, _ = find_optim_thres(fpr, tpr, thresholds)
            epoch_f1 = metricf1(all_outputs > threshold, all_labels)
            epoch_acc = accuracy(all_outputs > threshold, all_labels)
#             epoch_precision = precision(all_outputs > threshold, all_labels)
#             epoch_recall = recall(all_outputs > threshold, all_labels)
#             print(f'{phase} F1 is {epoch_f1}')            
            # save all of the statistics for latter analysis
            if phase == 'train':
                wandb.log({"train_acc": epoch_acc, "train_loss": epoch_loss, "train_f1": epoch_f1, "train_auc": epoch_auc})
                train_metrics['loss'].append(epoch_loss)
                train_metrics['acc'].append(epoch_acc)
                train_metrics['f1'].append(epoch_f1)
#                 train_metrics['precision'].append(epoch_precision)
#                 train_metrics['recall'].append(epoch_recall)
                train_metrics['auc'].append(epoch_auc)
            else:
                wandb.log({"val_acc": epoch_acc, "val_loss": epoch_loss, "val_f1": epoch_f1,  "val_auc": epoch_auc})
                val_metrics['loss'].append(epoch_loss)
                val_metrics['acc'].append(epoch_acc)
                val_metrics['f1'].append(epoch_f1)
#                 val_metrics['precision'].append(epoch_precision)
#                 val_metrics['recall'].append(epoch_recall)
                val_metrics['auc'].append(epoch_auc)

                if val_metrics['f1'][-1] > best_f1:
                    best_f1 = val_metrics['f1'][-1]

               
        # cant be formated in strin g
#         tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], train_metrics['acc'][-1],  train_metrics['f1'][-1], train_metrics['precision'][-1], train_metrics['recall'][-1], train_metrics['auc'][-1]
        val_loss, val_f1 = val_metrics['loss'][-1], val_metrics['f1'][-1]
#         lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch + 1}/{num_epochs}, learning rate: {lr}')
#         print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')
        print(f'Valitadion Loss: {val_loss:.4f}, Val f1: {val_f1:.4f}') 
        trial.report(val_f1, epoch)

        # Handle pruning based on the intermediate value.
        if trial.should_prune():
            raise optuna.TrialPruned()
            
        gc.collect()
        torch.cuda.empty_cache() 
#         best_f1=val_f1

             
        if val_f1>=best_f1:
#             best_f1_=val_f1
            stop_count = 0
        else:
            stop_count = stop_count + 1
                
           
    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val auc: {best_f1:4f}')
    wandb.finish()
    
    # load best model weights
#     model.load_state_dict(best_model_wts)
    return best_f1
68/11:
import optuna
# earlystoper = EarlyStopper(patience = 50)
study = optuna.create_study(direction='maximize',pruner=optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=7))
study.optimize(train_model,n_trials=300)
best_params = study.best_params
best_f1 = study.best_value
print ('best params: {best_params}')
print ('best f1: {best_f1}')
68/12: best_params
68/13: wandb.finish()
68/14: wandb.finish()
68/15: best_params
68/16: optuna.importance.get_param_importances(study)
   1: %history -g -f filename
