
  4%|███▍                                                                               | 2/49 [00:01<00:27,  1.69it/s]
Sequential(
  (0): DaVit(
    (stem): Stem(
      (conv): Conv2d(3, 128, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm2d((128,), eps=1e-05, elementwise_affine=True)
    )
    (stages): Sequential(
      (0): DaVitStage(
        (downsample): Identity()
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (act): Identity()
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): Identity()
              (cpe2): ConvPosEnc(
                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (act): Identity()
              )
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): Identity()
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (act): Identity()
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (drop_path1): Identity()
              (cpe2): ConvPosEnc(
                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (act): Identity()
              )
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): Identity()
            )
          )
        )
      )
      (1): DaVitStage(
        (downsample): Downsample(
          (norm): LayerNorm2d((128,), eps=1e-05, elementwise_affine=True)
          (conv): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
        )
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                (act): Identity()
              )
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.036)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                (act): Identity()
              )
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.036)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                (act): Identity()
              )
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.036)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                (act): Identity()
              )
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.036)
            )
          )
        )
      )
      (2): DaVitStage(
        (downsample): Downsample(
          (norm): LayerNorm2d((256,), eps=1e-05, elementwise_affine=True)
          (conv): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
        )
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.073)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.073)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.073)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.073)
            )
          )
          (1): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.109)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.109)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.109)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.109)
            )
          )
          (2): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.145)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.145)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.145)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.145)
            )
          )
          (3): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.182)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.182)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.182)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.182)
            )
          )
          (4): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.218)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.218)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.218)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.218)
            )
          )
          (5): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.255)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.255)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.255)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.255)
            )
          )
          (6): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.291)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.291)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.291)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.291)
            )
          )
          (7): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.327)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.327)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.327)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.327)
            )
          )
          (8): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.364)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.364)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.364)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.364)
            )
          )
        )
      )
      (3): DaVitStage(
        (downsample): Downsample(
          (norm): LayerNorm2d((512,), eps=1e-05, elementwise_affine=True)
          (conv): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
        )
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): Identity()
              )
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.400)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): Identity()
              )
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.400)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): Identity()
              )
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.400)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): Identity()
              )
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.400)
            )
          )
        )
      )
    )
    (norm_pre): Identity()
    (head): NormMlpClassifierHead(
      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())
      (norm): LayerNorm2d((1024,), eps=1e-05, elementwise_affine=True)
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (pre_logits): Identity()
      (drop): Dropout(p=0.0, inplace=False)
      (fc): Linear(in_features=1024, out_features=1, bias=True)
    )
  )
  (1): Sigmoid()
)
Starting training...
--------------------











 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:23<00:01,  2.04it/s]
New threshold is 0.4795832931995392
train F1 is 0.5413534045219421
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  1.98it/s]

 88%|███████████████████████████████████████████████████████████████████████▊          | 14/16 [00:02<00:00,  4.81it/s]
New threshold is 0.5139601230621338
val F1 is 0.5531914830207825
Epoch 1/28, learning rate: 3.992690592564548e-05
Train Loss: 0.6926, Train Acc: 0.5308, Train f1: 0.5414, Train Precision: 0.5159, Train Recall: 0.5694, Train AUC: 0.5319
Valitadion Loss: 0.6950, Validation Acc: 0.5928, Vall f1: 0.5532, Val Precision: 0.4892, Val Recall: 0.6364, Val AUC: 0.6164
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.49it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 45/49 [00:23<00:01,  2.04it/s]
New threshold is 0.4839264750480652
train F1 is 0.5554628968238831
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  1.97it/s]

 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [00:02<00:00,  5.36it/s]
New threshold is 0.4688812494277954
val F1 is 0.5838926434516907
Epoch 2/28, learning rate: 3.970815797696586e-05
Train Loss: 0.6918, Train Acc: 0.5444, Train f1: 0.5555, Train Precision: 0.5286, Train Recall: 0.5852, Train AUC: 0.5392
Valitadion Loss: 0.6675, Validation Acc: 0.6565, Vall f1: 0.5839, Val Precision: 0.5613, Val Recall: 0.6084, Val AUC: 0.6721
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.68it/s]












100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:25<00:00,  1.96it/s]
New threshold is 0.4792478084564209
train F1 is 0.5959183573722839
val for epoch 3
 62%|███████████████████████████████████████████████████▎                              | 10/16 [00:01<00:01,  5.51it/s]
New threshold is 0.49120819568634033
val F1 is 0.5814696550369263
Epoch 3/28, learning rate: 3.934535507188366e-05
Train Loss: 0.6852, Train Acc: 0.5769, Train f1: 0.5959, Train Precision: 0.5564, Train Recall: 0.6415, Train AUC: 0.5772
Valitadion Loss: 0.6566, Validation Acc: 0.6371, Vall f1: 0.5815, Val Precision: 0.5353, Val Recall: 0.6364, Val AUC: 0.6656
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.78it/s]











 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:23<00:01,  2.08it/s]
New threshold is 0.4825087785720825
train F1 is 0.5224274396896362
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  2.00it/s]

 81%|██████████████████████████████████████████████████████████████████▋               | 13/16 [00:02<00:00,  5.53it/s]
New threshold is 0.4683864712715149
val F1 is 0.5665528774261475
Epoch 4/28, learning rate: 3.884114908471721e-05
Train Loss: 0.6923, Train Acc: 0.5359, Train f1: 0.5224, Train Precision: 0.5229, Train Recall: 0.5220, Train AUC: 0.5450
Valitadion Loss: 0.6730, Validation Acc: 0.6482, Vall f1: 0.5666, Val Precision: 0.5533, Val Recall: 0.5804, Val AUC: 0.6641
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.77it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 45/49 [00:23<00:02,  1.96it/s]
New threshold is 0.49897077679634094
train F1 is 0.5584299564361572
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:25<00:00,  1.94it/s]

 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [00:02<00:00,  5.53it/s]
New threshold is 0.46267083287239075
val F1 is 0.6019417643547058
Epoch 5/28, learning rate: 3.819922546255023e-05
Train Loss: 0.6782, Train Acc: 0.5769, Train f1: 0.5584, Train Precision: 0.5670, Train Recall: 0.5501, Train AUC: 0.6017
Valitadion Loss: 0.6527, Validation Acc: 0.6593, Vall f1: 0.6019, Val Precision: 0.5602, Val Recall: 0.6503, Val AUC: 0.6934
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.77it/s]











 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:23<00:01,  2.07it/s]
New threshold is 0.47664034366607666
train F1 is 0.5965517163276672
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  2.01it/s]

 62%|███████████████████████████████████████████████████▎                              | 10/16 [00:02<00:01,  4.46it/s]
New threshold is 0.38469693064689636
val F1 is 0.6265060305595398
Epoch 6/28, learning rate: 3.742427628679688e-05
Train Loss: 0.6720, Train Acc: 0.6000, Train f1: 0.5966, Train Precision: 0.5854, Train Recall: 0.6081, Train AUC: 0.6182
Valitadion Loss: 0.6473, Validation Acc: 0.6565, Vall f1: 0.6265, Val Precision: 0.5503, Val Recall: 0.7273, Val AUC: 0.7103
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.87it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 45/49 [00:22<00:01,  2.06it/s]
New threshold is 0.4909556210041046
train F1 is 0.618086040019989
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  2.00it/s]

 69%|████████████████████████████████████████████████████████▍                         | 11/16 [00:02<00:00,  5.47it/s]
New threshold is 0.3457231819629669
val F1 is 0.5761589407920837
Epoch 7/28, learning rate: 3.652196597686613e-05
Train Loss: 0.6469, Train Acc: 0.6282, Train f1: 0.6181, Train Precision: 0.6175, Train Recall: 0.6186, Train AUC: 0.6732
Valitadion Loss: 0.6439, Validation Acc: 0.6454, Vall f1: 0.5762, Val Precision: 0.5472, Val Recall: 0.6084, Val AUC: 0.7042
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.73it/s]












100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:25<00:00,  1.94it/s]
New threshold is 0.48684170842170715
train F1 is 0.6310063600540161
val for epoch 8
 56%|██████████████████████████████████████████████▋                                    | 9/16 [00:01<00:01,  5.45it/s]
New threshold is 0.6067327260971069
val F1 is 0.6369863152503967
Epoch 8/28, learning rate: 3.549888988661135e-05
Train Loss: 0.6320, Train Acc: 0.6521, Train f1: 0.6310, Train Precision: 0.6517, Train Recall: 0.6116, Train AUC: 0.6970
Valitadion Loss: 0.6274, Validation Acc: 0.7064, Vall f1: 0.6370, Val Precision: 0.6242, Val Recall: 0.6503, Val AUC: 0.7570
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.72it/s]











100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  2.00it/s]
  0%|                                                                                           | 0/16 [00:00<?, ?it/s]
New threshold is 0.4452219307422638
train F1 is 0.6683587431907654

 62%|███████████████████████████████████████████████████▎                              | 10/16 [00:01<00:01,  4.82it/s]
New threshold is 0.36769911646842957
val F1 is 0.6476868391036987
Epoch 9/28, learning rate: 3.4362526096200635e-05
Train Loss: 0.6156, Train Acc: 0.6650, Train f1: 0.6684, Train Precision: 0.6444, Train Recall: 0.6942, Train AUC: 0.7189
Valitadion Loss: 0.6023, Validation Acc: 0.7258, Vall f1: 0.6477, Val Precision: 0.6594, Val Recall: 0.6364, Val AUC: 0.7767
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  5.11it/s]












 98%|████████████████████████████████████████████████████████████████████████████████▎ | 48/49 [00:24<00:00,  2.07it/s]
New threshold is 0.5057533383369446
train F1 is 0.6958139538764954
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  1.99it/s]
 56%|██████████████████████████████████████████████▋                                    | 9/16 [00:01<00:01,  5.52it/s]
New threshold is 0.4160788059234619
val F1 is 0.6222222447395325
Epoch 10/28, learning rate: 3.312118075178063e-05
Train Loss: 0.5705, Train Acc: 0.7205, Train f1: 0.6958, Train Precision: 0.7391, Train Recall: 0.6573, Train AUC: 0.7768
Valitadion Loss: 0.6333, Validation Acc: 0.6704, Vall f1: 0.6222, Val Precision: 0.5698, Val Recall: 0.6853, Val AUC: 0.7646
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.78it/s]












 98%|████████████████████████████████████████████████████████████████████████████████▎ | 48/49 [00:24<00:00,  1.69it/s]
New threshold is 0.4673861861228943
train F1 is 0.7285463809967041
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:25<00:00,  1.94it/s]
 44%|████████████████████████████████████▎                                              | 7/16 [00:01<00:01,  5.37it/s]
New threshold is 0.30004504323005676
val F1 is 0.6603174805641174
Epoch 11/28, learning rate: 3.1783927352468664e-05
Train Loss: 0.5485, Train Acc: 0.7350, Train f1: 0.7285, Train Precision: 0.7260, Train Recall: 0.7311, Train AUC: 0.7935
Valitadion Loss: 0.6291, Validation Acc: 0.7036, Vall f1: 0.6603, Val Precision: 0.6047, Val Recall: 0.7273, Val AUC: 0.7896
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.72it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 45/49 [00:22<00:01,  2.07it/s]
New threshold is 0.44827231764793396
train F1 is 0.7336244583129883
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:23<00:00,  2.05it/s]

 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [00:02<00:00,  5.40it/s]
New threshold is 0.32781854271888733
val F1 is 0.6709265112876892
Epoch 12/28, learning rate: 3.03605404284491e-05
Train Loss: 0.5441, Train Acc: 0.7393, Train f1: 0.7336, Train Precision: 0.7292, Train Recall: 0.7381, Train AUC: 0.7987
Valitadion Loss: 0.6133, Validation Acc: 0.7147, Vall f1: 0.6709, Val Precision: 0.6176, Val Recall: 0.7343, Val AUC: 0.7841
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.70it/s]











 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:23<00:01,  2.06it/s]
New threshold is 0.4455852806568146
train F1 is 0.7443946003913879
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  1.99it/s]

 88%|███████████████████████████████████████████████████████████████████████▊          | 14/16 [00:02<00:00,  5.46it/s]
New threshold is 0.3266356885433197
val F1 is 0.6584615111351013
Epoch 13/28, learning rate: 2.8861424094948e-05
Train Loss: 0.5160, Train Acc: 0.7564, Train f1: 0.7444, Train Precision: 0.7601, Train Recall: 0.7293, Train AUC: 0.8162
Valitadion Loss: 0.6515, Validation Acc: 0.6925, Vall f1: 0.6585, Val Precision: 0.5879, Val Recall: 0.7483, Val AUC: 0.7670
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.73it/s]











 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:23<00:01,  2.06it/s]
New threshold is 0.4615449905395508
train F1 is 0.7701754570007324
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  1.99it/s]

 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [00:02<00:00,  4.25it/s]
New threshold is 0.2537148594856262
val F1 is 0.6301369667053223
Epoch 14/28, learning rate: 2.7297536004314e-05
Train Loss: 0.4960, Train Acc: 0.7761, Train f1: 0.7702, Train Precision: 0.7688, Train Recall: 0.7715, Train AUC: 0.8387
Valitadion Loss: 0.6554, Validation Acc: 0.7008, Vall f1: 0.6301, Val Precision: 0.6174, Val Recall: 0.6434, Val AUC: 0.7790
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.60it/s]











 96%|██████████████████████████████████████████████████████████████████████████████▋   | 47/49 [00:23<00:00,  2.06it/s]
New threshold is 0.4575764536857605
train F1 is 0.7686832547187805
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:23<00:00,  2.05it/s]
 38%|███████████████████████████████▏                                                   | 6/16 [00:01<00:01,  5.39it/s]
New threshold is 0.3380378484725952
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.70it/s]
  0%|                                                                                           | 0/16 [00:00<?, ?it/s]
Epoch 15/28, learning rate: 2.5680307252070786e-05
Train Loss: 0.4737, Train Acc: 0.7778, Train f1: 0.7687, Train Precision: 0.7784, Train Recall: 0.7592, Train AUC: 0.8548
Valitadion Loss: 0.6088, Validation Acc: 0.7313, Vall f1: 0.6881, Val Precision: 0.6369, Val Recall: 0.7483, Val AUC: 0.8113
Training complete in 6m 60s
Best val auc: 0.811253


 69%|████████████████████████████████████████████████████████▍                         | 11/16 [00:03<00:01,  3.18it/s]
New threshold is 0.3380378484725952
Inference complete in 0m 5s
F1 Score = : 0.688103
AUC Score = : 0.811253

100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:05<00:00,  2.97it/s]