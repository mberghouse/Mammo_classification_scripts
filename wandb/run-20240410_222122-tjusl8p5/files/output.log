
  4%|███▍                                                                               | 2/49 [00:01<00:34,  1.35it/s]
Sequential(
  (0): DaVit(
    (stem): Stem(
      (conv): Conv2d(3, 128, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm2d((128,), eps=1e-05, elementwise_affine=True)
    )
    (stages): Sequential(
      (0): DaVitStage(
        (downsample): Identity()
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (act): Identity()
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): Identity()
              (cpe2): ConvPosEnc(
                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (act): Identity()
              )
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): Identity()
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (act): Identity()
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (drop_path1): Identity()
              (cpe2): ConvPosEnc(
                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (act): Identity()
              )
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): Identity()
            )
          )
        )
      )
      (1): DaVitStage(
        (downsample): Downsample(
          (norm): LayerNorm2d((128,), eps=1e-05, elementwise_affine=True)
          (conv): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
        )
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                (act): Identity()
              )
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.036)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                (act): Identity()
              )
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.036)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                (act): Identity()
              )
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.036)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                (act): Identity()
              )
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.036)
            )
          )
        )
      )
      (2): DaVitStage(
        (downsample): Downsample(
          (norm): LayerNorm2d((256,), eps=1e-05, elementwise_affine=True)
          (conv): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
        )
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.073)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.073)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.073)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.073)
            )
          )
          (1): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.109)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.109)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.109)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.109)
            )
          )
          (2): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.145)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.145)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.145)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.145)
            )
          )
          (3): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.182)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.182)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.182)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.182)
            )
          )
          (4): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.218)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.218)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.218)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.218)
            )
          )
          (5): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.255)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.255)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.255)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.255)
            )
          )
          (6): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.291)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.291)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.291)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.291)
            )
          )
          (7): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.327)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.327)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.327)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.327)
            )
          )
          (8): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.364)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.364)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.364)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.364)
            )
          )
        )
      )
      (3): DaVitStage(
        (downsample): Downsample(
          (norm): LayerNorm2d((512,), eps=1e-05, elementwise_affine=True)
          (conv): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
        )
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): Identity()
              )
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.400)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): Identity()
              )
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.400)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): Identity()
              )
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.400)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): Identity()
              )
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.400)
            )
          )
        )
      )
    )
    (norm_pre): Identity()
    (head): NormMlpClassifierHead(
      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())
      (norm): LayerNorm2d((1024,), eps=1e-05, elementwise_affine=True)
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (pre_logits): Identity()
      (drop): Dropout(p=0.0, inplace=False)
      (fc): Linear(in_features=1024, out_features=1, bias=True)
    )
  )
  (1): Sigmoid()
)
Starting training...
--------------------













 98%|████████████████████████████████████████████████████████████████████████████████▎ | 48/49 [00:27<00:00,  1.94it/s]
New threshold is 0.4853731393814087
train F1 is 0.5227078199386597
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:27<00:00,  1.77it/s]
 56%|██████████████████████████████████████████████▋                                    | 9/16 [00:01<00:01,  5.33it/s]
New threshold is 0.49964168667793274
val F1 is 0.4399999976158142
Epoch 1/28, learning rate: 3.992690592564548e-05
Train Loss: 0.6937, Train Acc: 0.5239, Train f1: 0.5227, Train Precision: 0.5066, Train Recall: 0.5398, Train AUC: 0.5209
Valitadion Loss: 0.6942, Validation Acc: 0.6122, Vall f1: 0.4400, Val Precision: 0.5140, Val Recall: 0.3846, Val AUC: 0.5501
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.61it/s]












 96%|██████████████████████████████████████████████████████████████████████████████▋   | 47/49 [00:24<00:00,  2.07it/s]
New threshold is 0.48577141761779785
train F1 is 0.5070671439170837
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:25<00:00,  1.95it/s]

100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.97it/s]
New threshold is 0.49102717638015747
val F1 is 0.5796178579330444
Epoch 2/28, learning rate: 3.970815797696586e-05
Train Loss: 0.6922, Train Acc: 0.5231, Train f1: 0.5071, Train Precision: 0.5062, Train Recall: 0.5080, Train AUC: 0.5267
Valitadion Loss: 0.6793, Validation Acc: 0.6343, Vall f1: 0.5796, Val Precision: 0.5322, Val Recall: 0.6364, Val AUC: 0.6669
train for epoch 3











 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:23<00:01,  2.08it/s]
New threshold is 0.4774309992790222
train F1 is 0.56154465675354
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  2.00it/s]
 31%|█████████████████████████▉                                                         | 5/16 [00:00<00:02,  5.48it/s]
New threshold is 0.45936593413352966

100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.73it/s]
Epoch 3/28, learning rate: 3.934535507188366e-05
Train Loss: 0.6896, Train Acc: 0.5342, Train f1: 0.5615, Train Precision: 0.5147, Train Recall: 0.6177, Train AUC: 0.5392
Valitadion Loss: 0.6616, Validation Acc: 0.6593, Vall f1: 0.5967, Val Precision: 0.5617, Val Recall: 0.6364, Val AUC: 0.6838
train for epoch 4













100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:27<00:00,  1.77it/s]
New threshold is 0.4778813123703003
train F1 is 0.5903083682060242
val for epoch 4
 50%|█████████████████████████████████████████▌                                         | 8/16 [00:01<00:01,  4.62it/s]
New threshold is 0.44346383213996887
val F1 is 0.6172839403152466
Epoch 4/28, learning rate: 3.884114908471721e-05
Train Loss: 0.6748, Train Acc: 0.6026, Train f1: 0.5903, Train Precision: 0.5877, Train Recall: 0.5929, Train AUC: 0.6135
Valitadion Loss: 0.6327, Validation Acc: 0.6565, Vall f1: 0.6173, Val Precision: 0.5525, Val Recall: 0.6993, Val AUC: 0.7179
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.88it/s]













 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:26<00:01,  1.84it/s]
New threshold is 0.5006880164146423
train F1 is 0.5946934819221497
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:27<00:00,  1.78it/s]

 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [00:02<00:00,  4.97it/s]
New threshold is 0.503746509552002
val F1 is 0.624535322189331
Epoch 5/28, learning rate: 3.819922546255023e-05
Train Loss: 0.6519, Train Acc: 0.6214, Train f1: 0.5947, Train Precision: 0.6155, Train Recall: 0.5752, Train AUC: 0.6601
Valitadion Loss: 0.6045, Validation Acc: 0.7202, Vall f1: 0.6245, Val Precision: 0.6667, Val Recall: 0.5874, Val AUC: 0.7594
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  5.26it/s]












 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:24<00:01,  1.84it/s]
New threshold is 0.47253161668777466
train F1 is 0.654578447341919
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:26<00:00,  1.87it/s]

 81%|██████████████████████████████████████████████████████████████████▋               | 13/16 [00:02<00:00,  5.10it/s]
New threshold is 0.34368059039115906
val F1 is 0.6298701167106628
Epoch 6/28, learning rate: 3.742427628679688e-05
Train Loss: 0.6241, Train Acc: 0.6744, Train f1: 0.6546, Train Precision: 0.6710, Train Recall: 0.6389, Train AUC: 0.7107
Valitadion Loss: 0.6260, Validation Acc: 0.6842, Vall f1: 0.6299, Val Precision: 0.5879, Val Recall: 0.6783, Val AUC: 0.7593
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.58it/s]











 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:23<00:01,  2.05it/s]
New threshold is 0.4132177531719208
train F1 is 0.6838487982749939
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  1.99it/s]

 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [00:02<00:00,  4.25it/s]
New threshold is 0.35016700625419617
val F1 is 0.6514657735824585
Epoch 7/28, learning rate: 3.652196597686613e-05
Train Loss: 0.5974, Train Acc: 0.6855, Train f1: 0.6838, Train Precision: 0.6644, Train Recall: 0.7044, Train AUC: 0.7401
Valitadion Loss: 0.6008, Validation Acc: 0.7036, Vall f1: 0.6515, Val Precision: 0.6098, Val Recall: 0.6993, Val AUC: 0.7762
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.84it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 45/49 [00:22<00:01,  2.07it/s]
New threshold is 0.4856482446193695
train F1 is 0.6855059266090393
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  2.00it/s]

 81%|██████████████████████████████████████████████████████████████████▋               | 13/16 [00:02<00:00,  5.48it/s]
New threshold is 0.42527246475219727
val F1 is 0.6405693888664246
Epoch 8/28, learning rate: 3.549888988661135e-05
Train Loss: 0.5820, Train Acc: 0.7051, Train f1: 0.6855, Train Precision: 0.7068, Train Recall: 0.6655, Train AUC: 0.7580
Valitadion Loss: 0.5691, Validation Acc: 0.7202, Vall f1: 0.6406, Val Precision: 0.6522, Val Recall: 0.6294, Val AUC: 0.7930
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.74it/s]












100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:25<00:00,  1.94it/s]
New threshold is 0.4578971862792969
train F1 is 0.6950998306274414
val for epoch 9
 62%|███████████████████████████████████████████████████▎                              | 10/16 [00:01<00:01,  5.42it/s]
New threshold is 0.3357730209827423
val F1 is 0.6270626783370972
Epoch 9/28, learning rate: 3.4362526096200635e-05
Train Loss: 0.5548, Train Acc: 0.7128, Train f1: 0.6951, Train Precision: 0.7132, Train Recall: 0.6779, Train AUC: 0.7828
Valitadion Loss: 0.6317, Validation Acc: 0.6870, Vall f1: 0.6271, Val Precision: 0.5938, Val Recall: 0.6643, Val AUC: 0.7531
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.71it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 45/49 [00:22<00:01,  2.05it/s]
New threshold is 0.4391672909259796
train F1 is 0.7204206585884094
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  1.99it/s]

 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [00:02<00:00,  5.42it/s]
New threshold is 0.3456447720527649
val F1 is 0.6711409687995911
Epoch 10/28, learning rate: 3.312118075178063e-05
Train Loss: 0.5429, Train Acc: 0.7274, Train f1: 0.7204, Train Precision: 0.7135, Train Recall: 0.7274, Train AUC: 0.7991
Valitadion Loss: 0.6245, Validation Acc: 0.7285, Vall f1: 0.6711, Val Precision: 0.6452, Val Recall: 0.6993, Val AUC: 0.7860
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.49it/s]











100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:25<00:00,  1.96it/s]
  0%|                                                                                           | 0/16 [00:00<?, ?it/s]
New threshold is 0.4894718527793884
train F1 is 0.7448405027389526

 62%|███████████████████████████████████████████████████▎                              | 10/16 [00:01<00:01,  5.31it/s]
New threshold is 0.5327642560005188
val F1 is 0.6408450603485107
Epoch 11/28, learning rate: 3.1783927352468664e-05
Train Loss: 0.5041, Train Acc: 0.7675, Train f1: 0.7448, Train Precision: 0.7924, Train Recall: 0.7027, Train AUC: 0.8304
Valitadion Loss: 0.6503, Validation Acc: 0.7175, Vall f1: 0.6408, Val Precision: 0.6454, Val Recall: 0.6364, Val AUC: 0.7875
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.60it/s]











 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:22<00:01,  2.05it/s]
New threshold is 0.43159857392311096
train F1 is 0.7424110770225525
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  2.01it/s]

 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [00:02<00:00,  5.31it/s]
New threshold is 0.19246581196784973
val F1 is 0.6601941585540771
Epoch 12/28, learning rate: 3.03605404284491e-05
Train Loss: 0.5143, Train Acc: 0.7462, Train f1: 0.7424, Train Precision: 0.7279, Train Recall: 0.7575, Train AUC: 0.8218
Valitadion Loss: 0.7145, Validation Acc: 0.7091, Vall f1: 0.6602, Val Precision: 0.6145, Val Recall: 0.7133, Val AUC: 0.7687
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  5.30it/s]











 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:23<00:01,  2.04it/s]
New threshold is 0.4247383177280426
train F1 is 0.7415929436683655
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  1.98it/s]

 81%|██████████████████████████████████████████████████████████████████▋               | 13/16 [00:02<00:00,  5.38it/s]
New threshold is 0.3542393743991852
val F1 is 0.6784660816192627
Epoch 13/28, learning rate: 2.8861424094948e-05
Train Loss: 0.4923, Train Acc: 0.7504, Train f1: 0.7416, Train Precision: 0.7416, Train Recall: 0.7416, Train AUC: 0.8349
Valitadion Loss: 0.6605, Validation Acc: 0.6981, Vall f1: 0.6785, Val Precision: 0.5867, Val Recall: 0.8042, Val AUC: 0.7972
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.61it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 45/49 [00:22<00:02,  1.87it/s]
New threshold is 0.49326810240745544
train F1 is 0.7851162552833557
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  1.98it/s]

 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [00:02<00:00,  5.36it/s]
New threshold is 0.51820969581604
val F1 is 0.6597222089767456
Epoch 14/28, learning rate: 2.7297536004314e-05
Train Loss: 0.4517, Train Acc: 0.8026, Train f1: 0.7851, Train Precision: 0.8275, Train Recall: 0.7469, Train AUC: 0.8671
Valitadion Loss: 0.6585, Validation Acc: 0.7285, Vall f1: 0.6597, Val Precision: 0.6552, Val Recall: 0.6643, Val AUC: 0.7997
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.60it/s]











 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:22<00:01,  2.04it/s]
New threshold is 0.4197641611099243
train F1 is 0.8024582862854004
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  2.03it/s]

 81%|██████████████████████████████████████████████████████████████████▋               | 13/16 [00:02<00:00,  4.26it/s]
New threshold is 0.3852989375591278
val F1 is 0.6688524484634399
Epoch 15/28, learning rate: 2.5680307252070786e-05
Train Loss: 0.4454, Train Acc: 0.8077, Train f1: 0.8025, Train Precision: 0.7962, Train Recall: 0.8088, Train AUC: 0.8723
Valitadion Loss: 0.6377, Validation Acc: 0.7202, Vall f1: 0.6689, Val Precision: 0.6296, Val Recall: 0.7133, Val AUC: 0.8014
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.73it/s]











 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:22<00:01,  2.04it/s]
New threshold is 0.4682654142379761
train F1 is 0.7874439358711243
100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:24<00:00,  2.03it/s]

 88%|███████████████████████████████████████████████████████████████████████▊          | 14/16 [00:02<00:00,  5.31it/s]
New threshold is 0.27060750126838684
val F1 is 0.6840391159057617
Epoch 16/28, learning rate: 2.4021558822380333e-05
Train Loss: 0.4437, Train Acc: 0.7974, Train f1: 0.7874, Train Precision: 0.7982, Train Recall: 0.7770, Train AUC: 0.8731
Valitadion Loss: 0.6282, Validation Acc: 0.7313, Vall f1: 0.6840, Val Precision: 0.6402, Val Recall: 0.7343, Val AUC: 0.8119
Training complete in 7m 40s
Best val auc: 0.811862
100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.59it/s]


100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:05<00:00,  2.97it/s]
New threshold is 0.27060750126838684
Inference complete in 0m 5s
F1 Score = : 0.684039
AUC Score = : 0.811862
Acc Score = : 0.731302