
  4%|███▎                                                                               | 3/74 [00:01<00:29,  2.43it/s]
Sequential(
  (0): DaVit(
    (stem): Stem(
      (conv): Conv2d(3, 128, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm2d((128,), eps=1e-05, elementwise_affine=True)
    )
    (stages): Sequential(
      (0): DaVitStage(
        (downsample): Identity()
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (act): Identity()
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): Identity()
              (cpe2): ConvPosEnc(
                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (act): Identity()
              )
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): Identity()
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (act): Identity()
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (drop_path1): Identity()
              (cpe2): ConvPosEnc(
                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (act): Identity()
              )
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): Identity()
            )
          )
        )
      )
      (1): DaVitStage(
        (downsample): Downsample(
          (norm): LayerNorm2d((128,), eps=1e-05, elementwise_affine=True)
          (conv): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
        )
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                (act): Identity()
              )
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.036)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                (act): Identity()
              )
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.036)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                (act): Identity()
              )
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.036)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
                (act): Identity()
              )
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=256, out_features=1024, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1024, out_features=256, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.036)
            )
          )
        )
      )
      (2): DaVitStage(
        (downsample): Downsample(
          (norm): LayerNorm2d((256,), eps=1e-05, elementwise_affine=True)
          (conv): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
        )
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.073)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.073)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.073)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.073)
            )
          )
          (1): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.109)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.109)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.109)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.109)
            )
          )
          (2): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.145)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.145)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.145)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.145)
            )
          )
          (3): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.182)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.182)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.182)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.182)
            )
          )
          (4): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.218)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.218)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.218)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.218)
            )
          )
          (5): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.255)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.255)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.255)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.255)
            )
          )
          (6): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.291)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.291)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.291)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.291)
            )
          )
          (7): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.327)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.327)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.327)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.327)
            )
          )
          (8): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.364)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.364)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (proj): Linear(in_features=512, out_features=512, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.364)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): Identity()
              )
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=512, out_features=2048, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=2048, out_features=512, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.364)
            )
          )
        )
      )
      (3): DaVitStage(
        (downsample): Downsample(
          (norm): LayerNorm2d((512,), eps=1e-05, elementwise_affine=True)
          (conv): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
        )
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): Identity()
              )
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.400)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): Identity()
              )
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.400)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): Identity()
              )
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.400)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): Identity()
              )
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.400)
            )
          )
        )
      )
    )
    (norm_pre): Identity()
    (head): NormMlpClassifierHead(
      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())
      (norm): LayerNorm2d((1024,), eps=1e-05, elementwise_affine=True)
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (pre_logits): Identity()
      (drop): Dropout(p=0.0, inplace=False)
      (fc): Linear(in_features=1024, out_features=1, bias=True)
    )
  )
  (1): Sigmoid()
)
Starting training...
--------------------












 97%|███████████████████████████████████████████████████████████████████████████████▊  | 72/74 [00:25<00:00,  2.85it/s]
New threshold is 0.486438125371933
train F1 is 0.5026177763938904
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:25<00:00,  2.86it/s]
 48%|███████████████████████████████████████▏                                          | 11/23 [00:01<00:01,  7.65it/s]
New threshold is 0.5785166621208191
val F1 is 0.46822741627693176
Epoch 1/40, learning rate: 3.983342325182623e-05
Train Loss: 0.6964, Train Acc: 0.5128, Train f1: 0.5026, Train Precision: 0.4966, Train Recall: 0.5088, Train AUC: 0.5093
Valitadion Loss: 0.7272, Validation Acc: 0.5596, Vall f1: 0.4682, Val Precision: 0.4487, Val Recall: 0.4895, Val AUC: 0.5486
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  7.72it/s]













100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:26<00:00,  2.83it/s]
New threshold is 0.48688387870788574
train F1 is 0.5219730734825134
val for epoch 2
 61%|█████████████████████████████████████████████████▉                                | 14/23 [00:01<00:01,  7.58it/s]
New threshold is 0.4933195114135742
val F1 is 0.5830721259117126
Epoch 2/40, learning rate: 3.93364677886775e-05
Train Loss: 0.6898, Train Acc: 0.5444, Train f1: 0.5220, Train Precision: 0.5301, Train Recall: 0.5141, Train AUC: 0.5460
Valitadion Loss: 0.6741, Validation Acc: 0.6316, Vall f1: 0.5831, Val Precision: 0.5284, Val Recall: 0.6503, Val AUC: 0.6521
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  7.62it/s]












 93%|████████████████████████████████████████████████████████████████████████████▍     | 69/74 [00:24<00:02,  2.50it/s]
New threshold is 0.46925947070121765
train F1 is 0.5925925970077515
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:25<00:00,  2.88it/s]

 91%|██████████████████████████████████████████████████████████████████████████▊       | 21/23 [00:02<00:00,  8.40it/s]
New threshold is 0.49592119455337524
val F1 is 0.5394737124443054
Epoch 3/40, learning rate: 3.8517411733264606e-05
Train Loss: 0.6810, Train Acc: 0.5675, Train f1: 0.5926, Train Precision: 0.5444, Train Recall: 0.6502, Train AUC: 0.5937
Valitadion Loss: 0.6747, Validation Acc: 0.6122, Vall f1: 0.5395, Val Precision: 0.5093, Val Recall: 0.5734, Val AUC: 0.6141
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.37it/s]











100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.11it/s]
New threshold is 0.49251529574394226
train F1 is 0.5621716380119324
val for epoch 4
 65%|█████████████████████████████████████████████████████▍                            | 15/23 [00:01<00:00,  8.35it/s]
New threshold is 0.367942750453949
val F1 is 0.534246563911438
Epoch 4/40, learning rate: 3.738989865535692e-05
Train Loss: 0.6801, Train Acc: 0.5726, Train f1: 0.5622, Train Precision: 0.5573, Train Recall: 0.5671, Train AUC: 0.6002
Valitadion Loss: 0.6569, Validation Acc: 0.6233, Vall f1: 0.5342, Val Precision: 0.5235, Val Recall: 0.5455, Val AUC: 0.6289
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.36it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 68/74 [00:22<00:01,  3.10it/s]
New threshold is 0.48437052965164185
train F1 is 0.5671641826629639
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:24<00:00,  3.03it/s]

 87%|███████████████████████████████████████████████████████████████████████▎          | 20/23 [00:02<00:00,  8.37it/s]
New threshold is 0.4177018702030182
val F1 is 0.6098360419273376
Epoch 5/40, learning rate: 3.59727103016281e-05
Train Loss: 0.6780, Train Acc: 0.5786, Train f1: 0.5672, Train Precision: 0.5637, Train Recall: 0.5707, Train AUC: 0.5999
Valitadion Loss: 0.6252, Validation Acc: 0.6704, Vall f1: 0.6098, Val Precision: 0.5741, Val Recall: 0.6503, Val AUC: 0.7017
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.38it/s]











 96%|██████████████████████████████████████████████████████████████████████████████▋   | 71/74 [00:23<00:00,  3.19it/s]
New threshold is 0.48175594210624695
train F1 is 0.6019590497016907
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.11it/s]

100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  7.00it/s]
New threshold is 0.3060474991798401
val F1 is 0.5639344453811646
Epoch 6/40, learning rate: 3.428945373541973e-05
Train Loss: 0.6602, Train Acc: 0.6179, Train f1: 0.6020, Train Precision: 0.6068, Train Recall: 0.5972, Train AUC: 0.6407
Valitadion Loss: 0.6475, Validation Acc: 0.6316, Vall f1: 0.5639, Val Precision: 0.5309, Val Recall: 0.6014, Val AUC: 0.6697
train for epoch 7











100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.10it/s]
New threshold is 0.44134828448295593
train F1 is 0.6404886841773987
val for epoch 7
 65%|█████████████████████████████████████████████████████▍                            | 15/23 [00:01<00:00,  8.29it/s]
New threshold is 0.47831445932388306
val F1 is 0.5969230532646179
Epoch 7/40, learning rate: 3.236816809794689e-05
Train Loss: 0.6232, Train Acc: 0.6479, Train f1: 0.6405, Train Precision: 0.6328, Train Recall: 0.6484, Train AUC: 0.7042
Valitadion Loss: 0.6262, Validation Acc: 0.6371, Vall f1: 0.5969, Val Precision: 0.5330, Val Recall: 0.6783, Val AUC: 0.7223
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.35it/s]











 93%|████████████████████████████████████████████████████████████████████████████▍     | 69/74 [00:22<00:01,  2.79it/s]
New threshold is 0.45816415548324585
train F1 is 0.6924460530281067
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:24<00:00,  3.03it/s]

 78%|████████████████████████████████████████████████████████████████▏                 | 18/23 [00:02<00:00,  8.30it/s]
New threshold is 0.6060446500778198
val F1 is 0.6293706297874451
Epoch 8/40, learning rate: 3.0240857541389998e-05
Train Loss: 0.5786, Train Acc: 0.7077, Train f1: 0.6924, Train Precision: 0.7051, Train Recall: 0.6802, Train AUC: 0.7534
Valitadion Loss: 0.6303, Validation Acc: 0.7064, Vall f1: 0.6294, Val Precision: 0.6294, Val Recall: 0.6294, Val AUC: 0.7469
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.08it/s]











 95%|█████████████████████████████████████████████████████████████████████████████▌    | 70/74 [00:22<00:01,  3.21it/s]
New threshold is 0.42068395018577576
train F1 is 0.682414710521698
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.10it/s]
 35%|████████████████████████████▊                                                      | 8/23 [00:01<00:01,  8.15it/s]
New threshold is 0.37816521525382996

100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.29it/s]
Epoch 9/40, learning rate: 2.794295811412167e-05
Train Loss: 0.5815, Train Acc: 0.6897, Train f1: 0.6824, Train Precision: 0.6759, Train Recall: 0.6890, Train AUC: 0.7603
Valitadion Loss: 0.5766, Validation Acc: 0.6898, Vall f1: 0.6291, Val Precision: 0.5975, Val Recall: 0.6643, Val AUC: 0.7469
train for epoch 10











 96%|██████████████████████████████████████████████████████████████████████████████▋   | 71/74 [00:23<00:00,  3.09it/s]
New threshold is 0.4676983058452606
train F1 is 0.70705246925354
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:24<00:00,  3.03it/s]
 48%|███████████████████████████████████████▏                                          | 11/23 [00:01<00:01,  8.27it/s]
New threshold is 0.3685224950313568
val F1 is 0.6550522446632385
Epoch 10/40, learning rate: 2.551274747852131e-05
Train Loss: 0.5528, Train Acc: 0.7231, Train f1: 0.7071, Train Precision: 0.7241, Train Recall: 0.6908, Train AUC: 0.7844
Valitadion Loss: 0.5467, Validation Acc: 0.7258, Vall f1: 0.6551, Val Precision: 0.6528, Val Recall: 0.6573, Val AUC: 0.7708
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.37it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 68/74 [00:22<00:01,  3.19it/s]
New threshold is 0.47048357129096985
train F1 is 0.7269406318664551
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.10it/s]

 74%|████████████████████████████████████████████████████████████▌                     | 17/23 [00:02<00:00,  6.93it/s]
New threshold is 0.41422557830810547
val F1 is 0.6464646458625793
Epoch 11/40, learning rate: 2.299070729410652e-05
Train Loss: 0.5376, Train Acc: 0.7444, Train f1: 0.7269, Train Precision: 0.7524, Train Recall: 0.7032, Train AUC: 0.8060
Valitadion Loss: 0.5643, Validation Acc: 0.7091, Vall f1: 0.6465, Val Precision: 0.6234, Val Recall: 0.6713, Val AUC: 0.7684
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  7.40it/s]











 96%|██████████████████████████████████████████████████████████████████████████████▋   | 71/74 [00:22<00:00,  3.20it/s]
New threshold is 0.46795618534088135
train F1 is 0.73247230052948
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.15it/s]
 48%|███████████████████████████████████████▏                                          | 11/23 [00:01<00:01,  8.20it/s]
New threshold is 0.38898709416389465
val F1 is 0.6690647602081299
Epoch 12/40, learning rate: 2.041884888719593e-05
Train Loss: 0.5162, Train Acc: 0.7521, Train f1: 0.7325, Train Precision: 0.7664, Train Recall: 0.7014, Train AUC: 0.8147
Valitadion Loss: 0.5365, Validation Acc: 0.7452, Vall f1: 0.6691, Val Precision: 0.6889, Val Recall: 0.6503, Val AUC: 0.7876
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.28it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 68/74 [00:22<00:01,  3.19it/s]
New threshold is 0.46412160992622375
train F1 is 0.7430683970451355
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.10it/s]

 78%|████████████████████████████████████████████████████████████████▏                 | 18/23 [00:02<00:00,  8.35it/s]
New threshold is 0.42410874366760254
val F1 is 0.6825938820838928
Epoch 13/40, learning rate: 1.7840013439879223e-05
Train Loss: 0.5090, Train Acc: 0.7624, Train f1: 0.7431, Train Precision: 0.7791, Train Recall: 0.7102, Train AUC: 0.8252
Valitadion Loss: 0.5247, Validation Acc: 0.7424, Vall f1: 0.6826, Val Precision: 0.6667, Val Recall: 0.6993, Val AUC: 0.8029
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.29it/s]











 96%|██████████████████████████████████████████████████████████████████████████████▋   | 71/74 [00:23<00:00,  3.21it/s]
New threshold is 0.5083496570587158
train F1 is 0.7514018416404724
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.11it/s]
 43%|███████████████████████████████████▋                                              | 10/23 [00:01<00:01,  8.24it/s]
New threshold is 0.4350668787956238
val F1 is 0.6715328693389893
Epoch 14/40, learning rate: 1.529715835551926e-05
Train Loss: 0.4765, Train Acc: 0.7726, Train f1: 0.7514, Train Precision: 0.7976, Train Recall: 0.7102, Train AUC: 0.8486
Valitadion Loss: 0.5421, Validation Acc: 0.7507, Vall f1: 0.6715, Val Precision: 0.7023, Val Recall: 0.6434, Val AUC: 0.7980
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.39it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 68/74 [00:22<00:01,  3.20it/s]
New threshold is 0.41456079483032227
train F1 is 0.7805309891700745
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.10it/s]

 83%|███████████████████████████████████████████████████████████████████▋              | 19/23 [00:02<00:00,  8.19it/s]
New threshold is 0.426751047372818
val F1 is 0.6666666865348816
Epoch 15/40, learning rate: 1.2832641688277968e-05
Train Loss: 0.4611, Train Acc: 0.7880, Train f1: 0.7805, Train Precision: 0.7819, Train Recall: 0.7792, Train AUC: 0.8551
Valitadion Loss: 0.5725, Validation Acc: 0.7285, Vall f1: 0.6667, Val Precision: 0.6490, Val Recall: 0.6853, Val AUC: 0.7906
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.29it/s]











 97%|███████████████████████████████████████████████████████████████████████████████▊  | 72/74 [00:23<00:00,  3.17it/s]
New threshold is 0.44847533106803894
train F1 is 0.7761732935905457
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.10it/s]
 52%|██████████████████████████████████████████▊                                       | 12/23 [00:01<00:01,  8.31it/s]
New threshold is 0.5933828353881836
val F1 is 0.6810035705566406
Epoch 16/40, learning rate: 1.0487516556406596e-05
Train Loss: 0.4558, Train Acc: 0.7880, Train f1: 0.7762, Train Precision: 0.7934, Train Recall: 0.7597, Train AUC: 0.8562
Valitadion Loss: 0.5640, Validation Acc: 0.7535, Vall f1: 0.6810, Val Precision: 0.6985, Val Recall: 0.6643, Val AUC: 0.8088
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.38it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 68/74 [00:22<00:02,  2.92it/s]
New threshold is 0.463987797498703
train F1 is 0.7790802717208862
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.10it/s]

 83%|███████████████████████████████████████████████████████████████████▋              | 19/23 [00:02<00:00,  8.32it/s]
New threshold is 0.49188196659088135
val F1 is 0.6877192854881287
Epoch 17/40, learning rate: 8.300847292734526e-06
Train Loss: 0.4460, Train Acc: 0.7906, Train f1: 0.7791, Train Precision: 0.7956, Train Recall: 0.7633, Train AUC: 0.8688
Valitadion Loss: 0.5422, Validation Acc: 0.7535, Vall f1: 0.6877, Val Precision: 0.6901, Val Recall: 0.6853, Val AUC: 0.8076
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.35it/s]










100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.19it/s]
  4%|███▌                                                                               | 1/23 [00:00<00:03,  6.50it/s]
New threshold is 0.45783495903015137
train F1 is 0.8029196858406067

 74%|████████████████████████████████████████████████████████████▌                     | 17/23 [00:02<00:00,  8.12it/s]
New threshold is 0.41988667845726013
val F1 is 0.6734007000923157
Epoch 18/40, learning rate: 6.309058723699785e-06
Train Loss: 0.4324, Train Acc: 0.8154, Train f1: 0.8029, Train Precision: 0.8302, Train Recall: 0.7774, Train AUC: 0.8743
Valitadion Loss: 0.5488, Validation Acc: 0.7313, Vall f1: 0.6734, Val Precision: 0.6494, Val Recall: 0.6993, Val AUC: 0.8049
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  7.90it/s]











 93%|████████████████████████████████████████████████████████████████████████████▍     | 69/74 [00:23<00:01,  3.18it/s]
New threshold is 0.43225836753845215
train F1 is 0.7853309512138367
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:24<00:00,  3.04it/s]

 96%|██████████████████████████████████████████████████████████████████████████████▍   | 22/23 [00:02<00:00,  8.29it/s]
New threshold is 0.47709181904792786
val F1 is 0.6783216595649719
Epoch 19/40, learning rate: 4.545329416419773e-06
Train Loss: 0.4469, Train Acc: 0.7949, Train f1: 0.7853, Train Precision: 0.7953, Train Recall: 0.7756, Train AUC: 0.8681
Valitadion Loss: 0.5418, Validation Acc: 0.7452, Vall f1: 0.6783, Val Precision: 0.6783, Val Recall: 0.6783, Val AUC: 0.8089
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.26it/s]










100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.18it/s]
  0%|                                                                                           | 0/23 [00:00<?, ?it/s]
New threshold is 0.4826296865940094
train F1 is 0.8014705777168274

 57%|██████████████████████████████████████████████▎                                   | 13/23 [00:02<00:01,  6.53it/s]
New threshold is 0.4561120867729187
val F1 is 0.6736111044883728
Epoch 20/40, learning rate: 3.0390390008955333e-06
Train Loss: 0.4177, Train Acc: 0.8154, Train f1: 0.8015, Train Precision: 0.8352, Train Recall: 0.7703, Train AUC: 0.8855
Valitadion Loss: 0.5393, Validation Acc: 0.7396, Vall f1: 0.6736, Val Precision: 0.6690, Val Recall: 0.6783, Val AUC: 0.8111
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  6.80it/s]











 95%|█████████████████████████████████████████████████████████████████████████████▌    | 70/74 [00:22<00:01,  3.17it/s]
New threshold is 0.4122422933578491
train F1 is 0.800000011920929
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.18it/s]

100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.25it/s]
New threshold is 0.4801395833492279
val F1 is 0.6755852699279785
Epoch 21/40, learning rate: 1.8152787736766885e-06
Train Loss: 0.4326, Train Acc: 0.8085, Train f1: 0.8000, Train Precision: 0.8087, Train Recall: 0.7915, Train AUC: 0.8870
Valitadion Loss: 0.5505, Validation Acc: 0.7313, Vall f1: 0.6756, Val Precision: 0.6474, Val Recall: 0.7063, Val AUC: 0.8130
train for epoch 22











 96%|██████████████████████████████████████████████████████████████████████████████▋   | 71/74 [00:23<00:00,  3.15it/s]
New threshold is 0.5116133689880371
train F1 is 0.8011049628257751
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.10it/s]
 43%|███████████████████████████████████▋                                              | 10/23 [00:01<00:01,  8.20it/s]
New threshold is 0.4708366394042969
val F1 is 0.6783216595649719
Epoch 22/40, learning rate: 8.944337351923086e-07
Train Loss: 0.4287, Train Acc: 0.8154, Train f1: 0.8011, Train Precision: 0.8365, Train Recall: 0.7686, Train AUC: 0.8833
Valitadion Loss: 0.5416, Validation Acc: 0.7452, Vall f1: 0.6783, Val Precision: 0.6783, Val Recall: 0.6783, Val AUC: 0.8126
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.24it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 68/74 [00:22<00:01,  3.18it/s]
New threshold is 0.4849228262901306
train F1 is 0.7788898944854736
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.09it/s]

 78%|████████████████████████████████████████████████████████████████▏                 | 18/23 [00:02<00:00,  8.35it/s]
New threshold is 0.48066484928131104
val F1 is 0.6782007217407227
Epoch 23/40, learning rate: 2.918430230341475e-07
Train Loss: 0.4339, Train Acc: 0.7923, Train f1: 0.7789, Train Precision: 0.8030, Train Recall: 0.7562, Train AUC: 0.8811
Valitadion Loss: 0.5450, Validation Acc: 0.7424, Vall f1: 0.6782, Val Precision: 0.6712, Val Recall: 0.6853, Val AUC: 0.8134
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.23it/s]











 95%|█████████████████████████████████████████████████████████████████████████████▌    | 70/74 [00:23<00:01,  3.17it/s]
New threshold is 0.4197026193141937
train F1 is 0.7935943007469177
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:24<00:00,  3.08it/s]
 35%|████████████████████████████▊                                                      | 8/23 [00:01<00:01,  8.23it/s]
New threshold is 0.4952683746814728
val F1 is 0.6783216595649719
Epoch 24/40, learning rate: 1.7544397584247387e-08
Train Loss: 0.4227, Train Acc: 0.8017, Train f1: 0.7936, Train Precision: 0.7993, Train Recall: 0.7880, Train AUC: 0.8861
Valitadion Loss: 0.5449, Validation Acc: 0.7452, Vall f1: 0.6783, Val Precision: 0.6783, Val Recall: 0.6783, Val AUC: 0.8138

100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.27it/s]











 99%|████████████████████████████████████████████████████████████████████████████████▉ | 73/74 [00:23<00:00,  3.18it/s]
New threshold is 0.4580036401748657
train F1 is 0.7971014380455017
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.09it/s]
 61%|█████████████████████████████████████████████████▉                                | 14/23 [00:01<00:01,  8.21it/s]
New threshold is 0.5399401187896729
val F1 is 0.6738350987434387
Epoch 25/40, learning rate: 3.998096443211305e-05
Train Loss: 0.4437, Train Acc: 0.8085, Train f1: 0.7971, Train Precision: 0.8178, Train Recall: 0.7774, Train AUC: 0.8714
Valitadion Loss: 0.5668, Validation Acc: 0.7479, Vall f1: 0.6738, Val Precision: 0.6912, Val Recall: 0.6573, Val AUC: 0.7890
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.16it/s]











 95%|█████████████████████████████████████████████████████████████████████████████▌    | 70/74 [00:22<00:01,  3.16it/s]
New threshold is 0.48694485425949097
train F1 is 0.7732341885566711
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.10it/s]
 26%|█████████████████████▋                                                             | 6/23 [00:00<00:02,  8.20it/s]
New threshold is 0.3193497955799103
val F1 is 0.6920635104179382
Epoch 26/40, learning rate: 3.988301928237083e-05
Train Loss: 0.4479, Train Acc: 0.7915, Train f1: 0.7732, Train Precision: 0.8157, Train Recall: 0.7350, Train AUC: 0.8643
Valitadion Loss: 0.5415, Validation Acc: 0.7313, Vall f1: 0.6921, Val Precision: 0.6337, Val Recall: 0.7622, Val AUC: 0.8080

100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.32it/s]










 91%|██████████████████████████████████████████████████████████████████████████▏       | 67/74 [00:21<00:02,  3.19it/s]
New threshold is 0.46191707253456116
train F1 is 0.7803992629051208

100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.10it/s]
 65%|█████████████████████████████████████████████████████▍                            | 15/23 [00:01<00:00,  8.15it/s]
New threshold is 0.7786775231361389
val F1 is 0.6875
Epoch 27/40, learning rate: 3.970218653054082e-05
Train Loss: 0.4548, Train Acc: 0.7932, Train f1: 0.7804, Train Precision: 0.8022, Train Recall: 0.7597, Train AUC: 0.8656
Valitadion Loss: 0.7239, Validation Acc: 0.7507, Vall f1: 0.6875, Val Precision: 0.6828, Val Recall: 0.6923, Val AUC: 0.8040
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.21it/s]











 95%|█████████████████████████████████████████████████████████████████████████████▌    | 70/74 [00:22<00:01,  3.18it/s]
New threshold is 0.45541778206825256
train F1 is 0.779691755771637
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.09it/s]
 30%|█████████████████████████▎                                                         | 7/23 [00:00<00:01,  8.08it/s]
New threshold is 0.6429843902587891
val F1 is 0.6736111044883728
Epoch 28/40, learning rate: 3.943922002559043e-05
Train Loss: 0.4812, Train Acc: 0.7923, Train f1: 0.7797, Train Precision: 0.8007, Train Recall: 0.7597, Train AUC: 0.8453
Valitadion Loss: 0.6241, Validation Acc: 0.7396, Vall f1: 0.6736, Val Precision: 0.6690, Val Recall: 0.6783, Val AUC: 0.8000
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.15it/s]











 93%|████████████████████████████████████████████████████████████████████████████▍     | 69/74 [00:21<00:01,  3.14it/s]
New threshold is 0.4358712434768677
train F1 is 0.7913669347763062
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.13it/s]

 70%|█████████████████████████████████████████████████████████                         | 16/23 [00:02<00:00,  8.21it/s]
New threshold is 0.3982265889644623
val F1 is 0.6689655184745789
Epoch 29/40, learning rate: 3.909521601267555e-05
Train Loss: 0.4295, Train Acc: 0.8017, Train f1: 0.7914, Train Precision: 0.8059, Train Recall: 0.7774, Train AUC: 0.8827
Valitadion Loss: 0.5644, Validation Acc: 0.7341, Vall f1: 0.6690, Val Precision: 0.6599, Val Recall: 0.6783, Val AUC: 0.7879
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  7.63it/s]










 91%|██████████████████████████████████████████████████████████████████████████▏       | 67/74 [00:21<00:02,  3.20it/s]
New threshold is 0.41380277276039124
train F1 is 0.8247787356376648

100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.20it/s]
 65%|█████████████████████████████████████████████████████▍                            | 15/23 [00:01<00:00,  8.11it/s]
New threshold is 0.13686645030975342
val F1 is 0.6950819492340088
Epoch 30/40, learning rate: 3.8671608563153825e-05
Train Loss: 0.3866, Train Acc: 0.8308, Train f1: 0.8248, Train Precision: 0.8262, Train Recall: 0.8233, Train AUC: 0.9032
Valitadion Loss: 0.6128, Validation Acc: 0.7424, Vall f1: 0.6951, Val Precision: 0.6543, Val Recall: 0.7413, Val AUC: 0.7995
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.16it/s]











 92%|███████████████████████████████████████████████████████████████████████████▎      | 68/74 [00:22<00:02,  2.52it/s]
New threshold is 0.4462965130805969
train F1 is 0.8050541281700134
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:24<00:00,  3.01it/s]

 78%|████████████████████████████████████████████████████████████████▏                 | 18/23 [00:02<00:00,  8.17it/s]
New threshold is 0.3986848294734955
val F1 is 0.6644295454025269
Epoch 31/40, learning rate: 3.817016359628035e-05
Train Loss: 0.4060, Train Acc: 0.8154, Train f1: 0.8051, Train Precision: 0.8229, Train Recall: 0.7880, Train AUC: 0.8910
Valitadion Loss: 0.6119, Validation Acc: 0.7230, Vall f1: 0.6644, Val Precision: 0.6387, Val Recall: 0.6923, Val AUC: 0.7973
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.23it/s]










 91%|██████████████████████████████████████████████████████████████████████████▏       | 67/74 [00:21<00:02,  3.18it/s]
New threshold is 0.48571741580963135
train F1 is 0.8161764740943909

100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.18it/s]
 65%|█████████████████████████████████████████████████████▍                            | 15/23 [00:01<00:00,  8.00it/s]
New threshold is 0.4001012146472931
val F1 is 0.6711864471435547
Epoch 32/40, learning rate: 3.7592971517508045e-05
Train Loss: 0.4005, Train Acc: 0.8291, Train f1: 0.8162, Train Precision: 0.8506, Train Recall: 0.7845, Train AUC: 0.9001
Valitadion Loss: 0.5765, Validation Acc: 0.7313, Vall f1: 0.6712, Val Precision: 0.6513, Val Recall: 0.6923, Val AUC: 0.7883
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.14it/s]











 95%|█████████████████████████████████████████████████████████████████████████████▌    | 70/74 [00:22<00:01,  3.16it/s]
New threshold is 0.4713469445705414
train F1 is 0.8495897650718689
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.09it/s]
 30%|█████████████████████████▎                                                         | 7/23 [00:00<00:02,  7.85it/s]
New threshold is 0.45115479826927185
val F1 is 0.6834532618522644
Epoch 33/40, learning rate: 3.6942438504081787e-05
Train Loss: 0.3521, Train Acc: 0.8590, Train f1: 0.8496, Train Precision: 0.8776, Train Recall: 0.8233, Train AUC: 0.9200
Valitadion Loss: 0.5903, Validation Acc: 0.7562, Vall f1: 0.6835, Val Precision: 0.7037, Val Recall: 0.6643, Val AUC: 0.8026

100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.16it/s]











100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.09it/s]
New threshold is 0.4244798719882965
train F1 is 0.8576480746269226
val for epoch 34
 65%|█████████████████████████████████████████████████████▍                            | 15/23 [00:01<00:00,  8.06it/s]
New threshold is 0.27745211124420166
val F1 is 0.6851851940155029
Epoch 34/40, learning rate: 3.622127647425463e-05
Train Loss: 0.3459, Train Acc: 0.8624, Train f1: 0.8576, Train Precision: 0.8584, Train Recall: 0.8569, Train AUC: 0.9285
Valitadion Loss: 0.6211, Validation Acc: 0.7175, Vall f1: 0.6852, Val Precision: 0.6133, Val Recall: 0.7762, Val AUC: 0.7964
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.13it/s]











 95%|█████████████████████████████████████████████████████████████████████████████▌    | 70/74 [00:22<00:01,  3.17it/s]
New threshold is 0.43335235118865967
train F1 is 0.8543342351913452
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:23<00:00,  3.11it/s]
 30%|█████████████████████████▎                                                         | 7/23 [00:00<00:02,  7.77it/s]
New threshold is 0.3127751052379608
val F1 is 0.6996699571609497
Epoch 35/40, learning rate: 3.543249178194211e-05
Train Loss: 0.3334, Train Acc: 0.8607, Train f1: 0.8543, Train Precision: 0.8644, Train Recall: 0.8445, Train AUC: 0.9291
Valitadion Loss: 0.6229, Validation Acc: 0.7479, Vall f1: 0.6997, Val Precision: 0.6625, Val Recall: 0.7413, Val AUC: 0.7995
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.09it/s]












 92%|███████████████████████████████████████████████████████████████████████████▎      | 68/74 [00:23<00:02,  2.89it/s]
New threshold is 0.4389103055000305
train F1 is 0.8645740151405334
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:25<00:00,  2.89it/s]

 70%|█████████████████████████████████████████████████████████                         | 16/23 [00:02<00:00,  7.42it/s]
New threshold is 0.46688464283943176
val F1 is 0.6889632344245911
Epoch 36/40, learning rate: 3.457937268394392e-05
Train Loss: 0.3150, Train Acc: 0.8709, Train f1: 0.8646, Train Precision: 0.8780, Train Recall: 0.8516, Train AUC: 0.9338
Valitadion Loss: 0.6663, Validation Acc: 0.7424, Vall f1: 0.6890, Val Precision: 0.6603, Val Recall: 0.7203, Val AUC: 0.8071
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  7.53it/s]












 95%|█████████████████████████████████████████████████████████████████████████████▌    | 70/74 [00:25<00:01,  2.77it/s]
New threshold is 0.42882129549980164
train F1 is 0.8606702089309692
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:26<00:00,  2.82it/s]

 87%|███████████████████████████████████████████████████████████████████████▎          | 20/23 [00:02<00:00,  7.39it/s]
New threshold is 0.08987673372030258
val F1 is 0.6729559898376465
Epoch 37/40, learning rate: 3.36654756319791e-05
Train Loss: 0.3357, Train Acc: 0.8650, Train f1: 0.8607, Train Precision: 0.8592, Train Recall: 0.8622, Train AUC: 0.9369
Valitadion Loss: 0.6976, Validation Acc: 0.7119, Vall f1: 0.6730, Val Precision: 0.6114, Val Recall: 0.7483, Val AUC: 0.7834
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  7.47it/s]












 96%|██████████████████████████████████████████████████████████████████████████████▋   | 71/74 [00:25<00:01,  2.86it/s]
New threshold is 0.4715975821018219
train F1 is 0.865350067615509
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:26<00:00,  2.83it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  7.44it/s]
  0%|                                                                                           | 0/74 [00:00<?, ?it/s]
New threshold is 0.7084924578666687
val F1 is 0.6713286638259888
Epoch 38/40, learning rate: 3.26946104466801e-05
Train Loss: 0.2995, Train Acc: 0.8718, Train f1: 0.8654, Train Precision: 0.8796, Train Recall: 0.8516, Train AUC: 0.9436
Valitadion Loss: 0.6874, Validation Acc: 0.7396, Vall f1: 0.6713, Val Precision: 0.6713, Val Recall: 0.6713, Val AUC: 0.7924













 97%|███████████████████████████████████████████████████████████████████████████████▊  | 72/74 [00:25<00:00,  2.70it/s]
New threshold is 0.4423511326313019
train F1 is 0.8910714387893677
100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:26<00:00,  2.82it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  7.45it/s]
  0%|                                                                                           | 0/74 [00:00<?, ?it/s]
New threshold is 0.8260759711265564
val F1 is 0.6909090876579285
Epoch 39/40, learning rate: 3.167082443535175e-05
Train Loss: 0.2627, Train Acc: 0.8957, Train f1: 0.8911, Train Precision: 0.9007, Train Recall: 0.8816, Train AUC: 0.9556
Valitadion Loss: 0.7640, Validation Acc: 0.7645, Vall f1: 0.6909, Val Precision: 0.7197, Val Recall: 0.6643, Val AUC: 0.7962












100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:26<00:00,  2.83it/s]
  0%|                                                                                           | 0/23 [00:00<?, ?it/s]
New threshold is 0.5010731220245361
train F1 is 0.8651078939437866

 65%|█████████████████████████████████████████████████████▍                            | 15/23 [00:02<00:01,  7.37it/s]
New threshold is 0.5301674008369446
val F1 is 0.6875
Epoch 40/40, learning rate: 3.059838551970447e-05
Train Loss: 0.2832, Train Acc: 0.8718, Train f1: 0.8651, Train Precision: 0.8810, Train Recall: 0.8498, Train AUC: 0.9501
Valitadion Loss: 0.6862, Validation Acc: 0.7507, Vall f1: 0.6875, Val Precision: 0.6828, Val Recall: 0.6923, Val AUC: 0.7973
Training complete in 18m 21s
Best val auc: 0.813787
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  7.53it/s]



 83%|███████████████████████████████████████████████████████████████████▋              | 19/23 [00:06<00:01,  3.81it/s]
New threshold is 0.5301674008369446
Inference complete in 0m 8s
F1 Score = : 0.687500
AUC Score = : 0.797267

100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:07<00:00,  2.93it/s]