
  1%|▌                                                                                 | 1/147 [00:01<02:34,  1.06s/it]
Sequential(
  (0): DaVit(
    (stem): Stem(
      (conv): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
    )
    (stages): Sequential(
      (0): DaVitStage(
        (downsample): Identity()
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
                (act): Identity()
              )
              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (proj): Linear(in_features=96, out_features=96, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): Identity()
              (cpe2): ConvPosEnc(
                (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
                (act): Identity()
              )
              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=96, out_features=384, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=384, out_features=96, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): Identity()
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
                (act): Identity()
              )
              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (proj): Linear(in_features=96, out_features=96, bias=True)
              )
              (drop_path1): Identity()
              (cpe2): ConvPosEnc(
                (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
                (act): Identity()
              )
              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=96, out_features=384, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=384, out_features=96, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): Identity()
            )
          )
        )
      )
      (1): DaVitStage(
        (downsample): Downsample(
          (norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
          (conv): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
        )
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
                (act): Identity()
              )
              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (proj): Linear(in_features=192, out_features=192, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.018)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
                (act): Identity()
              )
              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=192, out_features=768, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=768, out_features=192, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.018)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
                (act): Identity()
              )
              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (proj): Linear(in_features=192, out_features=192, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.018)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
                (act): Identity()
              )
              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=192, out_features=768, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=768, out_features=192, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.018)
            )
          )
        )
      )
      (2): DaVitStage(
        (downsample): Downsample(
          (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (conv): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
        )
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.036)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.036)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.036)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.036)
            )
          )
          (1): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.055)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.055)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.055)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.055)
            )
          )
          (2): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.073)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.073)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.073)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.073)
            )
          )
          (3): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.091)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.091)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.091)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.091)
            )
          )
          (4): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.109)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.109)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.109)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.109)
            )
          )
          (5): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.127)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.127)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.127)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.127)
            )
          )
          (6): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.145)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.145)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.145)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.145)
            )
          )
          (7): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.164)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.164)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.164)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.164)
            )
          )
          (8): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.182)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.182)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (proj): Linear(in_features=384, out_features=384, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.182)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
                (act): Identity()
              )
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.182)
            )
          )
        )
      )
      (3): DaVitStage(
        (downsample): Downsample(
          (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (conv): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
        )
        (blocks): Sequential(
          (0): Sequential(
            (0): SpatialBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
                (act): Identity()
              )
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=768, out_features=2304, bias=True)
                (proj): Linear(in_features=768, out_features=768, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (drop_path1): DropPath(drop_prob=0.200)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
                (act): Identity()
              )
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=768, out_features=3072, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=3072, out_features=768, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.200)
            )
            (1): ChannelBlock(
              (cpe1): ConvPosEnc(
                (proj): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
                (act): Identity()
              )
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (attn): ChannelAttention(
                (qkv): Linear(in_features=768, out_features=2304, bias=True)
                (proj): Linear(in_features=768, out_features=768, bias=True)
              )
              (drop_path1): DropPath(drop_prob=0.200)
              (cpe2): ConvPosEnc(
                (proj): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
                (act): Identity()
              )
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=768, out_features=3072, bias=True)
                (act): GELU(approximate='none')
                (drop1): Dropout(p=0.0, inplace=False)
                (norm): Identity()
                (fc2): Linear(in_features=3072, out_features=768, bias=True)
                (drop2): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.200)
            )
          )
        )
      )
    )
    (norm_pre): Identity()
    (head): NormMlpClassifierHead(
      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())
      (norm): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (pre_logits): Identity()
      (drop): Dropout(p=0.0, inplace=False)
      (fc): Linear(in_features=768, out_features=1, bias=True)
    )
  )
  (1): Sigmoid()
)
Starting training...
--------------------









































 99%|██████████████████████████████████████████████████████████████████████████████▉ | 145/147 [01:23<00:01,  1.75it/s]
New threshold is 0.4853132367134094
train F1 is 0.5097706317901611
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:24<00:00,  1.75it/s]




 91%|██████████████████████████████████████████████████████████████████████████▊       | 21/23 [00:09<00:00,  2.31it/s]
New threshold is 0.4453904330730438
val F1 is 0.510769248008728
Epoch 1/80, learning rate: 9.993116499286332e-06
Train Loss: 0.6948, Train Acc: 0.5068, Train f1: 0.5098, Train Precision: 0.4918, Train Recall: 0.5291, Train AUC: 0.5093
Valitadion Loss: 0.6718, Validation Acc: 0.5596, Vall f1: 0.5108, Val Precision: 0.4560, Val Recall: 0.5804, Val AUC: 0.5700
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.35it/s]









































 98%|██████████████████████████████████████████████████████████████████████████████▎ | 144/147 [01:22<00:01,  1.78it/s]
New threshold is 0.4895308315753937
train F1 is 0.5666942596435547
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:24<00:00,  1.75it/s]




 83%|███████████████████████████████████████████████████████████████████▋              | 19/23 [00:08<00:01,  2.30it/s]
New threshold is 0.4739897549152374
val F1 is 0.5161290168762207
Epoch 2/80, learning rate: 9.972484950180048e-06
Train Loss: 0.6893, Train Acc: 0.5530, Train f1: 0.5667, Train Precision: 0.5344, Train Recall: 0.6032, Train AUC: 0.5561
Valitadion Loss: 0.6733, Validation Acc: 0.5845, Vall f1: 0.5161, Val Precision: 0.4790, Val Recall: 0.5594, Val AUC: 0.6073
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:10<00:00,  2.27it/s]









































 97%|█████████████████████████████████████████████████████████████████████████████▊  | 143/147 [01:22<00:02,  1.64it/s]
New threshold is 0.4824737012386322
train F1 is 0.5145888328552246
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:24<00:00,  1.75it/s]




 78%|████████████████████████████████████████████████████████████████▏                 | 18/23 [00:07<00:02,  2.32it/s]
New threshold is 0.4622511863708496
val F1 is 0.4868420958518982
Epoch 3/80, learning rate: 9.938162159600028e-06
Train Loss: 0.6917, Train Acc: 0.5308, Train f1: 0.5146, Train Precision: 0.5160, Train Recall: 0.5132, Train AUC: 0.5266
Valitadion Loss: 0.6722, Validation Acc: 0.5679, Vall f1: 0.4868, Val Precision: 0.4596, Val Recall: 0.5175, Val AUC: 0.5875
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.33it/s]









































 98%|██████████████████████████████████████████████████████████████████████████████▎ | 144/147 [01:21<00:01,  1.79it/s]
New threshold is 0.48346611857414246
train F1 is 0.5164152383804321
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:23<00:00,  1.77it/s]




 87%|███████████████████████████████████████████████████████████████████████▎          | 20/23 [00:09<00:01,  2.23it/s]
New threshold is 0.4523565173149109
val F1 is 0.5697329640388489
Epoch 4/80, learning rate: 9.890242631937106e-06
Train Loss: 0.6898, Train Acc: 0.5342, Train f1: 0.5164, Train Precision: 0.5196, Train Recall: 0.5132, Train AUC: 0.5406
Valitadion Loss: 0.6637, Validation Acc: 0.5983, Vall f1: 0.5697, Val Precision: 0.4948, Val Recall: 0.6713, Val AUC: 0.6482
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:10<00:00,  2.28it/s]









































 99%|██████████████████████████████████████████████████████████████████████████████▉ | 145/147 [01:22<00:01,  1.67it/s]
New threshold is 0.48613300919532776
train F1 is 0.5519031286239624
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:23<00:00,  1.77it/s]




 91%|██████████████████████████████████████████████████████████████████████████▊       | 21/23 [00:09<00:00,  2.34it/s]
New threshold is 0.3963620364665985
val F1 is 0.590062141418457
Epoch 5/80, learning rate: 9.828858308845623e-06
Train Loss: 0.6854, Train Acc: 0.5573, Train f1: 0.5519, Train Precision: 0.5416, Train Recall: 0.5626, Train AUC: 0.5749
Valitadion Loss: 0.6506, Validation Acc: 0.6343, Vall f1: 0.5901, Val Precision: 0.5307, Val Recall: 0.6643, Val AUC: 0.6769
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.35it/s]








































100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:23<00:00,  1.77it/s]
  0%|                                                                                           | 0/23 [00:00<?, ?it/s]
New threshold is 0.47459280490875244
train F1 is 0.5510729551315308





100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.32it/s]
New threshold is 0.4035830795764923
val F1 is 0.5962733030319214
Epoch 6/80, learning rate: 9.7541782059552e-06
Train Loss: 0.6858, Train Acc: 0.5530, Train f1: 0.5511, Train Precision: 0.5368, Train Recall: 0.5661, Train AUC: 0.5668
Valitadion Loss: 0.6468, Validation Acc: 0.6399, Vall f1: 0.5963, Val Precision: 0.5363, Val Recall: 0.6713, Val AUC: 0.6927
train for epoch 7








































 98%|██████████████████████████████████████████████████████████████████████████████▎ | 144/147 [01:21<00:01,  1.80it/s]
New threshold is 0.48648229241371155
train F1 is 0.563330352306366
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:23<00:00,  1.77it/s]




 83%|███████████████████████████████████████████████████████████████████▋              | 19/23 [00:08<00:01,  2.29it/s]
New threshold is 0.46867409348487854
val F1 is 0.6227545142173767
Epoch 7/80, learning rate: 9.66640794750302e-06
Train Loss: 0.6811, Train Acc: 0.5786, Train f1: 0.5633, Train Precision: 0.5658, Train Recall: 0.5608, Train AUC: 0.5982
Valitadion Loss: 0.6470, Validation Acc: 0.6510, Vall f1: 0.6228, Val Precision: 0.5445, Val Recall: 0.7273, Val AUC: 0.7173
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.32it/s]









































 98%|██████████████████████████████████████████████████████████████████████████████▎ | 144/147 [01:21<00:01,  1.72it/s]
New threshold is 0.48436594009399414
train F1 is 0.5618789792060852
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:23<00:00,  1.77it/s]




 83%|███████████████████████████████████████████████████████████████████▋              | 19/23 [00:08<00:01,  2.31it/s]
New threshold is 0.5057271122932434
val F1 is 0.6056782603263855
Epoch 8/80, learning rate: 9.565789200167927e-06
Train Loss: 0.6740, Train Acc: 0.5855, Train f1: 0.5619, Train Precision: 0.5759, Train Recall: 0.5485, Train AUC: 0.6116
Valitadion Loss: 0.6623, Validation Acc: 0.6537, Vall f1: 0.6057, Val Precision: 0.5517, Val Recall: 0.6713, Val AUC: 0.6808
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.32it/s]









































 99%|██████████████████████████████████████████████████████████████████████████████▉ | 145/147 [01:22<00:01,  1.79it/s]
New threshold is 0.4850119650363922
train F1 is 0.5524475574493408
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:23<00:00,  1.77it/s]




 87%|███████████████████████████████████████████████████████████████████████▎          | 20/23 [00:09<00:01,  2.29it/s]
New threshold is 0.506223201751709
val F1 is 0.6094674468040466
Epoch 9/80, learning rate: 9.45259900766526e-06
Train Loss: 0.6796, Train Acc: 0.5624, Train f1: 0.5524, Train Precision: 0.5477, Train Recall: 0.5573, Train AUC: 0.5950
Valitadion Loss: 0.6662, Validation Acc: 0.6343, Vall f1: 0.6095, Val Precision: 0.5282, Val Recall: 0.7203, Val AUC: 0.6789
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:10<00:00,  2.26it/s]








































 97%|█████████████████████████████████████████████████████████████████████████████▊  | 143/147 [01:21<00:02,  1.78it/s]
New threshold is 0.47884610295295715
train F1 is 0.5731292366981506
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:22<00:00,  1.77it/s]




 78%|████████████████████████████████████████████████████████████████▏                 | 18/23 [00:07<00:02,  2.35it/s]
New threshold is 0.5351875424385071
val F1 is 0.5894039869308472
Epoch 10/80, learning rate: 9.327149027934535e-06
Train Loss: 0.6820, Train Acc: 0.5709, Train f1: 0.5731, Train Precision: 0.5534, Train Recall: 0.5944, Train AUC: 0.5929
Valitadion Loss: 0.6656, Validation Acc: 0.6565, Vall f1: 0.5894, Val Precision: 0.5597, Val Recall: 0.6224, Val AUC: 0.6979
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.34it/s]









































 97%|█████████████████████████████████████████████████████████████████████████████▊  | 143/147 [01:21<00:02,  1.79it/s]
New threshold is 0.4903729557991028
train F1 is 0.5658363103866577
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:23<00:00,  1.76it/s]




 78%|████████████████████████████████████████████████████████████████▏                 | 18/23 [00:08<00:02,  2.14it/s]
New threshold is 0.5517237186431885
val F1 is 0.5454545617103577
Epoch 11/80, learning rate: 9.189784675020298e-06
Train Loss: 0.6727, Train Acc: 0.5829, Train f1: 0.5658, Train Precision: 0.5709, Train Recall: 0.5608, Train AUC: 0.6131
Valitadion Loss: 0.6720, Validation Acc: 0.6399, Vall f1: 0.5455, Val Precision: 0.5455, Val Recall: 0.5455, Val AUC: 0.6692

100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:10<00:00,  2.26it/s]








































 98%|██████████████████████████████████████████████████████████████████████████████▎ | 144/147 [01:21<00:01,  1.77it/s]
New threshold is 0.4816552996635437
train F1 is 0.5832614302635193
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:22<00:00,  1.77it/s]




 87%|███████████████████████████████████████████████████████████████████████▎          | 20/23 [00:08<00:01,  2.34it/s]
New threshold is 0.5165046453475952
val F1 is 0.5947712659835815
Epoch 12/80, learning rate: 9.040884168008893e-06
Train Loss: 0.6718, Train Acc: 0.5872, Train f1: 0.5833, Train Precision: 0.5709, Train Recall: 0.5961, Train AUC: 0.6165
Valitadion Loss: 0.6476, Validation Acc: 0.6565, Vall f1: 0.5948, Val Precision: 0.5583, Val Recall: 0.6364, Val AUC: 0.6930
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.31it/s]









































 99%|███████████████████████████████████████████████████████████████████████████████▍| 146/147 [01:23<00:00,  1.80it/s]
New threshold is 0.4717988967895508
train F1 is 0.5902480483055115
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:23<00:00,  1.77it/s]




 96%|██████████████████████████████████████████████████████████████████████████████▍   | 22/23 [00:09<00:00,  2.33it/s]
New threshold is 0.4257952868938446
val F1 is 0.5543859601020813
Epoch 13/80, learning rate: 8.880857489639832e-06
Train Loss: 0.6722, Train Acc: 0.5906, Train f1: 0.5902, Train Precision: 0.5731, Train Recall: 0.6085, Train AUC: 0.6186
Valitadion Loss: 0.6187, Validation Acc: 0.6482, Vall f1: 0.5544, Val Precision: 0.5563, Val Recall: 0.5524, Val AUC: 0.6936
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.35it/s]








































 99%|██████████████████████████████████████████████████████████████████████████████▉ | 145/147 [01:21<00:01,  1.80it/s]
New threshold is 0.46001455187797546
train F1 is 0.5860927104949951
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:22<00:00,  1.78it/s]




 87%|███████████████████████████████████████████████████████████████████████▎          | 20/23 [00:09<00:01,  2.33it/s]
New threshold is 0.45486927032470703
val F1 is 0.6266666650772095
Epoch 14/80, learning rate: 8.710145257459083e-06
Train Loss: 0.6782, Train Acc: 0.5726, Train f1: 0.5861, Train Precision: 0.5523, Train Recall: 0.6243, Train AUC: 0.5946
Valitadion Loss: 0.6231, Validation Acc: 0.6898, Vall f1: 0.6267, Val Precision: 0.5987, Val Recall: 0.6573, Val AUC: 0.7181
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:10<00:00,  2.28it/s]









































100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:22<00:00,  1.78it/s]
New threshold is 0.47799545526504517
train F1 is 0.5709312558174133
val for epoch 15




100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.38it/s]
New threshold is 0.45656272768974304
val F1 is 0.6242038011550903
Epoch 15/80, learning rate: 8.529217510622467e-06
Train Loss: 0.6745, Train Acc: 0.5786, Train f1: 0.5709, Train Precision: 0.5636, Train Recall: 0.5785, Train AUC: 0.6114
Valitadion Loss: 0.6221, Validation Acc: 0.6731, Vall f1: 0.6242, Val Precision: 0.5731, Val Recall: 0.6853, Val AUC: 0.7185
train for epoch 16








































 97%|█████████████████████████████████████████████████████████████████████████████▊  | 143/147 [01:21<00:02,  1.78it/s]
New threshold is 0.47480088472366333
train F1 is 0.5933682322502136
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:22<00:00,  1.77it/s]




 83%|███████████████████████████████████████████████████████████████████▋              | 19/23 [00:08<00:01,  2.31it/s]
New threshold is 0.45345160365104675
val F1 is 0.6129032373428345
Epoch 16/80, learning rate: 8.338572415689588e-06
Train Loss: 0.6629, Train Acc: 0.6017, Train f1: 0.5934, Train Precision: 0.5872, Train Recall: 0.5996, Train AUC: 0.6341
Valitadion Loss: 0.6131, Validation Acc: 0.6676, Vall f1: 0.6129, Val Precision: 0.5689, Val Recall: 0.6643, Val AUC: 0.7239
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.35it/s]









































 99%|██████████████████████████████████████████████████████████████████████████████▉ | 145/147 [01:22<00:01,  1.79it/s]
New threshold is 0.49118128418922424
train F1 is 0.5796579718589783
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:22<00:00,  1.77it/s]




 91%|██████████████████████████████████████████████████████████████████████████▊       | 21/23 [00:09<00:00,  2.36it/s]
New threshold is 0.4335995614528656
val F1 is 0.6163522005081177
Epoch 17/80, learning rate: 8.138734894971755e-06
Train Loss: 0.6593, Train Acc: 0.6009, Train f1: 0.5797, Train Precision: 0.5919, Train Recall: 0.5679, Train AUC: 0.6372
Valitadion Loss: 0.6184, Validation Acc: 0.6620, Vall f1: 0.6164, Val Precision: 0.5600, Val Recall: 0.6853, Val AUC: 0.7119
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.38it/s]








































 98%|██████████████████████████████████████████████████████████████████████████████▎ | 144/147 [01:21<00:01,  1.75it/s]
New threshold is 0.4841625392436981
train F1 is 0.5810564756393433
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:22<00:00,  1.77it/s]




 83%|███████████████████████████████████████████████████████████████████▋              | 19/23 [00:08<00:01,  2.29it/s]
New threshold is 0.5107445120811462
val F1 is 0.6289308071136475
Epoch 18/80, learning rate: 7.930255181210576e-06
Train Loss: 0.6612, Train Acc: 0.6068, Train f1: 0.5811, Train Precision: 0.6008, Train Recall: 0.5626, Train AUC: 0.6406
Valitadion Loss: 0.6337, Validation Acc: 0.6731, Vall f1: 0.6289, Val Precision: 0.5714, Val Recall: 0.6993, Val AUC: 0.7190
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.34it/s]









































 98%|██████████████████████████████████████████████████████████████████████████████▎ | 144/147 [01:22<00:01,  1.78it/s]
New threshold is 0.4881947934627533
train F1 is 0.5837838053703308
100%|████████████████████████████████████████████████████████████████████████████████| 147/147 [01:23<00:00,  1.75it/s]




 87%|███████████████████████████████████████████████████████████████████████▎          | 20/23 [00:08<00:01,  2.35it/s]
New threshold is 0.4021807909011841
val F1 is 0.6178343892097473
Epoch 19/80, learning rate: 7.713707302566843e-06
Train Loss: 0.6613, Train Acc: 0.6051, Train f1: 0.5838, Train Precision: 0.5967, Train Recall: 0.5714, Train AUC: 0.6395
Valitadion Loss: 0.6109, Validation Acc: 0.6676, Vall f1: 0.6178, Val Precision: 0.5673, Val Recall: 0.6783, Val AUC: 0.7222
100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.37it/s]




 11%|████████▊                                                                        | 16/147 [00:09<01:17,  1.68it/s]
Traceback (most recent call last):
  File "C:\Users\marcb\OneDrive\Desktop\mberghouse\Mammo_classification_scripts\cbisddsm_classification_300x500.py", line 1199, in <module>
    model = train_model(model, model_name, criterion, optimizer, scheduler, num_epochs=epochs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marcb\OneDrive\Desktop\mberghouse\Mammo_classification_scripts\cbisddsm_classification_300x500.py", line 164, in train_model
    all_outputs = torch.cat((all_outputs, outputs.to('cpu')))
                                          ^^^^^^^^^^^^^^^^^
KeyboardInterrupt