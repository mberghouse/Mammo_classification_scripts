{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc543652-1ae0-4db8-b1ad-bc9f273805c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timm.layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DropPath, to_2tuple, trunc_normal_, Mlp, LayerNorm2d, get_norm_layer, use_fused_attn\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NormMlpClassifierHead, ClassifierHead\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_model_with_cfg\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'timm.layers'"
     ]
    }
   ],
   "source": [
    "\"\"\" DaViT: Dual Attention Vision Transformers\n",
    "\n",
    "As described in https://arxiv.org/abs/2204.03645\n",
    "\n",
    "Input size invariant transformer architecture that combines channel and spacial\n",
    "attention in each block. The attention mechanisms used are linear in complexity.\n",
    "\n",
    "DaViT model defs and weights adapted from https://github.com/dingmyu/davit, original copyright below\n",
    "\n",
    "\"\"\"\n",
    "# Copyright (c) 2022 Mingyu Ding\n",
    "# All rights reserved.\n",
    "# This source code is licensed under the MIT license\n",
    "from functools import partial\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import timm\n",
    "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.layers import DropPath, to_2tuple, trunc_normal_, Mlp, LayerNorm2d, get_norm_layer, use_fused_attn\n",
    "from timm.layers import NormMlpClassifierHead, ClassifierHead\n",
    "from ._builder import build_model_with_cfg\n",
    "from ._features_fx import register_notrace_function\n",
    "from ._manipulate import checkpoint_seq\n",
    "from ._registry import generate_default_cfgs, register_model\n",
    "\n",
    "__all__ = ['DaVit']\n",
    "\n",
    "\n",
    "class ConvPosEnc(nn.Module):\n",
    "    def __init__(self, dim: int, k: int = 3, act: bool = False):\n",
    "        super(ConvPosEnc, self).__init__()\n",
    "\n",
    "        self.proj = nn.Conv2d(dim, dim, k, 1, k // 2, groups=dim)\n",
    "        self.act = nn.GELU() if act else nn.Identity()\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        feat = self.proj(x)\n",
    "        x = x + self.act(feat)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Stem(nn.Module):\n",
    "    \"\"\" Size-agnostic implementation of 2D image to patch embedding,\n",
    "        allowing input size to be adjusted during model forward operation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_chs=3,\n",
    "            out_chs=96,\n",
    "            stride=4,\n",
    "            norm_layer=LayerNorm2d,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        stride = to_2tuple(stride)\n",
    "        self.stride = stride\n",
    "        self.in_chs = in_chs\n",
    "        self.out_chs = out_chs\n",
    "        assert stride[0] == 4  # only setup for stride==4\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_chs,\n",
    "            out_chs,\n",
    "            kernel_size=7,\n",
    "            stride=stride,\n",
    "            padding=3,\n",
    "        )\n",
    "        self.norm = norm_layer(out_chs)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        B, C, H, W = x.shape\n",
    "        x = F.pad(x, (0, (self.stride[1] - W % self.stride[1]) % self.stride[1]))\n",
    "        x = F.pad(x, (0, 0, 0, (self.stride[0] - H % self.stride[0]) % self.stride[0]))\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_chs,\n",
    "            out_chs,\n",
    "            norm_layer=LayerNorm2d,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_chs = in_chs\n",
    "        self.out_chs = out_chs\n",
    "\n",
    "        self.norm = norm_layer(in_chs)\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_chs,\n",
    "            out_chs,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.norm(x)\n",
    "        x = F.pad(x, (0, (2 - W % 2) % 2))\n",
    "        x = F.pad(x, (0, 0, 0, (2 - H % 2) % 2))\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv.unbind(0)\n",
    "\n",
    "        k = k * self.scale\n",
    "        attention = k.transpose(-1, -2) @ v\n",
    "        attention = attention.softmax(dim=-1)\n",
    "        x = (attention @ q.transpose(-1, -2)).transpose(-1, -2)\n",
    "        x = x.transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ChannelBlock(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dim,\n",
    "            num_heads,\n",
    "            mlp_ratio=4.,\n",
    "            qkv_bias=False,\n",
    "            drop_path=0.,\n",
    "            act_layer=nn.GELU,\n",
    "            norm_layer=nn.LayerNorm,\n",
    "            ffn=True,\n",
    "            cpe_act=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cpe1 = ConvPosEnc(dim=dim, k=3, act=cpe_act)\n",
    "        self.ffn = ffn\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = ChannelAttention(dim, num_heads=num_heads, qkv_bias=qkv_bias)\n",
    "        self.drop_path1 = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.cpe2 = ConvPosEnc(dim=dim, k=3, act=cpe_act)\n",
    "\n",
    "        if self.ffn:\n",
    "            self.norm2 = norm_layer(dim)\n",
    "            self.mlp = Mlp(\n",
    "                in_features=dim,\n",
    "                hidden_features=int(dim * mlp_ratio),\n",
    "                act_layer=act_layer,\n",
    "            )\n",
    "            self.drop_path2 = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        else:\n",
    "            self.norm2 = None\n",
    "            self.mlp = None\n",
    "            self.drop_path2 = None\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        x = self.cpe1(x).flatten(2).transpose(1, 2)\n",
    "\n",
    "        cur = self.norm1(x)\n",
    "        cur = self.attn(cur)\n",
    "        x = x + self.drop_path1(cur)\n",
    "\n",
    "        x = self.cpe2(x.transpose(1, 2).view(B, C, H, W))\n",
    "\n",
    "        if self.mlp is not None:\n",
    "            x = x.flatten(2).transpose(1, 2)\n",
    "            x = x + self.drop_path2(self.mlp(self.norm2(x)))\n",
    "            x = x.transpose(1, 2).view(B, C, H, W)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def window_partition(x: Tensor, window_size: Tuple[int, int]):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, H, W, C)\n",
    "        window_size (int): window size\n",
    "    Returns:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "    \"\"\"\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.view(B, H // window_size[0], window_size[0], W // window_size[1], window_size[1], C)\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size[0], window_size[1], C)\n",
    "    return windows\n",
    "\n",
    "\n",
    "@register_notrace_function  # reason: int argument is a Proxy\n",
    "def window_reverse(windows: Tensor, window_size: Tuple[int, int], H: int, W: int):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "        window_size (int): Window size\n",
    "        H (int): Height of image\n",
    "        W (int): Width of image\n",
    "    Returns:\n",
    "        x: (B, H, W, C)\n",
    "    \"\"\"\n",
    "    C = windows.shape[-1]\n",
    "    x = windows.view(-1, H // window_size[0], W // window_size[1], window_size[0], window_size[1], C)\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, H, W, C)\n",
    "    return x\n",
    "\n",
    "\n",
    "class WindowAttention(nn.Module):\n",
    "    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
    "    It supports both of shifted and non-shifted window.\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        window_size (tuple[int]): The height and width of the window.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
    "    \"\"\"\n",
    "    fused_attn: torch.jit.Final[bool]\n",
    "\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "        self.fused_attn = use_fused_attn()\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        B_, N, C = x.shape\n",
    "\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv.unbind(0)\n",
    "\n",
    "        if self.fused_attn:\n",
    "            x = F.scaled_dot_product_attention(q, k, v)\n",
    "        else:\n",
    "            q = q * self.scale\n",
    "            attn = (q @ k.transpose(-2, -1))\n",
    "            attn = self.softmax(attn)\n",
    "            x = attn @ v\n",
    "\n",
    "        x = x.transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpatialBlock(nn.Module):\n",
    "    r\"\"\" Windows Block.\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Window size.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
    "        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n",
    "        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dim,\n",
    "            num_heads,\n",
    "            window_size=7,\n",
    "            mlp_ratio=4.,\n",
    "            qkv_bias=True,\n",
    "            drop_path=0.,\n",
    "            act_layer=nn.GELU,\n",
    "            norm_layer=nn.LayerNorm,\n",
    "            ffn=True,\n",
    "            cpe_act=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.ffn = ffn\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = to_2tuple(window_size)\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "\n",
    "        self.cpe1 = ConvPosEnc(dim=dim, k=3, act=cpe_act)\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = WindowAttention(\n",
    "            dim,\n",
    "            self.window_size,\n",
    "            num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "        )\n",
    "        self.drop_path1 = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "        self.cpe2 = ConvPosEnc(dim=dim, k=3, act=cpe_act)\n",
    "        if self.ffn:\n",
    "            self.norm2 = norm_layer(dim)\n",
    "            mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "            self.mlp = Mlp(\n",
    "                in_features=dim,\n",
    "                hidden_features=mlp_hidden_dim,\n",
    "                act_layer=act_layer,\n",
    "            )\n",
    "            self.drop_path2 = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        else:\n",
    "            self.norm2 = None\n",
    "            self.mlp = None\n",
    "            self.drop_path1 = None\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        shortcut = self.cpe1(x).flatten(2).transpose(1, 2)\n",
    "\n",
    "        x = self.norm1(shortcut)\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        pad_l = pad_t = 0\n",
    "        pad_r = (self.window_size[1] - W % self.window_size[1]) % self.window_size[1]\n",
    "        pad_b = (self.window_size[0] - H % self.window_size[0]) % self.window_size[0]\n",
    "        x = F.pad(x, (0, 0, pad_l, pad_r, pad_t, pad_b))\n",
    "        _, Hp, Wp, _ = x.shape\n",
    "\n",
    "        x_windows = window_partition(x, self.window_size)\n",
    "        x_windows = x_windows.view(-1, self.window_size[0] * self.window_size[1], C)\n",
    "\n",
    "        # W-MSA/SW-MSA\n",
    "        attn_windows = self.attn(x_windows)\n",
    "\n",
    "        # merge windows\n",
    "        attn_windows = attn_windows.view(-1, self.window_size[0], self.window_size[1], C)\n",
    "        x = window_reverse(attn_windows, self.window_size, Hp, Wp)\n",
    "\n",
    "        # if pad_r > 0 or pad_b > 0:\n",
    "        x = x[:, :H, :W, :].contiguous()\n",
    "\n",
    "        x = x.view(B, H * W, C)\n",
    "        x = shortcut + self.drop_path1(x)\n",
    "\n",
    "        x = self.cpe2(x.transpose(1, 2).view(B, C, H, W))\n",
    "\n",
    "        if self.mlp is not None:\n",
    "            x = x.flatten(2).transpose(1, 2)\n",
    "            x = x + self.drop_path2(self.mlp(self.norm2(x)))\n",
    "            x = x.transpose(1, 2).view(B, C, H, W)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DaVitStage(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_chs,\n",
    "            out_chs,\n",
    "            depth=1,\n",
    "            downsample=True,\n",
    "            attn_types=('spatial', 'channel'),\n",
    "            num_heads=3,\n",
    "            window_size=7,\n",
    "            mlp_ratio=4,\n",
    "            qkv_bias=True,\n",
    "            drop_path_rates=(0, 0),\n",
    "            norm_layer=LayerNorm2d,\n",
    "            norm_layer_cl=nn.LayerNorm,\n",
    "            ffn=True,\n",
    "            cpe_act=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.grad_checkpointing = False\n",
    "\n",
    "        # downsample embedding layer at the beginning of each stage\n",
    "        if downsample:\n",
    "            self.downsample = Downsample(in_chs, out_chs, norm_layer=norm_layer)\n",
    "        else:\n",
    "            self.downsample = nn.Identity()\n",
    "\n",
    "        '''\n",
    "         repeating alternating attention blocks in each stage\n",
    "         default: (spatial -> channel) x depth\n",
    "         \n",
    "         potential opportunity to integrate with a more general version of ByobNet/ByoaNet\n",
    "         since the logic is similar\n",
    "        '''\n",
    "        stage_blocks = []\n",
    "        for block_idx in range(depth):\n",
    "            dual_attention_block = []\n",
    "            for attn_idx, attn_type in enumerate(attn_types):\n",
    "                if attn_type == 'spatial':\n",
    "                    dual_attention_block.append(SpatialBlock(\n",
    "                        dim=out_chs,\n",
    "                        num_heads=num_heads,\n",
    "                        mlp_ratio=mlp_ratio,\n",
    "                        qkv_bias=qkv_bias,\n",
    "                        drop_path=drop_path_rates[block_idx],\n",
    "                        norm_layer=norm_layer_cl,\n",
    "                        ffn=ffn,\n",
    "                        cpe_act=cpe_act,\n",
    "                        window_size=window_size,\n",
    "                    ))\n",
    "                elif attn_type == 'channel':\n",
    "                    dual_attention_block.append(ChannelBlock(\n",
    "                        dim=out_chs,\n",
    "                        num_heads=num_heads,\n",
    "                        mlp_ratio=mlp_ratio,\n",
    "                        qkv_bias=qkv_bias,\n",
    "                        drop_path=drop_path_rates[block_idx],\n",
    "                        norm_layer=norm_layer_cl,\n",
    "                        ffn=ffn,\n",
    "                        cpe_act=cpe_act\n",
    "                    ))\n",
    "            stage_blocks.append(nn.Sequential(*dual_attention_block))\n",
    "        self.blocks = nn.Sequential(*stage_blocks)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def set_grad_checkpointing(self, enable=True):\n",
    "        self.grad_checkpointing = enable\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        x = self.downsample(x)\n",
    "        if self.grad_checkpointing and not torch.jit.is_scripting():\n",
    "            x = checkpoint_seq(self.blocks, x)\n",
    "        else:\n",
    "            x = self.blocks(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DaVit(nn.Module):\n",
    "    r\"\"\" DaViT\n",
    "        A PyTorch implementation of `DaViT: Dual Attention Vision Transformers`  - https://arxiv.org/abs/2204.03645\n",
    "        Supports arbitrary input sizes and pyramid feature extraction\n",
    "        \n",
    "    Args:\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        depths (tuple(int)): Number of blocks in each stage. Default: (1, 1, 3, 1)\n",
    "        embed_dims (tuple(int)): Patch embedding dimension. Default: (96, 192, 384, 768)\n",
    "        num_heads (tuple(int)): Number of attention heads in different layers. Default: (3, 6, 12, 24)\n",
    "        window_size (int): Window size. Default: 7\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n",
    "        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n",
    "        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_chans=3,\n",
    "            depths=(1, 1, 3, 1),\n",
    "            embed_dims=(96, 192, 384, 768),\n",
    "            num_heads=(3, 6, 12, 24),\n",
    "            window_size=7,\n",
    "            mlp_ratio=4,\n",
    "            qkv_bias=True,\n",
    "            norm_layer='layernorm2d',\n",
    "            norm_layer_cl='layernorm',\n",
    "            norm_eps=1e-5,\n",
    "            attn_types=('spatial', 'channel'),\n",
    "            ffn=True,\n",
    "            cpe_act=False,\n",
    "            drop_rate=0.,\n",
    "            drop_path_rate=0.,\n",
    "            num_classes=1000,\n",
    "            global_pool='avg',\n",
    "            head_norm_first=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        num_stages = len(embed_dims)\n",
    "        assert num_stages == len(num_heads) == len(depths)\n",
    "        norm_layer = partial(get_norm_layer(norm_layer), eps=norm_eps)\n",
    "        norm_layer_cl = partial(get_norm_layer(norm_layer_cl), eps=norm_eps)\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = embed_dims[-1]\n",
    "        self.drop_rate = drop_rate\n",
    "        self.grad_checkpointing = False\n",
    "        self.feature_info = []\n",
    "\n",
    "        self.stem = Stem(in_chans, embed_dims[0], norm_layer=norm_layer)\n",
    "        in_chs = embed_dims[0]\n",
    "\n",
    "        dpr = [x.tolist() for x in torch.linspace(0, drop_path_rate, sum(depths)).split(depths)]\n",
    "        stages = []\n",
    "        for stage_idx in range(num_stages):\n",
    "            out_chs = embed_dims[stage_idx]\n",
    "            stage = DaVitStage(\n",
    "                in_chs,\n",
    "                out_chs,\n",
    "                depth=depths[stage_idx],\n",
    "                downsample=stage_idx > 0,\n",
    "                attn_types=attn_types,\n",
    "                num_heads=num_heads[stage_idx],\n",
    "                window_size=window_size,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                drop_path_rates=dpr[stage_idx],\n",
    "                norm_layer=norm_layer,\n",
    "                norm_layer_cl=norm_layer_cl,\n",
    "                ffn=ffn,\n",
    "                cpe_act=cpe_act,\n",
    "            )\n",
    "            in_chs = out_chs\n",
    "            stages.append(stage)\n",
    "            self.feature_info += [dict(num_chs=out_chs, reduction=2, module=f'stages.{stage_idx}')]\n",
    "\n",
    "        self.stages = nn.Sequential(*stages)\n",
    "\n",
    "        # if head_norm_first == true, norm -> global pool -> fc ordering, like most other nets\n",
    "        # otherwise pool -> norm -> fc, the default DaViT order, similar to ConvNeXt\n",
    "        # FIXME generalize this structure to ClassifierHead\n",
    "        if head_norm_first:\n",
    "            self.norm_pre = norm_layer(self.num_features)\n",
    "            self.head = ClassifierHead(\n",
    "                self.num_features,\n",
    "                num_classes,\n",
    "                pool_type=global_pool,\n",
    "                drop_rate=self.drop_rate,\n",
    "            )\n",
    "        else:\n",
    "            self.norm_pre = nn.Identity()\n",
    "            self.head = NormMlpClassifierHead(\n",
    "                self.num_features,\n",
    "                num_classes,\n",
    "                pool_type=global_pool,\n",
    "                drop_rate=self.drop_rate,\n",
    "                norm_layer=norm_layer,\n",
    "            )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def group_matcher(self, coarse=False):\n",
    "        return dict(\n",
    "            stem=r'^stem',  # stem and embed\n",
    "            blocks=r'^stages\\.(\\d+)' if coarse else [\n",
    "                (r'^stages\\.(\\d+).downsample', (0,)),\n",
    "                (r'^stages\\.(\\d+)\\.blocks\\.(\\d+)', None),\n",
    "                (r'^norm_pre', (99999,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def set_grad_checkpointing(self, enable=True):\n",
    "        self.grad_checkpointing = enable\n",
    "        for stage in self.stages:\n",
    "            stage.set_grad_checkpointing(enable=enable)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def get_classifier(self):\n",
    "        return self.head.fc\n",
    "\n",
    "    def reset_classifier(self, num_classes, global_pool=None):\n",
    "        self.head.reset(num_classes, global_pool)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.stem(x)\n",
    "        if self.grad_checkpointing and not torch.jit.is_scripting():\n",
    "            x = checkpoint_seq(self.stages, x)\n",
    "        else:\n",
    "            x = self.stages(x)\n",
    "        x = self.norm_pre(x)\n",
    "        return x\n",
    "\n",
    "    def forward_head(self, x, pre_logits: bool = False):\n",
    "        return self.head(x, pre_logits=True) if pre_logits else self.head(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.forward_head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def checkpoint_filter_fn(state_dict, model):\n",
    "    \"\"\" Remap MSFT checkpoints -> timm \"\"\"\n",
    "    if 'head.fc.weight' in state_dict:\n",
    "        return state_dict  # non-MSFT checkpoint\n",
    "\n",
    "    if 'state_dict' in state_dict:\n",
    "        state_dict = state_dict['state_dict']\n",
    "\n",
    "    import re\n",
    "    out_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        k = re.sub(r'patch_embeds.([0-9]+)', r'stages.\\1.downsample', k)\n",
    "        k = re.sub(r'main_blocks.([0-9]+)', r'stages.\\1.blocks', k)\n",
    "        k = k.replace('downsample.proj', 'downsample.conv')\n",
    "        k = k.replace('stages.0.downsample', 'stem')\n",
    "        k = k.replace('head.', 'head.fc.')\n",
    "        k = k.replace('norms.', 'head.norm.')\n",
    "        k = k.replace('cpe.0', 'cpe1')\n",
    "        k = k.replace('cpe.1', 'cpe2')\n",
    "        out_dict[k] = v\n",
    "    return out_dict\n",
    "\n",
    "\n",
    "def _create_davit(variant, pretrained=False, **kwargs):\n",
    "    default_out_indices = tuple(i for i, _ in enumerate(kwargs.get('depths', (1, 1, 3, 1))))\n",
    "    out_indices = kwargs.pop('out_indices', default_out_indices)\n",
    "\n",
    "    model = build_model_with_cfg(\n",
    "        DaVit,\n",
    "        variant,\n",
    "        pretrained,\n",
    "        pretrained_filter_fn=checkpoint_filter_fn,\n",
    "        feature_cfg=dict(flatten_sequential=True, out_indices=out_indices),\n",
    "        **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _cfg(url='', **kwargs):\n",
    "    return {\n",
    "        'url': url,\n",
    "        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n",
    "        'crop_pct': 0.95, 'interpolation': 'bicubic',\n",
    "        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n",
    "        'first_conv': 'stem.conv', 'classifier': 'head.fc',\n",
    "        **kwargs\n",
    "    }\n",
    "\n",
    "\n",
    "# TODO contact authors to get larger pretrained models\n",
    "default_cfgs = generate_default_cfgs({\n",
    "    # official microsoft weights from https://github.com/dingmyu/davit\n",
    "    'davit_tiny.msft_in1k': _cfg(\n",
    "        hf_hub_id='timm/'),\n",
    "    'davit_small.msft_in1k': _cfg(\n",
    "        hf_hub_id='timm/'),\n",
    "    'davit_base.msft_in1k': _cfg(\n",
    "        hf_hub_id='timm/'),\n",
    "    'davit_large': _cfg(),\n",
    "    'davit_huge': _cfg(),\n",
    "    'davit_giant': _cfg(),\n",
    "})\n",
    "\n",
    "\n",
    "@register_model\n",
    "def davit_tiny(pretrained=False, **kwargs) -> DaVit:\n",
    "    model_args = dict(depths=(1, 1, 3, 1), embed_dims=(96, 192, 384, 768), num_heads=(3, 6, 12, 24))\n",
    "    return _create_davit('davit_tiny', pretrained=pretrained, **dict(model_args, **kwargs))\n",
    "\n",
    "\n",
    "@register_model\n",
    "def davit_small(pretrained=False, **kwargs) -> DaVit:\n",
    "    model_args = dict(depths=(1, 1, 9, 1), embed_dims=(96, 192, 384, 768), num_heads=(3, 6, 12, 24))\n",
    "    return _create_davit('davit_small', pretrained=pretrained, **dict(model_args, **kwargs))\n",
    "\n",
    "\n",
    "@register_model\n",
    "def davit_base(pretrained=False, **kwargs) -> DaVit:\n",
    "    model_args = dict(depths=(1, 1, 9, 1), embed_dims=(128, 256, 512, 1024), num_heads=(4, 8, 16, 32))\n",
    "    return _create_davit('davit_base', pretrained=pretrained, **dict(model_args, **kwargs))\n",
    "\n",
    "\n",
    "@register_model\n",
    "def davit_large(pretrained=False, **kwargs) -> DaVit:\n",
    "    model_args = dict(depths=(1, 1, 9, 1), embed_dims=(192, 384, 768, 1536), num_heads=(6, 12, 24, 48))\n",
    "    return _create_davit('davit_large', pretrained=pretrained, **dict(model_args, **kwargs))\n",
    "\n",
    "\n",
    "@register_model\n",
    "def davit_huge(pretrained=False, **kwargs) -> DaVit:\n",
    "    model_args = dict(depths=(1, 1, 9, 1), embed_dims=(256, 512, 1024, 2048), num_heads=(8, 16, 32, 64))\n",
    "    return _create_davit('davit_huge', pretrained=pretrained, **dict(model_args, **kwargs))\n",
    "\n",
    "\n",
    "@register_model\n",
    "def davit_giant(pretrained=False, **kwargs) -> DaVit:\n",
    "    model_args = dict(depths=(1, 1, 12, 3), embed_dims=(384, 768, 1536, 3072), num_heads=(12, 24, 48, 96))\n",
    "    return _create_davit('davit_giant', pretrained=pretrained, **dict(model_args, **kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f227ae-6e7c-44b5-83ed-2017f6c65e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'timm.models' from 'C:\\\\Users\\\\marcb\\\\OneDrive\\\\Desktop\\\\mberghouse\\\\Mammo_classification_scripts\\\\timm\\\\models\\\\__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5939a3-c02e-46a2-81e1-dfe2e2f8314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function timm.models.layers.config.is_scriptable()>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.is_scriptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c273d2e0-66bc-478d-bce7-5a0d57d0f1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat_resnext26ts',\n",
       " 'beit_base_patch16_224',\n",
       " 'beit_base_patch16_384',\n",
       " 'beit_large_patch16_224',\n",
       " 'beit_large_patch16_384',\n",
       " 'beit_large_patch16_512',\n",
       " 'beitv2_base_patch16_224',\n",
       " 'beitv2_large_patch16_224',\n",
       " 'botnet26t_256',\n",
       " 'botnet50ts_256',\n",
       " 'caformer_b36',\n",
       " 'caformer_m36',\n",
       " 'caformer_s18',\n",
       " 'caformer_s36',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_medium',\n",
       " 'coat_lite_medium_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_small',\n",
       " 'coat_tiny',\n",
       " 'coatnet_0_224',\n",
       " 'coatnet_0_rw_224',\n",
       " 'coatnet_1_224',\n",
       " 'coatnet_1_rw_224',\n",
       " 'coatnet_2_224',\n",
       " 'coatnet_2_rw_224',\n",
       " 'coatnet_3_224',\n",
       " 'coatnet_3_rw_224',\n",
       " 'coatnet_4_224',\n",
       " 'coatnet_5_224',\n",
       " 'coatnet_bn_0_rw_224',\n",
       " 'coatnet_nano_cc_224',\n",
       " 'coatnet_nano_rw_224',\n",
       " 'coatnet_pico_rw_224',\n",
       " 'coatnet_rmlp_0_rw_224',\n",
       " 'coatnet_rmlp_1_rw2_224',\n",
       " 'coatnet_rmlp_1_rw_224',\n",
       " 'coatnet_rmlp_2_rw_224',\n",
       " 'coatnet_rmlp_2_rw_384',\n",
       " 'coatnet_rmlp_3_rw_224',\n",
       " 'coatnet_rmlp_nano_rw_224',\n",
       " 'coatnext_nano_rw_224',\n",
       " 'convformer_b36',\n",
       " 'convformer_m36',\n",
       " 'convformer_s18',\n",
       " 'convformer_s36',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_atto',\n",
       " 'convnext_atto_ols',\n",
       " 'convnext_base',\n",
       " 'convnext_femto',\n",
       " 'convnext_femto_ols',\n",
       " 'convnext_large',\n",
       " 'convnext_large_mlp',\n",
       " 'convnext_nano',\n",
       " 'convnext_nano_ols',\n",
       " 'convnext_pico',\n",
       " 'convnext_pico_ols',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_hnf',\n",
       " 'convnext_xlarge',\n",
       " 'convnext_xxlarge',\n",
       " 'convnextv2_atto',\n",
       " 'convnextv2_base',\n",
       " 'convnextv2_femto',\n",
       " 'convnextv2_huge',\n",
       " 'convnextv2_large',\n",
       " 'convnextv2_nano',\n",
       " 'convnextv2_pico',\n",
       " 'convnextv2_small',\n",
       " 'convnextv2_tiny',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cs3darknet_focus_l',\n",
       " 'cs3darknet_focus_m',\n",
       " 'cs3darknet_focus_s',\n",
       " 'cs3darknet_focus_x',\n",
       " 'cs3darknet_l',\n",
       " 'cs3darknet_m',\n",
       " 'cs3darknet_s',\n",
       " 'cs3darknet_x',\n",
       " 'cs3edgenet_x',\n",
       " 'cs3se_edgenet_x',\n",
       " 'cs3sedarknet_l',\n",
       " 'cs3sedarknet_x',\n",
       " 'cs3sedarknet_xdw',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnet50d',\n",
       " 'cspresnet50w',\n",
       " 'cspresnext50',\n",
       " 'darknet17',\n",
       " 'darknet21',\n",
       " 'darknet53',\n",
       " 'darknetaa53',\n",
       " 'davit_base',\n",
       " 'davit_giant',\n",
       " 'davit_huge',\n",
       " 'davit_large',\n",
       " 'davit_small',\n",
       " 'davit_tiny',\n",
       " 'deit3_base_patch16_224',\n",
       " 'deit3_base_patch16_384',\n",
       " 'deit3_huge_patch14_224',\n",
       " 'deit3_large_patch16_224',\n",
       " 'deit3_large_patch16_384',\n",
       " 'deit3_medium_patch16_224',\n",
       " 'deit3_small_patch16_224',\n",
       " 'deit3_small_patch16_384',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet264d',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn48b',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'eca_nfnet_l3',\n",
       " 'eca_resnet33ts',\n",
       " 'eca_resnext26ts',\n",
       " 'eca_vovnet39b',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet200d',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'ecaresnext26t_32x4d',\n",
       " 'ecaresnext50t_32x4d',\n",
       " 'edgenext_base',\n",
       " 'edgenext_small',\n",
       " 'edgenext_small_rw',\n",
       " 'edgenext_x_small',\n",
       " 'edgenext_xx_small',\n",
       " 'efficientformer_l1',\n",
       " 'efficientformer_l3',\n",
       " 'efficientformer_l7',\n",
       " 'efficientformerv2_l',\n",
       " 'efficientformerv2_s0',\n",
       " 'efficientformerv2_s1',\n",
       " 'efficientformerv2_s2',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b0_g8_gn',\n",
       " 'efficientnet_b0_g16_evos',\n",
       " 'efficientnet_b0_gn',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_g8_gn',\n",
       " 'efficientnet_b3_gn',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'efficientnetv2_s',\n",
       " 'efficientnetv2_xl',\n",
       " 'efficientvit_b0',\n",
       " 'efficientvit_b1',\n",
       " 'efficientvit_b2',\n",
       " 'efficientvit_b3',\n",
       " 'efficientvit_l1',\n",
       " 'efficientvit_l2',\n",
       " 'efficientvit_l3',\n",
       " 'efficientvit_m0',\n",
       " 'efficientvit_m1',\n",
       " 'efficientvit_m2',\n",
       " 'efficientvit_m3',\n",
       " 'efficientvit_m4',\n",
       " 'efficientvit_m5',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet19b_slim',\n",
       " 'ese_vovnet19b_slim_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'ese_vovnet39b_evos',\n",
       " 'ese_vovnet57b',\n",
       " 'ese_vovnet99b',\n",
       " 'eva02_base_patch14_224',\n",
       " 'eva02_base_patch14_448',\n",
       " 'eva02_base_patch16_clip_224',\n",
       " 'eva02_enormous_patch14_clip_224',\n",
       " 'eva02_large_patch14_224',\n",
       " 'eva02_large_patch14_448',\n",
       " 'eva02_large_patch14_clip_224',\n",
       " 'eva02_large_patch14_clip_336',\n",
       " 'eva02_small_patch14_224',\n",
       " 'eva02_small_patch14_336',\n",
       " 'eva02_tiny_patch14_224',\n",
       " 'eva02_tiny_patch14_336',\n",
       " 'eva_giant_patch14_224',\n",
       " 'eva_giant_patch14_336',\n",
       " 'eva_giant_patch14_560',\n",
       " 'eva_giant_patch14_clip_224',\n",
       " 'eva_large_patch14_196',\n",
       " 'eva_large_patch14_336',\n",
       " 'fastvit_ma36',\n",
       " 'fastvit_s12',\n",
       " 'fastvit_sa12',\n",
       " 'fastvit_sa24',\n",
       " 'fastvit_sa36',\n",
       " 'fastvit_t8',\n",
       " 'fastvit_t12',\n",
       " 'fbnetc_100',\n",
       " 'fbnetv3_b',\n",
       " 'fbnetv3_d',\n",
       " 'fbnetv3_g',\n",
       " 'flexivit_base',\n",
       " 'flexivit_large',\n",
       " 'flexivit_small',\n",
       " 'focalnet_base_lrf',\n",
       " 'focalnet_base_srf',\n",
       " 'focalnet_huge_fl3',\n",
       " 'focalnet_huge_fl4',\n",
       " 'focalnet_large_fl3',\n",
       " 'focalnet_large_fl4',\n",
       " 'focalnet_small_lrf',\n",
       " 'focalnet_small_srf',\n",
       " 'focalnet_tiny_lrf',\n",
       " 'focalnet_tiny_srf',\n",
       " 'focalnet_xlarge_fl3',\n",
       " 'focalnet_xlarge_fl4',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'gcresnet33ts',\n",
       " 'gcresnet50t',\n",
       " 'gcresnext26ts',\n",
       " 'gcresnext50ts',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_050',\n",
       " 'ghostnet_100',\n",
       " 'ghostnet_130',\n",
       " 'ghostnetv2_100',\n",
       " 'ghostnetv2_130',\n",
       " 'ghostnetv2_160',\n",
       " 'gmixer_12_224',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_b16_224',\n",
       " 'gmlp_s16_224',\n",
       " 'gmlp_ti16_224',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'halonet_h1',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hgnet_base',\n",
       " 'hgnet_small',\n",
       " 'hgnet_tiny',\n",
       " 'hgnetv2_b0',\n",
       " 'hgnetv2_b1',\n",
       " 'hgnetv2_b2',\n",
       " 'hgnetv2_b3',\n",
       " 'hgnetv2_b4',\n",
       " 'hgnetv2_b5',\n",
       " 'hgnetv2_b6',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w18_ssld',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w48_ssld',\n",
       " 'hrnet_w64',\n",
       " 'inception_next_base',\n",
       " 'inception_next_small',\n",
       " 'inception_next_tiny',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_035',\n",
       " 'lcnet_050',\n",
       " 'lcnet_075',\n",
       " 'lcnet_100',\n",
       " 'lcnet_150',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'legacy_xception',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_256d',\n",
       " 'levit_384',\n",
       " 'levit_384_s8',\n",
       " 'levit_512',\n",
       " 'levit_512_s8',\n",
       " 'levit_512d',\n",
       " 'levit_conv_128',\n",
       " 'levit_conv_128s',\n",
       " 'levit_conv_192',\n",
       " 'levit_conv_256',\n",
       " 'levit_conv_256d',\n",
       " 'levit_conv_384',\n",
       " 'levit_conv_384_s8',\n",
       " 'levit_conv_512',\n",
       " 'levit_conv_512_s8',\n",
       " 'levit_conv_512d',\n",
       " 'maxvit_base_tf_224',\n",
       " 'maxvit_base_tf_384',\n",
       " 'maxvit_base_tf_512',\n",
       " 'maxvit_large_tf_224',\n",
       " 'maxvit_large_tf_384',\n",
       " 'maxvit_large_tf_512',\n",
       " 'maxvit_nano_rw_256',\n",
       " 'maxvit_pico_rw_256',\n",
       " 'maxvit_rmlp_base_rw_224',\n",
       " 'maxvit_rmlp_base_rw_384',\n",
       " 'maxvit_rmlp_nano_rw_256',\n",
       " 'maxvit_rmlp_pico_rw_256',\n",
       " 'maxvit_rmlp_small_rw_224',\n",
       " 'maxvit_rmlp_small_rw_256',\n",
       " 'maxvit_rmlp_tiny_rw_256',\n",
       " 'maxvit_small_tf_224',\n",
       " 'maxvit_small_tf_384',\n",
       " 'maxvit_small_tf_512',\n",
       " 'maxvit_tiny_pm_256',\n",
       " 'maxvit_tiny_rw_224',\n",
       " 'maxvit_tiny_rw_256',\n",
       " 'maxvit_tiny_tf_224',\n",
       " 'maxvit_tiny_tf_384',\n",
       " 'maxvit_tiny_tf_512',\n",
       " 'maxvit_xlarge_tf_224',\n",
       " 'maxvit_xlarge_tf_384',\n",
       " 'maxvit_xlarge_tf_512',\n",
       " 'maxxvit_rmlp_nano_rw_256',\n",
       " 'maxxvit_rmlp_small_rw_256',\n",
       " 'maxxvit_rmlp_tiny_rw_256',\n",
       " 'maxxvitv2_nano_rw_256',\n",
       " 'maxxvitv2_rmlp_base_rw_224',\n",
       " 'maxxvitv2_rmlp_base_rw_384',\n",
       " 'maxxvitv2_rmlp_large_rw_224',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b32_224',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l32_224',\n",
       " 'mixer_s16_224',\n",
       " 'mixer_s32_224',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mixnet_xxl',\n",
       " 'mnasnet_050',\n",
       " 'mnasnet_075',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_140',\n",
       " 'mnasnet_small',\n",
       " 'mobilenetv2_035',\n",
       " 'mobilenetv2_050',\n",
       " 'mobilenetv2_075',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_075',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_rw',\n",
       " 'mobilenetv3_small_050',\n",
       " 'mobilenetv3_small_075',\n",
       " 'mobilenetv3_small_100',\n",
       " 'mobileone_s0',\n",
       " 'mobileone_s1',\n",
       " 'mobileone_s2',\n",
       " 'mobileone_s3',\n",
       " 'mobileone_s4',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_200',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_base_cls',\n",
       " 'mvitv2_huge_cls',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_large_cls',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_small_cls',\n",
       " 'mvitv2_tiny',\n",
       " 'nasnetalarge',\n",
       " 'nest_base',\n",
       " 'nest_base_jx',\n",
       " 'nest_small',\n",
       " 'nest_small_jx',\n",
       " 'nest_tiny',\n",
       " 'nest_tiny_jx',\n",
       " 'nextvit_base',\n",
       " 'nextvit_large',\n",
       " 'nextvit_small',\n",
       " 'nf_ecaresnet26',\n",
       " 'nf_ecaresnet50',\n",
       " 'nf_ecaresnet101',\n",
       " 'nf_regnet_b0',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_regnet_b2',\n",
       " 'nf_regnet_b3',\n",
       " 'nf_regnet_b4',\n",
       " 'nf_regnet_b5',\n",
       " 'nf_resnet26',\n",
       " 'nf_resnet50',\n",
       " 'nf_resnet101',\n",
       " 'nf_seresnet26',\n",
       " 'nf_seresnet50',\n",
       " 'nf_seresnet101',\n",
       " 'nfnet_f0',\n",
       " 'nfnet_f1',\n",
       " 'nfnet_f2',\n",
       " 'nfnet_f3',\n",
       " 'nfnet_f4',\n",
       " 'nfnet_f5',\n",
       " 'nfnet_f6',\n",
       " 'nfnet_f7',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'poolformerv2_m36',\n",
       " 'poolformerv2_m48',\n",
       " 'poolformerv2_s12',\n",
       " 'poolformerv2_s24',\n",
       " 'poolformerv2_s36',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b2_li',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'regnetv_040',\n",
       " 'regnetv_064',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_004_tv',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_008_tv',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_040_sgn',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_080_tv',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'regnety_640',\n",
       " 'regnety_1280',\n",
       " 'regnety_2560',\n",
       " 'regnetz_005',\n",
       " 'regnetz_040',\n",
       " 'regnetz_040_h',\n",
       " 'regnetz_b16',\n",
       " 'regnetz_b16_evos',\n",
       " 'regnetz_c16',\n",
       " 'regnetz_c16_evos',\n",
       " 'regnetz_d8',\n",
       " 'regnetz_d8_evos',\n",
       " 'regnetz_d32',\n",
       " 'regnetz_e8',\n",
       " 'repghostnet_050',\n",
       " 'repghostnet_058',\n",
       " 'repghostnet_080',\n",
       " 'repghostnet_100',\n",
       " 'repghostnet_111',\n",
       " 'repghostnet_130',\n",
       " 'repghostnet_150',\n",
       " 'repghostnet_200',\n",
       " 'repvgg_a0',\n",
       " 'repvgg_a1',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'repvgg_d2se',\n",
       " 'repvit_m0_9',\n",
       " 'repvit_m1',\n",
       " 'repvit_m1_0',\n",
       " 'repvit_m1_1',\n",
       " 'repvit_m1_5',\n",
       " 'repvit_m2',\n",
       " 'repvit_m2_3',\n",
       " 'repvit_m3',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net50d',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2net101d',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts',\n",
       " 'resnet33ts',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50c',\n",
       " 'resnet50d',\n",
       " 'resnet50s',\n",
       " 'resnet50t',\n",
       " 'resnet51q',\n",
       " 'resnet61q',\n",
       " 'resnet101',\n",
       " 'resnet101c',\n",
       " 'resnet101d',\n",
       " 'resnet101s',\n",
       " 'resnet152',\n",
       " 'resnet152c',\n",
       " 'resnet152d',\n",
       " 'resnet152s',\n",
       " 'resnet200',\n",
       " 'resnet200d',\n",
       " 'resnetaa34d',\n",
       " 'resnetaa50',\n",
       " 'resnetaa50d',\n",
       " 'resnetaa101d',\n",
       " 'resnetblur18',\n",
       " 'resnetblur50',\n",
       " 'resnetblur50d',\n",
       " 'resnetblur101d',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50',\n",
       " 'resnetv2_50d',\n",
       " 'resnetv2_50d_evos',\n",
       " 'resnetv2_50d_frn',\n",
       " 'resnetv2_50d_gn',\n",
       " 'resnetv2_50t',\n",
       " 'resnetv2_50x1_bit',\n",
       " 'resnetv2_50x3_bit',\n",
       " 'resnetv2_101',\n",
       " 'resnetv2_101d',\n",
       " 'resnetv2_101x1_bit',\n",
       " 'resnetv2_101x3_bit',\n",
       " 'resnetv2_152',\n",
       " 'resnetv2_152d',\n",
       " 'resnetv2_152x2_bit',\n",
       " 'resnetv2_152x4_bit',\n",
       " 'resnext26ts',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_32x16d',\n",
       " 'resnext101_32x32d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'rexnet_300',\n",
       " 'rexnetr_100',\n",
       " 'rexnetr_130',\n",
       " 'rexnetr_150',\n",
       " 'rexnetr_200',\n",
       " 'rexnetr_300',\n",
       " 'samvit_base_patch16',\n",
       " 'samvit_base_patch16_224',\n",
       " 'samvit_huge_patch16',\n",
       " 'samvit_large_patch16',\n",
       " 'sebotnet33ts_256',\n",
       " 'sedarknet21',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'selecsls84',\n",
       " 'semnasnet_050',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'semnasnet_140',\n",
       " 'senet154',\n",
       " 'sequencer2d_l',\n",
       " 'sequencer2d_m',\n",
       " 'sequencer2d_s',\n",
       " 'seresnet18',\n",
       " 'seresnet33ts',\n",
       " 'seresnet34',\n",
       " 'seresnet50',\n",
       " 'seresnet50t',\n",
       " 'seresnet101',\n",
       " 'seresnet152',\n",
       " 'seresnet152d',\n",
       " 'seresnet200d',\n",
       " 'seresnet269d',\n",
       " 'seresnetaa50d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26ts',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'seresnext101_64x4d',\n",
       " 'seresnext101d_32x8d',\n",
       " 'seresnextaa101d_32x8d',\n",
       " 'seresnextaa201d_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnet50',\n",
       " 'skresnet50d',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_s3_base_224',\n",
       " 'swin_s3_small_224',\n",
       " 'swin_s3_tiny_224',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swinv2_base_window8_256',\n",
       " 'swinv2_base_window12_192',\n",
       " 'swinv2_base_window12to16_192to256',\n",
       " 'swinv2_base_window12to24_192to384',\n",
       " 'swinv2_base_window16_256',\n",
       " 'swinv2_cr_base_224',\n",
       " 'swinv2_cr_base_384',\n",
       " 'swinv2_cr_base_ns_224',\n",
       " 'swinv2_cr_giant_224',\n",
       " 'swinv2_cr_giant_384',\n",
       " 'swinv2_cr_huge_224',\n",
       " 'swinv2_cr_huge_384',\n",
       " 'swinv2_cr_large_224',\n",
       " 'swinv2_cr_large_384',\n",
       " 'swinv2_cr_small_224',\n",
       " 'swinv2_cr_small_384',\n",
       " 'swinv2_cr_small_ns_224',\n",
       " 'swinv2_cr_small_ns_256',\n",
       " 'swinv2_cr_tiny_224',\n",
       " 'swinv2_cr_tiny_384',\n",
       " 'swinv2_cr_tiny_ns_224',\n",
       " 'swinv2_large_window12_192',\n",
       " 'swinv2_large_window12to16_192to256',\n",
       " 'swinv2_large_window12to24_192to384',\n",
       " 'swinv2_small_window8_256',\n",
       " 'swinv2_small_window16_256',\n",
       " 'swinv2_tiny_window8_256',\n",
       " 'swinv2_tiny_window16_256',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_xl',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tiny_vit_5m_224',\n",
       " 'tiny_vit_11m_224',\n",
       " 'tiny_vit_21m_224',\n",
       " 'tiny_vit_21m_384',\n",
       " 'tiny_vit_21m_512',\n",
       " 'tinynet_a',\n",
       " 'tinynet_b',\n",
       " 'tinynet_c',\n",
       " 'tinynet_d',\n",
       " 'tinynet_e',\n",
       " 'tnt_b_patch16_224',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_m',\n",
       " 'tresnet_v2_l',\n",
       " 'tresnet_xl',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'visformer_tiny',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch14_dinov2',\n",
       " 'vit_base_patch14_reg4_dinov2',\n",
       " 'vit_base_patch16_18x2_224',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_clip_224',\n",
       " 'vit_base_patch16_clip_384',\n",
       " 'vit_base_patch16_clip_quickgelu_224',\n",
       " 'vit_base_patch16_gap_224',\n",
       " 'vit_base_patch16_plus_240',\n",
       " 'vit_base_patch16_reg4_gap_256',\n",
       " 'vit_base_patch16_rpn_224',\n",
       " 'vit_base_patch16_siglip_224',\n",
       " 'vit_base_patch16_siglip_256',\n",
       " 'vit_base_patch16_siglip_384',\n",
       " 'vit_base_patch16_siglip_512',\n",
       " 'vit_base_patch16_xp_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_clip_224',\n",
       " 'vit_base_patch32_clip_256',\n",
       " 'vit_base_patch32_clip_384',\n",
       " 'vit_base_patch32_clip_448',\n",
       " 'vit_base_patch32_clip_quickgelu_224',\n",
       " 'vit_base_patch32_plus_256',\n",
       " 'vit_base_r26_s32_224',\n",
       " 'vit_base_r50_s16_224',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_base_resnet26d_224',\n",
       " 'vit_base_resnet50d_224',\n",
       " 'vit_giant_patch14_224',\n",
       " 'vit_giant_patch14_clip_224',\n",
       " 'vit_giant_patch14_dinov2',\n",
       " 'vit_giant_patch14_reg4_dinov2',\n",
       " 'vit_giant_patch16_gap_224',\n",
       " 'vit_gigantic_patch14_224',\n",
       " 'vit_gigantic_patch14_clip_224',\n",
       " 'vit_huge_patch14_224',\n",
       " 'vit_huge_patch14_clip_224',\n",
       " 'vit_huge_patch14_clip_336',\n",
       " 'vit_huge_patch14_clip_378',\n",
       " 'vit_huge_patch14_clip_quickgelu_224',\n",
       " 'vit_huge_patch14_clip_quickgelu_378',\n",
       " 'vit_huge_patch14_gap_224',\n",
       " 'vit_huge_patch14_xp_224',\n",
       " 'vit_huge_patch16_gap_448',\n",
       " 'vit_large_patch14_224',\n",
       " 'vit_large_patch14_clip_224',\n",
       " 'vit_large_patch14_clip_336',\n",
       " 'vit_large_patch14_clip_quickgelu_224',\n",
       " 'vit_large_patch14_clip_quickgelu_336',\n",
       " 'vit_large_patch14_dinov2',\n",
       " 'vit_large_patch14_reg4_dinov2',\n",
       " 'vit_large_patch14_xp_224',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch16_siglip_256',\n",
       " 'vit_large_patch16_siglip_384',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_medium_patch16_gap_240',\n",
       " 'vit_medium_patch16_gap_256',\n",
       " 'vit_medium_patch16_gap_384',\n",
       " 'vit_medium_patch16_reg4_256',\n",
       " 'vit_medium_patch16_reg4_gap_256',\n",
       " 'vit_relpos_base_patch16_224',\n",
       " 'vit_relpos_base_patch16_cls_224',\n",
       " 'vit_relpos_base_patch16_clsgap_224',\n",
       " 'vit_relpos_base_patch16_plus_240',\n",
       " 'vit_relpos_base_patch16_rpn_224',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256',\n",
       " 'vit_relpos_medium_patch16_224',\n",
       " 'vit_relpos_medium_patch16_cls_224',\n",
       " 'vit_relpos_medium_patch16_rpn_224',\n",
       " 'vit_relpos_small_patch16_224',\n",
       " 'vit_relpos_small_patch16_rpn_224',\n",
       " 'vit_small_patch8_224',\n",
       " 'vit_small_patch14_dinov2',\n",
       " 'vit_small_patch14_reg4_dinov2',\n",
       " 'vit_small_patch16_18x2_224',\n",
       " 'vit_small_patch16_36x1_224',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_small_resnet26d_224',\n",
       " 'vit_small_resnet50d_s16_224',\n",
       " 'vit_so150m_patch16_reg4_gap_256',\n",
       " 'vit_so150m_patch16_reg4_map_256',\n",
       " 'vit_so400m_patch14_siglip_224',\n",
       " 'vit_so400m_patch14_siglip_384',\n",
       " 'vit_srelpos_medium_patch16_224',\n",
       " 'vit_srelpos_small_patch16_224',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_384',\n",
       " 'volo_d1_224',\n",
       " 'volo_d1_384',\n",
       " 'volo_d2_224',\n",
       " 'volo_d2_384',\n",
       " 'volo_d3_224',\n",
       " 'volo_d3_448',\n",
       " 'volo_d4_224',\n",
       " 'volo_d4_448',\n",
       " 'volo_d5_224',\n",
       " 'volo_d5_448',\n",
       " 'volo_d5_512',\n",
       " 'vovnet39a',\n",
       " 'vovnet57a',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception41',\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f39a48-1f3a-4c6c-9b9a-767386d45857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0502a64b864d4347962b2fe60fcf8759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/199M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\marcb\\.cache\\huggingface\\hub\\models--timm--davit_small.msft_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DaVit(\n",
       "  (stem): Stem(\n",
       "    (conv): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "    (norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): DaVitStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): SpatialBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): ChannelBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): DaVitStage(\n",
       "      (downsample): Downsample(\n",
       "        (norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (conv): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): SpatialBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): ChannelBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): DaVitStage(\n",
       "      (downsample): Downsample(\n",
       "        (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (conv): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): SpatialBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): ChannelBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): SpatialBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): ChannelBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): SpatialBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): ChannelBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): SpatialBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): ChannelBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): SpatialBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): ChannelBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): SpatialBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): ChannelBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): SpatialBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): ChannelBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): SpatialBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): ChannelBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): SpatialBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): ChannelBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): DaVitStage(\n",
       "      (downsample): Downsample(\n",
       "        (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (conv): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): SpatialBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): ChannelBlock(\n",
       "            (cpe1): ConvPosEnc(\n",
       "              (proj): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (cpe2): ConvPosEnc(\n",
       "              (proj): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm_pre): Identity()\n",
       "  (head): NormMlpClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (norm): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (pre_logits): Identity()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('davit_small.msft_in1k', pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d806d25e-d60a-4c16-a835-9f32068dda0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
